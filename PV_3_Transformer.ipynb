{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dba96fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score, classification_report, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311c6f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\My PC\\Desktop\\Solar PV Fault Research\\IO_DATA_LABELED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b30c3c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Inv-3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f383307d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Inv</th>\n",
       "      <th>AC_Real_Power</th>\n",
       "      <th>AC_Current</th>\n",
       "      <th>DC_Power</th>\n",
       "      <th>DC_Current</th>\n",
       "      <th>Tilt_Irradiation_1</th>\n",
       "      <th>Temp_Ambient_1</th>\n",
       "      <th>Temp_Module_1</th>\n",
       "      <th>Wind_Speed_1</th>\n",
       "      <th>Hor_Irradiation_1</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>05:45:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:15:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:30:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.510</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:45:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>1.09</td>\n",
       "      <td>6.02</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.91</td>\n",
       "      <td>25.9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.569</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16001</th>\n",
       "      <td>16001</td>\n",
       "      <td>16001</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>18:30:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>5.19</td>\n",
       "      <td>9.88</td>\n",
       "      <td>6.40</td>\n",
       "      <td>13.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16002</th>\n",
       "      <td>16002</td>\n",
       "      <td>16002</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>18:45:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.7</td>\n",
       "      <td>27.2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16003</th>\n",
       "      <td>16003</td>\n",
       "      <td>16003</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16004</th>\n",
       "      <td>16004</td>\n",
       "      <td>16004</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>19:15:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16005</th>\n",
       "      <td>16005</td>\n",
       "      <td>16005</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>19:30:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.1</td>\n",
       "      <td>25.7</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16006 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0        Date      Time    Inv  AC_Real_Power  \\\n",
       "0                 0           0  2019-04-01  05:45:00  Inv-3           0.00   \n",
       "1                 1           1  2019-04-01  06:00:00  Inv-3           0.00   \n",
       "2                 2           2  2019-04-01  06:15:00  Inv-3           0.00   \n",
       "3                 3           3  2019-04-01  06:30:00  Inv-3           0.00   \n",
       "4                 4           4  2019-04-01  06:45:00  Inv-3           1.09   \n",
       "...             ...         ...         ...       ...    ...            ...   \n",
       "16001         16001       16001  2020-02-29  18:30:00  Inv-3           5.19   \n",
       "16002         16002       16002  2020-02-29  18:45:00  Inv-3           0.00   \n",
       "16003         16003       16003  2020-02-29  19:00:00  Inv-3           0.00   \n",
       "16004         16004       16004  2020-02-29  19:15:00  Inv-3           0.00   \n",
       "16005         16005       16005  2020-02-29  19:30:00  Inv-3           0.00   \n",
       "\n",
       "       AC_Current  DC_Power  DC_Current  Tilt_Irradiation_1  Temp_Ambient_1  \\\n",
       "0            0.00      0.00        3.66                 0.0            17.7   \n",
       "1            0.00      0.00        2.84                 0.0            19.2   \n",
       "2            0.00      0.00        0.00                 0.0            19.0   \n",
       "3            0.00      0.00        0.00                 7.2            19.0   \n",
       "4            6.02      1.35        3.91                25.9            19.7   \n",
       "...           ...       ...         ...                 ...             ...   \n",
       "16001        9.88      6.40       13.46                 0.0            26.4   \n",
       "16002        0.00      0.00        0.00                 0.0            25.7   \n",
       "16003        0.00      0.00        0.00                 0.0            24.1   \n",
       "16004        0.00      0.00        0.37                 0.0            24.3   \n",
       "16005        0.00      0.00        1.26                 0.0            25.1   \n",
       "\n",
       "       Temp_Module_1  Wind_Speed_1  Hor_Irradiation_1  Operation  \n",
       "0               19.6         0.500                0.0          1  \n",
       "1               20.1         0.535                0.0          1  \n",
       "2               20.1         0.500                1.6          1  \n",
       "3               20.6         0.510               10.4          1  \n",
       "4               21.1         0.569               27.0          1  \n",
       "...              ...           ...                ...        ...  \n",
       "16001           28.6         0.500                3.2          1  \n",
       "16002           27.2         0.500                0.2          1  \n",
       "16003           26.1         0.500                0.1          1  \n",
       "16004           25.7         0.728                0.1          1  \n",
       "16005           25.7         1.010                0.1          1  \n",
       "\n",
       "[16006 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac88523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16006 entries, 0 to 16005\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Unnamed: 0.1        16006 non-null  int64  \n",
      " 1   Unnamed: 0          16006 non-null  int64  \n",
      " 2   Date                16006 non-null  object \n",
      " 3   Time                16006 non-null  object \n",
      " 4   Inv                 16006 non-null  object \n",
      " 5   AC_Real_Power       16002 non-null  float64\n",
      " 6   AC_Current          16002 non-null  float64\n",
      " 7   DC_Power            16002 non-null  float64\n",
      " 8   DC_Current          16002 non-null  float64\n",
      " 9   Tilt_Irradiation_1  16006 non-null  float64\n",
      " 10  Temp_Ambient_1      16006 non-null  float64\n",
      " 11  Temp_Module_1       16006 non-null  float64\n",
      " 12  Wind_Speed_1        16006 non-null  float64\n",
      " 13  Hor_Irradiation_1   16006 non-null  float64\n",
      " 14  Operation           16006 non-null  int64  \n",
      "dtypes: float64(9), int64(3), object(3)\n",
      "memory usage: 1.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Inv</th>\n",
       "      <th>AC_Real_Power</th>\n",
       "      <th>AC_Current</th>\n",
       "      <th>DC_Power</th>\n",
       "      <th>DC_Current</th>\n",
       "      <th>Tilt_Irradiation_1</th>\n",
       "      <th>Temp_Ambient_1</th>\n",
       "      <th>Temp_Module_1</th>\n",
       "      <th>Wind_Speed_1</th>\n",
       "      <th>Hor_Irradiation_1</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>05:45:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:15:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:30:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.510</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:45:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>1.09</td>\n",
       "      <td>6.02</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.91</td>\n",
       "      <td>25.9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.569</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0        Date      Time    Inv  AC_Real_Power  \\\n",
       "0             0           0  2019-04-01  05:45:00  Inv-3           0.00   \n",
       "1             1           1  2019-04-01  06:00:00  Inv-3           0.00   \n",
       "2             2           2  2019-04-01  06:15:00  Inv-3           0.00   \n",
       "3             3           3  2019-04-01  06:30:00  Inv-3           0.00   \n",
       "4             4           4  2019-04-01  06:45:00  Inv-3           1.09   \n",
       "\n",
       "   AC_Current  DC_Power  DC_Current  Tilt_Irradiation_1  Temp_Ambient_1  \\\n",
       "0        0.00      0.00        3.66                 0.0            17.7   \n",
       "1        0.00      0.00        2.84                 0.0            19.2   \n",
       "2        0.00      0.00        0.00                 0.0            19.0   \n",
       "3        0.00      0.00        0.00                 7.2            19.0   \n",
       "4        6.02      1.35        3.91                25.9            19.7   \n",
       "\n",
       "   Temp_Module_1  Wind_Speed_1  Hor_Irradiation_1  Operation  \n",
       "0           19.6         0.500                0.0          1  \n",
       "1           20.1         0.535                0.0          1  \n",
       "2           20.1         0.500                1.6          1  \n",
       "3           20.6         0.510               10.4          1  \n",
       "4           21.1         0.569               27.0          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.info(),df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32c33ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 16006\n",
      "Number of columns: 15\n"
     ]
    }
   ],
   "source": [
    "num_rows, num_columns = df.shape\n",
    "\n",
    "print(\"Number of rows:\", num_rows)\n",
    "print(\"Number of columns:\", num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a0bca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47b9e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26919da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('DateTime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af23b793",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Date','Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6c1b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = pd.Timestamp(\"07:00:00\")\n",
    "end_time = pd.Timestamp(\"18:30:00\")\n",
    "\n",
    "# Filtering the data to retain only the rows within the operational hours\n",
    "df = df[(df.index.time >= pd.to_datetime('7:00:00').time()) & (df.index.time <= pd.to_datetime('18:30:00').time())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13024fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inv</th>\n",
       "      <th>AC_Real_Power</th>\n",
       "      <th>AC_Current</th>\n",
       "      <th>DC_Power</th>\n",
       "      <th>DC_Current</th>\n",
       "      <th>Tilt_Irradiation_1</th>\n",
       "      <th>Temp_Ambient_1</th>\n",
       "      <th>Temp_Module_1</th>\n",
       "      <th>Wind_Speed_1</th>\n",
       "      <th>Hor_Irradiation_1</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-01 07:00:00</th>\n",
       "      <td>Inv-3</td>\n",
       "      <td>10.28</td>\n",
       "      <td>19.65</td>\n",
       "      <td>12.56</td>\n",
       "      <td>24.98</td>\n",
       "      <td>44.8</td>\n",
       "      <td>20.2</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.500</td>\n",
       "      <td>48.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 07:15:00</th>\n",
       "      <td>Inv-3</td>\n",
       "      <td>26.17</td>\n",
       "      <td>47.72</td>\n",
       "      <td>31.05</td>\n",
       "      <td>54.93</td>\n",
       "      <td>64.6</td>\n",
       "      <td>22.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>0.614</td>\n",
       "      <td>79.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 07:30:00</th>\n",
       "      <td>Inv-3</td>\n",
       "      <td>45.80</td>\n",
       "      <td>83.65</td>\n",
       "      <td>52.47</td>\n",
       "      <td>93.66</td>\n",
       "      <td>82.6</td>\n",
       "      <td>23.9</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.802</td>\n",
       "      <td>119.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 07:45:00</th>\n",
       "      <td>Inv-3</td>\n",
       "      <td>68.18</td>\n",
       "      <td>124.36</td>\n",
       "      <td>75.33</td>\n",
       "      <td>140.61</td>\n",
       "      <td>103.8</td>\n",
       "      <td>24.6</td>\n",
       "      <td>27.2</td>\n",
       "      <td>1.599</td>\n",
       "      <td>167.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 08:00:00</th>\n",
       "      <td>Inv-3</td>\n",
       "      <td>97.92</td>\n",
       "      <td>178.64</td>\n",
       "      <td>106.32</td>\n",
       "      <td>194.83</td>\n",
       "      <td>281.8</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0.960</td>\n",
       "      <td>220.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Inv  AC_Real_Power  AC_Current  DC_Power  DC_Current  \\\n",
       "DateTime                                                                      \n",
       "2019-04-01 07:00:00  Inv-3          10.28       19.65     12.56       24.98   \n",
       "2019-04-01 07:15:00  Inv-3          26.17       47.72     31.05       54.93   \n",
       "2019-04-01 07:30:00  Inv-3          45.80       83.65     52.47       93.66   \n",
       "2019-04-01 07:45:00  Inv-3          68.18      124.36     75.33      140.61   \n",
       "2019-04-01 08:00:00  Inv-3          97.92      178.64    106.32      194.83   \n",
       "\n",
       "                     Tilt_Irradiation_1  Temp_Ambient_1  Temp_Module_1  \\\n",
       "DateTime                                                                 \n",
       "2019-04-01 07:00:00                44.8            20.2           22.9   \n",
       "2019-04-01 07:15:00                64.6            22.4           24.8   \n",
       "2019-04-01 07:30:00                82.6            23.9           26.1   \n",
       "2019-04-01 07:45:00               103.8            24.6           27.2   \n",
       "2019-04-01 08:00:00               281.8            26.5           31.2   \n",
       "\n",
       "                     Wind_Speed_1  Hor_Irradiation_1  Operation  \n",
       "DateTime                                                         \n",
       "2019-04-01 07:00:00         0.500               48.1          1  \n",
       "2019-04-01 07:15:00         0.614               79.8          1  \n",
       "2019-04-01 07:30:00         0.802              119.5          1  \n",
       "2019-04-01 07:45:00         1.599              167.4          1  \n",
       "2019-04-01 08:00:00         0.960              220.1          1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8677fa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inv                   0\n",
      "AC_Real_Power         0\n",
      "AC_Current            0\n",
      "DC_Power              0\n",
      "DC_Current            0\n",
      "Tilt_Irradiation_1    0\n",
      "Temp_Ambient_1        0\n",
      "Temp_Module_1         0\n",
      "Wind_Speed_1          0\n",
      "Hor_Irradiation_1     0\n",
      "Operation             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_data = df.isnull().sum()\n",
    "print(missing_data)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f92bdbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "operational_data = df\n",
    "numerical_features = ['AC_Real_Power','Tilt_Irradiation_1', 'Temp_Ambient_1', 'Hor_Irradiation_1']\n",
    "\n",
    "# Normalization of the features\n",
    "operational_data[numerical_features] = scaler.fit_transform(operational_data[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54ed750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = operational_data[['Tilt_Irradiation_1', 'Temp_Ambient_1', 'Hor_Irradiation_1']]\n",
    "y = operational_data['AC_Real_Power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f4e7d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch [1/200], Loss: 0.1727\n",
      "Validation - Epoch [1/200], Loss: 0.0138\n",
      "Training - Epoch [2/200], Loss: 0.0141\n",
      "Validation - Epoch [2/200], Loss: 0.0119\n",
      "Training - Epoch [3/200], Loss: 0.0127\n",
      "Validation - Epoch [3/200], Loss: 0.0108\n",
      "Training - Epoch [4/200], Loss: 0.0122\n",
      "Validation - Epoch [4/200], Loss: 0.0110\n",
      "Training - Epoch [5/200], Loss: 0.0115\n",
      "Validation - Epoch [5/200], Loss: 0.0098\n",
      "Training - Epoch [6/200], Loss: 0.0112\n",
      "Validation - Epoch [6/200], Loss: 0.0173\n",
      "Training - Epoch [7/200], Loss: 0.0111\n",
      "Validation - Epoch [7/200], Loss: 0.0104\n",
      "Training - Epoch [8/200], Loss: 0.0111\n",
      "Validation - Epoch [8/200], Loss: 0.0088\n",
      "Training - Epoch [9/200], Loss: 0.0106\n",
      "Validation - Epoch [9/200], Loss: 0.0106\n",
      "Training - Epoch [10/200], Loss: 0.0106\n",
      "Validation - Epoch [10/200], Loss: 0.0090\n",
      "Training - Epoch [11/200], Loss: 0.0102\n",
      "Validation - Epoch [11/200], Loss: 0.0089\n",
      "Training - Epoch [12/200], Loss: 0.0110\n",
      "Validation - Epoch [12/200], Loss: 0.0091\n",
      "Training - Epoch [13/200], Loss: 0.0104\n",
      "Validation - Epoch [13/200], Loss: 0.0098\n",
      "Training - Epoch [14/200], Loss: 0.0102\n",
      "Validation - Epoch [14/200], Loss: 0.0190\n",
      "Training - Epoch [15/200], Loss: 0.0103\n",
      "Validation - Epoch [15/200], Loss: 0.0109\n",
      "Training - Epoch [16/200], Loss: 0.0099\n",
      "Validation - Epoch [16/200], Loss: 0.0083\n",
      "Training - Epoch [17/200], Loss: 0.0106\n",
      "Validation - Epoch [17/200], Loss: 0.0083\n",
      "Training - Epoch [18/200], Loss: 0.0100\n",
      "Validation - Epoch [18/200], Loss: 0.0095\n",
      "Training - Epoch [19/200], Loss: 0.0101\n",
      "Validation - Epoch [19/200], Loss: 0.0083\n",
      "Training - Epoch [20/200], Loss: 0.0100\n",
      "Validation - Epoch [20/200], Loss: 0.0099\n",
      "Training - Epoch [21/200], Loss: 0.0100\n",
      "Validation - Epoch [21/200], Loss: 0.0094\n",
      "Training - Epoch [22/200], Loss: 0.0105\n",
      "Validation - Epoch [22/200], Loss: 0.0099\n",
      "Training - Epoch [23/200], Loss: 0.0098\n",
      "Validation - Epoch [23/200], Loss: 0.0108\n",
      "Training - Epoch [24/200], Loss: 0.0100\n",
      "Validation - Epoch [24/200], Loss: 0.0098\n",
      "Training - Epoch [25/200], Loss: 0.0107\n",
      "Validation - Epoch [25/200], Loss: 0.0147\n",
      "Training - Epoch [26/200], Loss: 0.0106\n",
      "Validation - Epoch [26/200], Loss: 0.0124\n",
      "Training - Epoch [27/200], Loss: 0.0118\n",
      "Validation - Epoch [27/200], Loss: 0.0163\n",
      "Training - Epoch [28/200], Loss: 0.0119\n",
      "Validation - Epoch [28/200], Loss: 0.0099\n",
      "Training - Epoch [29/200], Loss: 0.0100\n",
      "Validation - Epoch [29/200], Loss: 0.0085\n",
      "Training - Epoch [30/200], Loss: 0.0101\n",
      "Validation - Epoch [30/200], Loss: 0.0088\n",
      "Training - Epoch [31/200], Loss: 0.0100\n",
      "Validation - Epoch [31/200], Loss: 0.0084\n",
      "Training - Epoch [32/200], Loss: 0.0108\n",
      "Validation - Epoch [32/200], Loss: 0.0090\n",
      "Training - Epoch [33/200], Loss: 0.0100\n",
      "Validation - Epoch [33/200], Loss: 0.0083\n",
      "Training - Epoch [34/200], Loss: 0.0116\n",
      "Validation - Epoch [34/200], Loss: 0.0092\n",
      "Training - Epoch [35/200], Loss: 0.0105\n",
      "Validation - Epoch [35/200], Loss: 0.0104\n",
      "Training - Epoch [36/200], Loss: 0.0102\n",
      "Validation - Epoch [36/200], Loss: 0.0104\n",
      "Training - Epoch [37/200], Loss: 0.0096\n",
      "Validation - Epoch [37/200], Loss: 0.0133\n",
      "Training - Epoch [38/200], Loss: 0.0097\n",
      "Validation - Epoch [38/200], Loss: 0.0093\n",
      "Training - Epoch [39/200], Loss: 0.0096\n",
      "Validation - Epoch [39/200], Loss: 0.0149\n",
      "Training - Epoch [40/200], Loss: 0.0454\n",
      "Validation - Epoch [40/200], Loss: 0.0338\n",
      "Training - Epoch [41/200], Loss: 0.0367\n",
      "Validation - Epoch [41/200], Loss: 0.0277\n",
      "Training - Epoch [42/200], Loss: 0.0302\n",
      "Validation - Epoch [42/200], Loss: 0.0274\n",
      "Training - Epoch [43/200], Loss: 0.0286\n",
      "Validation - Epoch [43/200], Loss: 0.0261\n",
      "Training - Epoch [44/200], Loss: 0.0286\n",
      "Validation - Epoch [44/200], Loss: 0.0275\n",
      "Training - Epoch [45/200], Loss: 0.0263\n",
      "Validation - Epoch [45/200], Loss: 0.0191\n",
      "Training - Epoch [46/200], Loss: 0.0153\n",
      "Validation - Epoch [46/200], Loss: 0.0116\n",
      "Training - Epoch [47/200], Loss: 0.0119\n",
      "Validation - Epoch [47/200], Loss: 0.0102\n",
      "Training - Epoch [48/200], Loss: 0.0117\n",
      "Validation - Epoch [48/200], Loss: 0.0109\n",
      "Training - Epoch [49/200], Loss: 0.0122\n",
      "Validation - Epoch [49/200], Loss: 0.0107\n",
      "Training - Epoch [50/200], Loss: 0.0120\n",
      "Validation - Epoch [50/200], Loss: 0.0119\n",
      "Training - Epoch [51/200], Loss: 0.0121\n",
      "Validation - Epoch [51/200], Loss: 0.0104\n",
      "Training - Epoch [52/200], Loss: 0.0118\n",
      "Validation - Epoch [52/200], Loss: 0.0167\n",
      "Training - Epoch [53/200], Loss: 0.0117\n",
      "Validation - Epoch [53/200], Loss: 0.0124\n",
      "Training - Epoch [54/200], Loss: 0.0119\n",
      "Validation - Epoch [54/200], Loss: 0.0100\n",
      "Training - Epoch [55/200], Loss: 0.0116\n",
      "Validation - Epoch [55/200], Loss: 0.0104\n",
      "Training - Epoch [56/200], Loss: 0.0120\n",
      "Validation - Epoch [56/200], Loss: 0.0105\n",
      "Training - Epoch [57/200], Loss: 0.0118\n",
      "Validation - Epoch [57/200], Loss: 0.0098\n",
      "Training - Epoch [58/200], Loss: 0.0127\n",
      "Validation - Epoch [58/200], Loss: 0.0132\n",
      "Training - Epoch [59/200], Loss: 0.0127\n",
      "Validation - Epoch [59/200], Loss: 0.0095\n",
      "Training - Epoch [60/200], Loss: 0.0120\n",
      "Validation - Epoch [60/200], Loss: 0.0100\n",
      "Training - Epoch [61/200], Loss: 0.0116\n",
      "Validation - Epoch [61/200], Loss: 0.0099\n",
      "Training - Epoch [62/200], Loss: 0.0115\n",
      "Validation - Epoch [62/200], Loss: 0.0116\n",
      "Training - Epoch [63/200], Loss: 0.0116\n",
      "Validation - Epoch [63/200], Loss: 0.0108\n",
      "Training - Epoch [64/200], Loss: 0.0111\n",
      "Validation - Epoch [64/200], Loss: 0.0108\n",
      "Training - Epoch [65/200], Loss: 0.0114\n",
      "Validation - Epoch [65/200], Loss: 0.0168\n",
      "Training - Epoch [66/200], Loss: 0.0115\n",
      "Validation - Epoch [66/200], Loss: 0.0098\n",
      "Training - Epoch [67/200], Loss: 0.0113\n",
      "Validation - Epoch [67/200], Loss: 0.0097\n",
      "Training - Epoch [68/200], Loss: 0.0112\n",
      "Validation - Epoch [68/200], Loss: 0.0103\n",
      "Training - Epoch [69/200], Loss: 0.0112\n",
      "Validation - Epoch [69/200], Loss: 0.0097\n",
      "Training - Epoch [70/200], Loss: 0.0109\n",
      "Validation - Epoch [70/200], Loss: 0.0109\n",
      "Training - Epoch [71/200], Loss: 0.0129\n",
      "Validation - Epoch [71/200], Loss: 0.0110\n",
      "Training - Epoch [72/200], Loss: 0.0110\n",
      "Validation - Epoch [72/200], Loss: 0.0108\n",
      "Training - Epoch [73/200], Loss: 0.0110\n",
      "Validation - Epoch [73/200], Loss: 0.0102\n",
      "Training - Epoch [74/200], Loss: 0.0107\n",
      "Validation - Epoch [74/200], Loss: 0.0099\n",
      "Training - Epoch [75/200], Loss: 0.0111\n",
      "Validation - Epoch [75/200], Loss: 0.0129\n",
      "Training - Epoch [76/200], Loss: 0.0110\n",
      "Validation - Epoch [76/200], Loss: 0.0099\n",
      "Training - Epoch [77/200], Loss: 0.0118\n",
      "Validation - Epoch [77/200], Loss: 0.0108\n",
      "Training - Epoch [78/200], Loss: 0.0112\n",
      "Validation - Epoch [78/200], Loss: 0.0097\n",
      "Training - Epoch [79/200], Loss: 0.0111\n",
      "Validation - Epoch [79/200], Loss: 0.0100\n",
      "Training - Epoch [80/200], Loss: 0.0116\n",
      "Validation - Epoch [80/200], Loss: 0.0104\n",
      "Training - Epoch [81/200], Loss: 0.0111\n",
      "Validation - Epoch [81/200], Loss: 0.0095\n",
      "Training - Epoch [82/200], Loss: 0.0111\n",
      "Validation - Epoch [82/200], Loss: 0.0095\n",
      "Training - Epoch [83/200], Loss: 0.0108\n",
      "Validation - Epoch [83/200], Loss: 0.0100\n",
      "Training - Epoch [84/200], Loss: 0.0109\n",
      "Validation - Epoch [84/200], Loss: 0.0099\n",
      "Training - Epoch [85/200], Loss: 0.0106\n",
      "Validation - Epoch [85/200], Loss: 0.0131\n",
      "Training - Epoch [86/200], Loss: 0.0110\n",
      "Validation - Epoch [86/200], Loss: 0.0096\n",
      "Training - Epoch [87/200], Loss: 0.0106\n",
      "Validation - Epoch [87/200], Loss: 0.0096\n",
      "Training - Epoch [88/200], Loss: 0.0107\n",
      "Validation - Epoch [88/200], Loss: 0.0099\n",
      "Training - Epoch [89/200], Loss: 0.0110\n",
      "Validation - Epoch [89/200], Loss: 0.0098\n",
      "Training - Epoch [90/200], Loss: 0.0110\n",
      "Validation - Epoch [90/200], Loss: 0.0113\n",
      "Training - Epoch [91/200], Loss: 0.0106\n",
      "Validation - Epoch [91/200], Loss: 0.0106\n",
      "Training - Epoch [92/200], Loss: 0.0116\n",
      "Validation - Epoch [92/200], Loss: 0.0099\n",
      "Training - Epoch [93/200], Loss: 0.0107\n",
      "Validation - Epoch [93/200], Loss: 0.0103\n",
      "Training - Epoch [94/200], Loss: 0.0104\n",
      "Validation - Epoch [94/200], Loss: 0.0095\n",
      "Training - Epoch [95/200], Loss: 0.0104\n",
      "Validation - Epoch [95/200], Loss: 0.0092\n",
      "Training - Epoch [96/200], Loss: 0.0104\n",
      "Validation - Epoch [96/200], Loss: 0.0094\n",
      "Training - Epoch [97/200], Loss: 0.0106\n",
      "Validation - Epoch [97/200], Loss: 0.0095\n",
      "Training - Epoch [98/200], Loss: 0.0106\n",
      "Validation - Epoch [98/200], Loss: 0.0097\n",
      "Training - Epoch [99/200], Loss: 0.0109\n",
      "Validation - Epoch [99/200], Loss: 0.0097\n",
      "Training - Epoch [100/200], Loss: 0.0109\n",
      "Validation - Epoch [100/200], Loss: 0.0097\n",
      "Training - Epoch [101/200], Loss: 0.0116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch [101/200], Loss: 0.0133\n",
      "Training - Epoch [102/200], Loss: 0.0108\n",
      "Validation - Epoch [102/200], Loss: 0.0095\n",
      "Training - Epoch [103/200], Loss: 0.0107\n",
      "Validation - Epoch [103/200], Loss: 0.0098\n",
      "Training - Epoch [104/200], Loss: 0.0104\n",
      "Validation - Epoch [104/200], Loss: 0.0095\n",
      "Training - Epoch [105/200], Loss: 0.0110\n",
      "Validation - Epoch [105/200], Loss: 0.0099\n",
      "Training - Epoch [106/200], Loss: 0.0105\n",
      "Validation - Epoch [106/200], Loss: 0.0096\n",
      "Training - Epoch [107/200], Loss: 0.0106\n",
      "Validation - Epoch [107/200], Loss: 0.0092\n",
      "Training - Epoch [108/200], Loss: 0.0104\n",
      "Validation - Epoch [108/200], Loss: 0.0112\n",
      "Training - Epoch [109/200], Loss: 0.0104\n",
      "Validation - Epoch [109/200], Loss: 0.0092\n",
      "Training - Epoch [110/200], Loss: 0.0108\n",
      "Validation - Epoch [110/200], Loss: 0.0119\n",
      "Training - Epoch [111/200], Loss: 0.0110\n",
      "Validation - Epoch [111/200], Loss: 0.0107\n",
      "Training - Epoch [112/200], Loss: 0.0108\n",
      "Validation - Epoch [112/200], Loss: 0.0096\n",
      "Training - Epoch [113/200], Loss: 0.0104\n",
      "Validation - Epoch [113/200], Loss: 0.0094\n",
      "Training - Epoch [114/200], Loss: 0.0103\n",
      "Validation - Epoch [114/200], Loss: 0.0096\n",
      "Training - Epoch [115/200], Loss: 0.0104\n",
      "Validation - Epoch [115/200], Loss: 0.0100\n",
      "Training - Epoch [116/200], Loss: 0.0105\n",
      "Validation - Epoch [116/200], Loss: 0.0095\n",
      "Training - Epoch [117/200], Loss: 0.0107\n",
      "Validation - Epoch [117/200], Loss: 0.0096\n",
      "Training - Epoch [118/200], Loss: 0.0103\n",
      "Validation - Epoch [118/200], Loss: 0.0092\n",
      "Training - Epoch [119/200], Loss: 0.0104\n",
      "Validation - Epoch [119/200], Loss: 0.0096\n",
      "Training - Epoch [120/200], Loss: 0.0107\n",
      "Validation - Epoch [120/200], Loss: 0.0094\n",
      "Training - Epoch [121/200], Loss: 0.0105\n",
      "Validation - Epoch [121/200], Loss: 0.0098\n",
      "Training - Epoch [122/200], Loss: 0.0105\n",
      "Validation - Epoch [122/200], Loss: 0.0092\n",
      "Training - Epoch [123/200], Loss: 0.0104\n",
      "Validation - Epoch [123/200], Loss: 0.0098\n",
      "Training - Epoch [124/200], Loss: 0.0109\n",
      "Validation - Epoch [124/200], Loss: 0.0093\n",
      "Training - Epoch [125/200], Loss: 0.0105\n",
      "Validation - Epoch [125/200], Loss: 0.0094\n",
      "Training - Epoch [126/200], Loss: 0.0103\n",
      "Validation - Epoch [126/200], Loss: 0.0117\n",
      "Training - Epoch [127/200], Loss: 0.0109\n",
      "Validation - Epoch [127/200], Loss: 0.0094\n",
      "Training - Epoch [128/200], Loss: 0.0104\n",
      "Validation - Epoch [128/200], Loss: 0.0098\n",
      "Training - Epoch [129/200], Loss: 0.0104\n",
      "Validation - Epoch [129/200], Loss: 0.0092\n",
      "Training - Epoch [130/200], Loss: 0.0104\n",
      "Validation - Epoch [130/200], Loss: 0.0094\n",
      "Training - Epoch [131/200], Loss: 0.0106\n",
      "Validation - Epoch [131/200], Loss: 0.0097\n",
      "Training - Epoch [132/200], Loss: 0.0103\n",
      "Validation - Epoch [132/200], Loss: 0.0104\n",
      "Training - Epoch [133/200], Loss: 0.0105\n",
      "Validation - Epoch [133/200], Loss: 0.0101\n",
      "Training - Epoch [134/200], Loss: 0.0107\n",
      "Validation - Epoch [134/200], Loss: 0.0126\n",
      "Training - Epoch [135/200], Loss: 0.0105\n",
      "Validation - Epoch [135/200], Loss: 0.0092\n",
      "Training - Epoch [136/200], Loss: 0.0104\n",
      "Validation - Epoch [136/200], Loss: 0.0097\n",
      "Training - Epoch [137/200], Loss: 0.0102\n",
      "Validation - Epoch [137/200], Loss: 0.0092\n",
      "Training - Epoch [138/200], Loss: 0.0105\n",
      "Validation - Epoch [138/200], Loss: 0.0093\n",
      "Training - Epoch [139/200], Loss: 0.0113\n",
      "Validation - Epoch [139/200], Loss: 0.0095\n",
      "Training - Epoch [140/200], Loss: 0.0104\n",
      "Validation - Epoch [140/200], Loss: 0.0093\n",
      "Training - Epoch [141/200], Loss: 0.0102\n",
      "Validation - Epoch [141/200], Loss: 0.0091\n",
      "Training - Epoch [142/200], Loss: 0.0102\n",
      "Validation - Epoch [142/200], Loss: 0.0098\n",
      "Training - Epoch [143/200], Loss: 0.0104\n",
      "Validation - Epoch [143/200], Loss: 0.0096\n",
      "Training - Epoch [144/200], Loss: 0.0105\n",
      "Validation - Epoch [144/200], Loss: 0.0093\n",
      "Training - Epoch [145/200], Loss: 0.0103\n",
      "Validation - Epoch [145/200], Loss: 0.0093\n",
      "Training - Epoch [146/200], Loss: 0.0103\n",
      "Validation - Epoch [146/200], Loss: 0.0094\n",
      "Training - Epoch [147/200], Loss: 0.0108\n",
      "Validation - Epoch [147/200], Loss: 0.0093\n",
      "Training - Epoch [148/200], Loss: 0.0105\n",
      "Validation - Epoch [148/200], Loss: 0.0093\n",
      "Training - Epoch [149/200], Loss: 0.0104\n",
      "Validation - Epoch [149/200], Loss: 0.0095\n",
      "Training - Epoch [150/200], Loss: 0.0103\n",
      "Validation - Epoch [150/200], Loss: 0.0102\n",
      "Training - Epoch [151/200], Loss: 0.0104\n",
      "Validation - Epoch [151/200], Loss: 0.0114\n",
      "Training - Epoch [152/200], Loss: 0.0103\n",
      "Validation - Epoch [152/200], Loss: 0.0098\n",
      "Training - Epoch [153/200], Loss: 0.0103\n",
      "Validation - Epoch [153/200], Loss: 0.0094\n",
      "Training - Epoch [154/200], Loss: 0.0104\n",
      "Validation - Epoch [154/200], Loss: 0.0096\n",
      "Training - Epoch [155/200], Loss: 0.0108\n",
      "Validation - Epoch [155/200], Loss: 0.0093\n",
      "Training - Epoch [156/200], Loss: 0.0104\n",
      "Validation - Epoch [156/200], Loss: 0.0091\n",
      "Training - Epoch [157/200], Loss: 0.0102\n",
      "Validation - Epoch [157/200], Loss: 0.0094\n",
      "Training - Epoch [158/200], Loss: 0.0102\n",
      "Validation - Epoch [158/200], Loss: 0.0099\n",
      "Training - Epoch [159/200], Loss: 0.0106\n",
      "Validation - Epoch [159/200], Loss: 0.0150\n",
      "Training - Epoch [160/200], Loss: 0.0108\n",
      "Validation - Epoch [160/200], Loss: 0.0095\n",
      "Training - Epoch [161/200], Loss: 0.0102\n",
      "Validation - Epoch [161/200], Loss: 0.0093\n",
      "Training - Epoch [162/200], Loss: 0.0104\n",
      "Validation - Epoch [162/200], Loss: 0.0104\n",
      "Training - Epoch [163/200], Loss: 0.0103\n",
      "Validation - Epoch [163/200], Loss: 0.0099\n",
      "Training - Epoch [164/200], Loss: 0.0105\n",
      "Validation - Epoch [164/200], Loss: 0.0107\n",
      "Training - Epoch [165/200], Loss: 0.0103\n",
      "Validation - Epoch [165/200], Loss: 0.0097\n",
      "Training - Epoch [166/200], Loss: 0.0103\n",
      "Validation - Epoch [166/200], Loss: 0.0098\n",
      "Training - Epoch [167/200], Loss: 0.0103\n",
      "Validation - Epoch [167/200], Loss: 0.0106\n",
      "Training - Epoch [168/200], Loss: 0.0107\n",
      "Validation - Epoch [168/200], Loss: 0.0100\n",
      "Training - Epoch [169/200], Loss: 0.0103\n",
      "Validation - Epoch [169/200], Loss: 0.0095\n",
      "Training - Epoch [170/200], Loss: 0.0102\n",
      "Validation - Epoch [170/200], Loss: 0.0092\n",
      "Training - Epoch [171/200], Loss: 0.0108\n",
      "Validation - Epoch [171/200], Loss: 0.0096\n",
      "Training - Epoch [172/200], Loss: 0.0104\n",
      "Validation - Epoch [172/200], Loss: 0.0100\n",
      "Training - Epoch [173/200], Loss: 0.0101\n",
      "Validation - Epoch [173/200], Loss: 0.0097\n",
      "Training - Epoch [174/200], Loss: 0.0101\n",
      "Validation - Epoch [174/200], Loss: 0.0093\n",
      "Training - Epoch [175/200], Loss: 0.0106\n",
      "Validation - Epoch [175/200], Loss: 0.0099\n",
      "Training - Epoch [176/200], Loss: 0.0106\n",
      "Validation - Epoch [176/200], Loss: 0.0094\n",
      "Training - Epoch [177/200], Loss: 0.0105\n",
      "Validation - Epoch [177/200], Loss: 0.0092\n",
      "Training - Epoch [178/200], Loss: 0.0102\n",
      "Validation - Epoch [178/200], Loss: 0.0091\n",
      "Training - Epoch [179/200], Loss: 0.0104\n",
      "Validation - Epoch [179/200], Loss: 0.0094\n",
      "Training - Epoch [180/200], Loss: 0.0103\n",
      "Validation - Epoch [180/200], Loss: 0.0094\n",
      "Training - Epoch [181/200], Loss: 0.0101\n",
      "Validation - Epoch [181/200], Loss: 0.0093\n",
      "Training - Epoch [182/200], Loss: 0.0101\n",
      "Validation - Epoch [182/200], Loss: 0.0094\n",
      "Training - Epoch [183/200], Loss: 0.0103\n",
      "Validation - Epoch [183/200], Loss: 0.0097\n",
      "Training - Epoch [184/200], Loss: 0.0105\n",
      "Validation - Epoch [184/200], Loss: 0.0107\n",
      "Training - Epoch [185/200], Loss: 0.0105\n",
      "Validation - Epoch [185/200], Loss: 0.0094\n",
      "Training - Epoch [186/200], Loss: 0.0107\n",
      "Validation - Epoch [186/200], Loss: 0.0093\n",
      "Training - Epoch [187/200], Loss: 0.0108\n",
      "Validation - Epoch [187/200], Loss: 0.0100\n",
      "Training - Epoch [188/200], Loss: 0.0106\n",
      "Validation - Epoch [188/200], Loss: 0.0097\n",
      "Training - Epoch [189/200], Loss: 0.0101\n",
      "Validation - Epoch [189/200], Loss: 0.0092\n",
      "Training - Epoch [190/200], Loss: 0.0101\n",
      "Validation - Epoch [190/200], Loss: 0.0093\n",
      "Training - Epoch [191/200], Loss: 0.0101\n",
      "Validation - Epoch [191/200], Loss: 0.0095\n",
      "Training - Epoch [192/200], Loss: 0.0104\n",
      "Validation - Epoch [192/200], Loss: 0.0098\n",
      "Training - Epoch [193/200], Loss: 0.0104\n",
      "Validation - Epoch [193/200], Loss: 0.0098\n",
      "Training - Epoch [194/200], Loss: 0.0102\n",
      "Validation - Epoch [194/200], Loss: 0.0091\n",
      "Training - Epoch [195/200], Loss: 0.0101\n",
      "Validation - Epoch [195/200], Loss: 0.0124\n",
      "Training - Epoch [196/200], Loss: 0.0106\n",
      "Validation - Epoch [196/200], Loss: 0.0101\n",
      "Training - Epoch [197/200], Loss: 0.0104\n",
      "Validation - Epoch [197/200], Loss: 0.0092\n",
      "Training - Epoch [198/200], Loss: 0.0104\n",
      "Validation - Epoch [198/200], Loss: 0.0094\n",
      "Training - Epoch [199/200], Loss: 0.0101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch [199/200], Loss: 0.0099\n",
      "Training - Epoch [200/200], Loss: 0.0102\n",
      "Validation - Epoch [200/200], Loss: 0.0106\n"
     ]
    }
   ],
   "source": [
    "# Transformer Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, hidden_dim, num_layers, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.squeeze(1)\n",
    "        x = self.fc(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.tensor(features.values, dtype=torch.float32) \n",
    "        self.targets = torch.tensor(targets.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = X_train.shape[1]  # Dimension of input features\n",
    "num_heads = 2  # Number of attention heads = 2\n",
    "hidden_dim = 200  # Hidden layers of the model = 200\n",
    "num_layers = 2  # Number of transformer layers = 2\n",
    "dropout = 0.1  # Dropout probability = 0.1\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "model = TransformerModel(input_dim=input_dim, num_heads=num_heads, hidden_dim=hidden_dim,\n",
    "                          num_layers=num_layers, dropout=dropout)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression task\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Optimizer used is Adam and learning rate is 0.001\n",
    "\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(inputs)\n",
    "    average_loss = total_loss / len(train_dataset)\n",
    "    print(f'Training - Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for inputs, labels in test_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * len(inputs)\n",
    "        average_loss = total_loss / len(test_dataset)\n",
    "        print(f'Validation - Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        # Stored true labels and predictions\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(outputs.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73045a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        # Stored true labels and predictions\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(outputs.numpy())\n",
    "\n",
    "# Converted y_true and y_pred to numpy arrays\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Computed confusion matrix\n",
    "cm = confusion_matrix(np.round(y_true), np.round(y_pred))\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7323b87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.010605556\n",
      "Mean Absolute Error: 0.06885473\n",
      "Root Mean Squared Error: 0.10298328\n",
      "R-squared Score: 0.867745617021991\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Computed Mean Squared Error\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "# Computed Mean Absolute Error\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# Computed Root Mean Squared Error\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Computed R2-Score\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "104a1dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alarm triggered for 11 consecutive faults on 2019-05-29.\n",
      "Alarm triggered for 8 consecutive faults on 2019-04-12.\n",
      "Alarm triggered for 7 consecutive faults on 2019-04-04.\n",
      "Alarm triggered for 7 consecutive faults on 2019-04-07.\n",
      "Alarm triggered for 7 consecutive faults on 2019-05-04.\n",
      "Alarm triggered for 6 consecutive faults on 2019-05-18.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-22.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-21.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-20.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-26.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-28.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-02.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-23.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-24.\n",
      "Alarm triggered for 6 consecutive faults on 2019-05-27.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-09.\n",
      "Alarm triggered for 6 consecutive faults on 2019-06-02.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-10.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-06.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-26.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-30.\n",
      "Alarm triggered for 5 consecutive faults on 2019-06-04.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-30.\n",
      "Alarm triggered for 5 consecutive faults on 2019-06-05.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-14.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-17.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-13.\n",
      "Alarm triggered for 4 consecutive faults on 2019-05-20.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-03.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-05.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-10.\n",
      "Alarm triggered for 4 consecutive faults on 2019-05-24.\n",
      "Alarm triggered for 4 consecutive faults on 2019-05-23.\n",
      "Alarm triggered for 4 consecutive faults on 2019-05-21.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-19.\n",
      "Alarm triggered for 4 consecutive faults on 2019-05-19.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-01.\n",
      "Alarm triggered for 4 consecutive faults on 2019-05-08.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-16.\n"
     ]
    }
   ],
   "source": [
    "# Function to check for four consecutive faults in a day and trigger alarms\n",
    "def check_consecutive_faults(fault_indices, df, window=3):\n",
    "    fault_timestamps = df.index[fault_indices]\n",
    "\n",
    "    grouped_by_day = fault_timestamps.to_series().dt.date\n",
    "\n",
    "    # Checked if there are three or more consecutive faults within the same day\n",
    "    daily_fault_count = grouped_by_day.value_counts()\n",
    "    for date, count in daily_fault_count.items():\n",
    "        if count >= window:\n",
    "            print(f\"Alarm triggered for {count} consecutive faults on {date}.\")\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_ac_power = model(X_test_tensor)  # Model predictions\n",
    "    actual_ac_power = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "    # Absolute residuals between predicted and actual AC power\n",
    "    residuals = torch.abs(predicted_ac_power - actual_ac_power)\n",
    "\n",
    "# Calculated the standard deviation for setting the fault threshold\n",
    "sigma = torch.std(residuals).item()\n",
    "threshold = 2 * sigma  # Set the threshold as 2 * sigma\n",
    "\n",
    "anomalies = (residuals > threshold).int()\n",
    "\n",
    "fault_indices = torch.nonzero(anomalies).squeeze().tolist()\n",
    "\n",
    "check_consecutive_faults(fault_indices, df, window=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a05332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
