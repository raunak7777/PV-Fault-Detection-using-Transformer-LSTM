{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a3793ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score, classification_report, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "543836a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\My PC\\Desktop\\Solar PV Fault Research\\IO_DATA_LABELED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a69a7ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Inv-5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba01140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Inv</th>\n",
       "      <th>AC_Real_Power</th>\n",
       "      <th>AC_Current</th>\n",
       "      <th>DC_Power</th>\n",
       "      <th>DC_Current</th>\n",
       "      <th>Tilt_Irradiation_1</th>\n",
       "      <th>Temp_Ambient_1</th>\n",
       "      <th>Temp_Module_1</th>\n",
       "      <th>Wind_Speed_1</th>\n",
       "      <th>Hor_Irradiation_1</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>05:45:00</td>\n",
       "      <td>Inv-5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>Inv-5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>06:15:00</td>\n",
       "      <td>Inv-5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.639</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>06:30:00</td>\n",
       "      <td>Inv-5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.5</td>\n",
       "      <td>20.7</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>13.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>06:45:00</td>\n",
       "      <td>Inv-5</td>\n",
       "      <td>1.26</td>\n",
       "      <td>9.27</td>\n",
       "      <td>1.56</td>\n",
       "      <td>3.11</td>\n",
       "      <td>30.1</td>\n",
       "      <td>21.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.500</td>\n",
       "      <td>30.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15636</th>\n",
       "      <td>15636</td>\n",
       "      <td>15636</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>18:30:00</td>\n",
       "      <td>Inv-5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15637</th>\n",
       "      <td>15637</td>\n",
       "      <td>15637</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>18:45:00</td>\n",
       "      <td>Inv-5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15638</th>\n",
       "      <td>15638</td>\n",
       "      <td>15638</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>Inv-5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15639</th>\n",
       "      <td>15639</td>\n",
       "      <td>15639</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>19:15:00</td>\n",
       "      <td>Inv-5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15640</th>\n",
       "      <td>15640</td>\n",
       "      <td>15640</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>19:30:00</td>\n",
       "      <td>Inv-5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15641 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0        Date      Time    Inv  AC_Real_Power  \\\n",
       "0                 0           0  2019-04-04  05:45:00  Inv-5           0.00   \n",
       "1                 1           1  2019-04-04  06:00:00  Inv-5           0.00   \n",
       "2                 2           2  2019-04-04  06:15:00  Inv-5           0.00   \n",
       "3                 3           3  2019-04-04  06:30:00  Inv-5           0.00   \n",
       "4                 4           4  2019-04-04  06:45:00  Inv-5           1.26   \n",
       "...             ...         ...         ...       ...    ...            ...   \n",
       "15636         15636       15636  2020-04-01  18:30:00  Inv-5           0.00   \n",
       "15637         15637       15637  2020-04-01  18:45:00  Inv-5           0.00   \n",
       "15638         15638       15638  2020-04-01  19:00:00  Inv-5           0.00   \n",
       "15639         15639       15639  2020-04-01  19:15:00  Inv-5           0.00   \n",
       "15640         15640       15640  2020-04-01  19:30:00  Inv-5           0.00   \n",
       "\n",
       "       AC_Current  DC_Power  DC_Current  Tilt_Irradiation_1  Temp_Ambient_1  \\\n",
       "0            0.00      0.00        1.26                 0.0            20.0   \n",
       "1            0.00      0.00        0.74                 0.0            19.6   \n",
       "2            0.00      0.00        0.00                 0.0            19.6   \n",
       "3            0.00      0.00        0.00                12.5            20.7   \n",
       "4            9.27      1.56        3.11                30.1            21.3   \n",
       "...           ...       ...         ...                 ...             ...   \n",
       "15636        0.00      0.00        0.00                 0.0            15.9   \n",
       "15637        0.00      0.00        0.91                 0.0            15.1   \n",
       "15638        0.00      0.00        3.14                 0.0            14.2   \n",
       "15639        0.00      0.00        3.28                 0.0            14.3   \n",
       "15640        0.00      0.00        3.36                 0.0            14.2   \n",
       "\n",
       "       Temp_Module_1  Wind_Speed_1  Hor_Irradiation_1  Operation  \n",
       "0               21.7         0.500                0.0          1  \n",
       "1               21.6         0.500                0.0          1  \n",
       "2               21.5         0.639                2.6          1  \n",
       "3               22.1         0.500               13.4          1  \n",
       "4               23.3         0.500               30.2          1  \n",
       "...              ...           ...                ...        ...  \n",
       "15636           17.5         0.500                0.5          1  \n",
       "15637           16.7         0.500                0.5          1  \n",
       "15638           16.1         0.500                0.5          1  \n",
       "15639           15.9         0.500                0.5          1  \n",
       "15640           15.6         0.500                0.5          1  \n",
       "\n",
       "[15641 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3721a9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15641 entries, 0 to 15640\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Unnamed: 0.1        15641 non-null  int64  \n",
      " 1   Unnamed: 0          15641 non-null  int64  \n",
      " 2   Date                15641 non-null  object \n",
      " 3   Time                15641 non-null  object \n",
      " 4   Inv                 15641 non-null  object \n",
      " 5   AC_Real_Power       15639 non-null  float64\n",
      " 6   AC_Current          15639 non-null  float64\n",
      " 7   DC_Power            15639 non-null  float64\n",
      " 8   DC_Current          15639 non-null  float64\n",
      " 9   Tilt_Irradiation_1  15641 non-null  float64\n",
      " 10  Temp_Ambient_1      15641 non-null  float64\n",
      " 11  Temp_Module_1       15641 non-null  float64\n",
      " 12  Wind_Speed_1        15641 non-null  float64\n",
      " 13  Hor_Irradiation_1   15641 non-null  float64\n",
      " 14  Operation           15641 non-null  int64  \n",
      "dtypes: float64(9), int64(3), object(3)\n",
      "memory usage: 1.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Inv</th>\n",
       "      <th>AC_Real_Power</th>\n",
       "      <th>AC_Current</th>\n",
       "      <th>DC_Power</th>\n",
       "      <th>DC_Current</th>\n",
       "      <th>Tilt_Irradiation_1</th>\n",
       "      <th>Temp_Ambient_1</th>\n",
       "      <th>Temp_Module_1</th>\n",
       "      <th>Wind_Speed_1</th>\n",
       "      <th>Hor_Irradiation_1</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>05:45:00</td>\n",
       "      <td>Inv-5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>Inv-5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>06:15:00</td>\n",
       "      <td>Inv-5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.639</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>06:30:00</td>\n",
       "      <td>Inv-5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.5</td>\n",
       "      <td>20.7</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>13.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>06:45:00</td>\n",
       "      <td>Inv-5</td>\n",
       "      <td>1.26</td>\n",
       "      <td>9.27</td>\n",
       "      <td>1.56</td>\n",
       "      <td>3.11</td>\n",
       "      <td>30.1</td>\n",
       "      <td>21.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.500</td>\n",
       "      <td>30.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0        Date      Time    Inv  AC_Real_Power  \\\n",
       "0             0           0  2019-04-04  05:45:00  Inv-5           0.00   \n",
       "1             1           1  2019-04-04  06:00:00  Inv-5           0.00   \n",
       "2             2           2  2019-04-04  06:15:00  Inv-5           0.00   \n",
       "3             3           3  2019-04-04  06:30:00  Inv-5           0.00   \n",
       "4             4           4  2019-04-04  06:45:00  Inv-5           1.26   \n",
       "\n",
       "   AC_Current  DC_Power  DC_Current  Tilt_Irradiation_1  Temp_Ambient_1  \\\n",
       "0        0.00      0.00        1.26                 0.0            20.0   \n",
       "1        0.00      0.00        0.74                 0.0            19.6   \n",
       "2        0.00      0.00        0.00                 0.0            19.6   \n",
       "3        0.00      0.00        0.00                12.5            20.7   \n",
       "4        9.27      1.56        3.11                30.1            21.3   \n",
       "\n",
       "   Temp_Module_1  Wind_Speed_1  Hor_Irradiation_1  Operation  \n",
       "0           21.7         0.500                0.0          1  \n",
       "1           21.6         0.500                0.0          1  \n",
       "2           21.5         0.639                2.6          1  \n",
       "3           22.1         0.500               13.4          1  \n",
       "4           23.3         0.500               30.2          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.info(),df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aaf63a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 15641\n",
      "Number of columns: 15\n"
     ]
    }
   ],
   "source": [
    "num_rows, num_columns = df.shape\n",
    "\n",
    "print(\"Number of rows:\", num_rows)\n",
    "print(\"Number of columns:\", num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06927643",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc73cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4caaa604",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('DateTime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21c56cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Date','Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9791ae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = pd.Timestamp(\"07:00:00\")\n",
    "end_time = pd.Timestamp(\"18:30:00\")\n",
    "\n",
    "# Filtering the data to retain only the rows within the operational hours\n",
    "df = df[(df.index.time >= pd.to_datetime('7:00:00').time()) & (df.index.time <= pd.to_datetime('18:30:00').time())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbfd8cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inv</th>\n",
       "      <th>AC_Real_Power</th>\n",
       "      <th>AC_Current</th>\n",
       "      <th>DC_Power</th>\n",
       "      <th>DC_Current</th>\n",
       "      <th>Tilt_Irradiation_1</th>\n",
       "      <th>Temp_Ambient_1</th>\n",
       "      <th>Temp_Module_1</th>\n",
       "      <th>Wind_Speed_1</th>\n",
       "      <th>Hor_Irradiation_1</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-04 07:00:00</th>\n",
       "      <td>Inv-5</td>\n",
       "      <td>12.58</td>\n",
       "      <td>24.49</td>\n",
       "      <td>15.31</td>\n",
       "      <td>26.44</td>\n",
       "      <td>48.3</td>\n",
       "      <td>23.1</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>49.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-04 07:15:00</th>\n",
       "      <td>Inv-5</td>\n",
       "      <td>28.84</td>\n",
       "      <td>52.58</td>\n",
       "      <td>34.04</td>\n",
       "      <td>57.61</td>\n",
       "      <td>65.4</td>\n",
       "      <td>25.3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>86.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-04 07:30:00</th>\n",
       "      <td>Inv-5</td>\n",
       "      <td>52.09</td>\n",
       "      <td>95.65</td>\n",
       "      <td>59.00</td>\n",
       "      <td>100.41</td>\n",
       "      <td>81.4</td>\n",
       "      <td>28.2</td>\n",
       "      <td>28.3</td>\n",
       "      <td>0.614</td>\n",
       "      <td>130.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-04 07:45:00</th>\n",
       "      <td>Inv-5</td>\n",
       "      <td>77.93</td>\n",
       "      <td>142.57</td>\n",
       "      <td>85.37</td>\n",
       "      <td>146.69</td>\n",
       "      <td>101.6</td>\n",
       "      <td>30.1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.728</td>\n",
       "      <td>180.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-04 08:00:00</th>\n",
       "      <td>Inv-5</td>\n",
       "      <td>109.67</td>\n",
       "      <td>199.79</td>\n",
       "      <td>118.50</td>\n",
       "      <td>206.12</td>\n",
       "      <td>308.8</td>\n",
       "      <td>31.5</td>\n",
       "      <td>35.4</td>\n",
       "      <td>0.827</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Inv  AC_Real_Power  AC_Current  DC_Power  DC_Current  \\\n",
       "DateTime                                                                      \n",
       "2019-04-04 07:00:00  Inv-5          12.58       24.49     15.31       26.44   \n",
       "2019-04-04 07:15:00  Inv-5          28.84       52.58     34.04       57.61   \n",
       "2019-04-04 07:30:00  Inv-5          52.09       95.65     59.00      100.41   \n",
       "2019-04-04 07:45:00  Inv-5          77.93      142.57     85.37      146.69   \n",
       "2019-04-04 08:00:00  Inv-5         109.67      199.79    118.50      206.12   \n",
       "\n",
       "                     Tilt_Irradiation_1  Temp_Ambient_1  Temp_Module_1  \\\n",
       "DateTime                                                                 \n",
       "2019-04-04 07:00:00                48.3            23.1           25.2   \n",
       "2019-04-04 07:15:00                65.4            25.3           27.0   \n",
       "2019-04-04 07:30:00                81.4            28.2           28.3   \n",
       "2019-04-04 07:45:00               101.6            30.1           30.0   \n",
       "2019-04-04 08:00:00               308.8            31.5           35.4   \n",
       "\n",
       "                     Wind_Speed_1  Hor_Irradiation_1  Operation  \n",
       "DateTime                                                         \n",
       "2019-04-04 07:00:00         0.500               49.6          1  \n",
       "2019-04-04 07:15:00         0.500               86.6          1  \n",
       "2019-04-04 07:30:00         0.614              130.6          1  \n",
       "2019-04-04 07:45:00         0.728              180.6          1  \n",
       "2019-04-04 08:00:00         0.827              236.0          1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db3e9c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inv                   0\n",
      "AC_Real_Power         0\n",
      "AC_Current            0\n",
      "DC_Power              0\n",
      "DC_Current            0\n",
      "Tilt_Irradiation_1    0\n",
      "Temp_Ambient_1        0\n",
      "Temp_Module_1         0\n",
      "Wind_Speed_1          0\n",
      "Hor_Irradiation_1     0\n",
      "Operation             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_data = df.isnull().sum()\n",
    "print(missing_data)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc0970ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "operational_data = df\n",
    "numerical_features = ['AC_Real_Power','Tilt_Irradiation_1', 'Temp_Ambient_1', 'Hor_Irradiation_1']\n",
    "\n",
    "# Normalization of the features\n",
    "operational_data[numerical_features] = scaler.fit_transform(operational_data[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4729753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = operational_data[['Tilt_Irradiation_1', 'Temp_Ambient_1', 'Hor_Irradiation_1']]\n",
    "y = operational_data['AC_Real_Power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b944406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch [1/200], Loss: 0.1223\n",
      "Validation - Epoch [1/200], Loss: 0.0304\n",
      "Training - Epoch [2/200], Loss: 0.0306\n",
      "Validation - Epoch [2/200], Loss: 0.0279\n",
      "Training - Epoch [3/200], Loss: 0.0275\n",
      "Validation - Epoch [3/200], Loss: 0.0249\n",
      "Training - Epoch [4/200], Loss: 0.0281\n",
      "Validation - Epoch [4/200], Loss: 0.0248\n",
      "Training - Epoch [5/200], Loss: 0.0275\n",
      "Validation - Epoch [5/200], Loss: 0.0254\n",
      "Training - Epoch [6/200], Loss: 0.0266\n",
      "Validation - Epoch [6/200], Loss: 0.0245\n",
      "Training - Epoch [7/200], Loss: 0.0265\n",
      "Validation - Epoch [7/200], Loss: 0.0257\n",
      "Training - Epoch [8/200], Loss: 0.0264\n",
      "Validation - Epoch [8/200], Loss: 0.0284\n",
      "Training - Epoch [9/200], Loss: 0.0264\n",
      "Validation - Epoch [9/200], Loss: 0.0294\n",
      "Training - Epoch [10/200], Loss: 0.0259\n",
      "Validation - Epoch [10/200], Loss: 0.0258\n",
      "Training - Epoch [11/200], Loss: 0.0261\n",
      "Validation - Epoch [11/200], Loss: 0.0244\n",
      "Training - Epoch [12/200], Loss: 0.0257\n",
      "Validation - Epoch [12/200], Loss: 0.0292\n",
      "Training - Epoch [13/200], Loss: 0.0259\n",
      "Validation - Epoch [13/200], Loss: 0.0253\n",
      "Training - Epoch [14/200], Loss: 0.0257\n",
      "Validation - Epoch [14/200], Loss: 0.0293\n",
      "Training - Epoch [15/200], Loss: 0.0256\n",
      "Validation - Epoch [15/200], Loss: 0.0250\n",
      "Training - Epoch [16/200], Loss: 0.0255\n",
      "Validation - Epoch [16/200], Loss: 0.0291\n",
      "Training - Epoch [17/200], Loss: 0.0252\n",
      "Validation - Epoch [17/200], Loss: 0.0240\n",
      "Training - Epoch [18/200], Loss: 0.0258\n",
      "Validation - Epoch [18/200], Loss: 0.0250\n",
      "Training - Epoch [19/200], Loss: 0.0254\n",
      "Validation - Epoch [19/200], Loss: 0.0244\n",
      "Training - Epoch [20/200], Loss: 0.0256\n",
      "Validation - Epoch [20/200], Loss: 0.0256\n",
      "Training - Epoch [21/200], Loss: 0.0255\n",
      "Validation - Epoch [21/200], Loss: 0.0245\n",
      "Training - Epoch [22/200], Loss: 0.0256\n",
      "Validation - Epoch [22/200], Loss: 0.0262\n",
      "Training - Epoch [23/200], Loss: 0.0260\n",
      "Validation - Epoch [23/200], Loss: 0.0257\n",
      "Training - Epoch [24/200], Loss: 0.0257\n",
      "Validation - Epoch [24/200], Loss: 0.0297\n",
      "Training - Epoch [25/200], Loss: 0.0258\n",
      "Validation - Epoch [25/200], Loss: 0.0271\n",
      "Training - Epoch [26/200], Loss: 0.0253\n",
      "Validation - Epoch [26/200], Loss: 0.0261\n",
      "Training - Epoch [27/200], Loss: 0.0257\n",
      "Validation - Epoch [27/200], Loss: 0.0247\n",
      "Training - Epoch [28/200], Loss: 0.0254\n",
      "Validation - Epoch [28/200], Loss: 0.0265\n",
      "Training - Epoch [29/200], Loss: 0.0254\n",
      "Validation - Epoch [29/200], Loss: 0.0249\n",
      "Training - Epoch [30/200], Loss: 0.0257\n",
      "Validation - Epoch [30/200], Loss: 0.0245\n",
      "Training - Epoch [31/200], Loss: 0.0252\n",
      "Validation - Epoch [31/200], Loss: 0.0266\n",
      "Training - Epoch [32/200], Loss: 0.0279\n",
      "Validation - Epoch [32/200], Loss: 0.0319\n",
      "Training - Epoch [33/200], Loss: 0.0260\n",
      "Validation - Epoch [33/200], Loss: 0.0267\n",
      "Training - Epoch [34/200], Loss: 0.0253\n",
      "Validation - Epoch [34/200], Loss: 0.0252\n",
      "Training - Epoch [35/200], Loss: 0.0250\n",
      "Validation - Epoch [35/200], Loss: 0.0355\n",
      "Training - Epoch [36/200], Loss: 0.0251\n",
      "Validation - Epoch [36/200], Loss: 0.0269\n",
      "Training - Epoch [37/200], Loss: 0.0255\n",
      "Validation - Epoch [37/200], Loss: 0.0252\n",
      "Training - Epoch [38/200], Loss: 0.0253\n",
      "Validation - Epoch [38/200], Loss: 0.0269\n",
      "Training - Epoch [39/200], Loss: 0.0249\n",
      "Validation - Epoch [39/200], Loss: 0.0251\n",
      "Training - Epoch [40/200], Loss: 0.0249\n",
      "Validation - Epoch [40/200], Loss: 0.0243\n",
      "Training - Epoch [41/200], Loss: 0.0256\n",
      "Validation - Epoch [41/200], Loss: 0.0269\n",
      "Training - Epoch [42/200], Loss: 0.0252\n",
      "Validation - Epoch [42/200], Loss: 0.0268\n",
      "Training - Epoch [43/200], Loss: 0.0249\n",
      "Validation - Epoch [43/200], Loss: 0.0243\n",
      "Training - Epoch [44/200], Loss: 0.0247\n",
      "Validation - Epoch [44/200], Loss: 0.0264\n",
      "Training - Epoch [45/200], Loss: 0.0252\n",
      "Validation - Epoch [45/200], Loss: 0.0246\n",
      "Training - Epoch [46/200], Loss: 0.0251\n",
      "Validation - Epoch [46/200], Loss: 0.0252\n",
      "Training - Epoch [47/200], Loss: 0.0248\n",
      "Validation - Epoch [47/200], Loss: 0.0284\n",
      "Training - Epoch [48/200], Loss: 0.0247\n",
      "Validation - Epoch [48/200], Loss: 0.0278\n",
      "Training - Epoch [49/200], Loss: 0.0245\n",
      "Validation - Epoch [49/200], Loss: 0.0244\n",
      "Training - Epoch [50/200], Loss: 0.0247\n",
      "Validation - Epoch [50/200], Loss: 0.0261\n",
      "Training - Epoch [51/200], Loss: 0.0246\n",
      "Validation - Epoch [51/200], Loss: 0.0258\n",
      "Training - Epoch [52/200], Loss: 0.0246\n",
      "Validation - Epoch [52/200], Loss: 0.0250\n",
      "Training - Epoch [53/200], Loss: 0.0249\n",
      "Validation - Epoch [53/200], Loss: 0.0253\n",
      "Training - Epoch [54/200], Loss: 0.0253\n",
      "Validation - Epoch [54/200], Loss: 0.0239\n",
      "Training - Epoch [55/200], Loss: 0.0247\n",
      "Validation - Epoch [55/200], Loss: 0.0244\n",
      "Training - Epoch [56/200], Loss: 0.0254\n",
      "Validation - Epoch [56/200], Loss: 0.0254\n",
      "Training - Epoch [57/200], Loss: 0.0246\n",
      "Validation - Epoch [57/200], Loss: 0.0254\n",
      "Training - Epoch [58/200], Loss: 0.0249\n",
      "Validation - Epoch [58/200], Loss: 0.0239\n",
      "Training - Epoch [59/200], Loss: 0.0249\n",
      "Validation - Epoch [59/200], Loss: 0.0246\n",
      "Training - Epoch [60/200], Loss: 0.0245\n",
      "Validation - Epoch [60/200], Loss: 0.0257\n",
      "Training - Epoch [61/200], Loss: 0.0243\n",
      "Validation - Epoch [61/200], Loss: 0.0245\n",
      "Training - Epoch [62/200], Loss: 0.0247\n",
      "Validation - Epoch [62/200], Loss: 0.0277\n",
      "Training - Epoch [63/200], Loss: 0.0250\n",
      "Validation - Epoch [63/200], Loss: 0.0246\n",
      "Training - Epoch [64/200], Loss: 0.0245\n",
      "Validation - Epoch [64/200], Loss: 0.0242\n",
      "Training - Epoch [65/200], Loss: 0.0244\n",
      "Validation - Epoch [65/200], Loss: 0.0250\n",
      "Training - Epoch [66/200], Loss: 0.0245\n",
      "Validation - Epoch [66/200], Loss: 0.0256\n",
      "Training - Epoch [67/200], Loss: 0.0250\n",
      "Validation - Epoch [67/200], Loss: 0.0245\n",
      "Training - Epoch [68/200], Loss: 0.0248\n",
      "Validation - Epoch [68/200], Loss: 0.0263\n",
      "Training - Epoch [69/200], Loss: 0.0244\n",
      "Validation - Epoch [69/200], Loss: 0.0245\n",
      "Training - Epoch [70/200], Loss: 0.0246\n",
      "Validation - Epoch [70/200], Loss: 0.0297\n",
      "Training - Epoch [71/200], Loss: 0.0272\n",
      "Validation - Epoch [71/200], Loss: 0.0374\n",
      "Training - Epoch [72/200], Loss: 0.0310\n",
      "Validation - Epoch [72/200], Loss: 0.0260\n",
      "Training - Epoch [73/200], Loss: 0.0268\n",
      "Validation - Epoch [73/200], Loss: 0.0271\n",
      "Training - Epoch [74/200], Loss: 0.0266\n",
      "Validation - Epoch [74/200], Loss: 0.0251\n",
      "Training - Epoch [75/200], Loss: 0.0263\n",
      "Validation - Epoch [75/200], Loss: 0.0248\n",
      "Training - Epoch [76/200], Loss: 0.0266\n",
      "Validation - Epoch [76/200], Loss: 0.0253\n",
      "Training - Epoch [77/200], Loss: 0.0264\n",
      "Validation - Epoch [77/200], Loss: 0.0300\n",
      "Training - Epoch [78/200], Loss: 0.0263\n",
      "Validation - Epoch [78/200], Loss: 0.0265\n",
      "Training - Epoch [79/200], Loss: 0.0258\n",
      "Validation - Epoch [79/200], Loss: 0.0252\n",
      "Training - Epoch [80/200], Loss: 0.0256\n",
      "Validation - Epoch [80/200], Loss: 0.0302\n",
      "Training - Epoch [81/200], Loss: 0.0261\n",
      "Validation - Epoch [81/200], Loss: 0.0248\n",
      "Training - Epoch [82/200], Loss: 0.0275\n",
      "Validation - Epoch [82/200], Loss: 0.0279\n",
      "Training - Epoch [83/200], Loss: 0.0273\n",
      "Validation - Epoch [83/200], Loss: 0.0261\n",
      "Training - Epoch [84/200], Loss: 0.0259\n",
      "Validation - Epoch [84/200], Loss: 0.0244\n",
      "Training - Epoch [85/200], Loss: 0.0254\n",
      "Validation - Epoch [85/200], Loss: 0.0253\n",
      "Training - Epoch [86/200], Loss: 0.0259\n",
      "Validation - Epoch [86/200], Loss: 0.0251\n",
      "Training - Epoch [87/200], Loss: 0.0254\n",
      "Validation - Epoch [87/200], Loss: 0.0276\n",
      "Training - Epoch [88/200], Loss: 0.0253\n",
      "Validation - Epoch [88/200], Loss: 0.0261\n",
      "Training - Epoch [89/200], Loss: 0.0253\n",
      "Validation - Epoch [89/200], Loss: 0.0249\n",
      "Training - Epoch [90/200], Loss: 0.0248\n",
      "Validation - Epoch [90/200], Loss: 0.0253\n",
      "Training - Epoch [91/200], Loss: 0.0251\n",
      "Validation - Epoch [91/200], Loss: 0.0248\n",
      "Training - Epoch [92/200], Loss: 0.0251\n",
      "Validation - Epoch [92/200], Loss: 0.0256\n",
      "Training - Epoch [93/200], Loss: 0.0247\n",
      "Validation - Epoch [93/200], Loss: 0.0250\n",
      "Training - Epoch [94/200], Loss: 0.0246\n",
      "Validation - Epoch [94/200], Loss: 0.0251\n",
      "Training - Epoch [95/200], Loss: 0.0251\n",
      "Validation - Epoch [95/200], Loss: 0.0256\n",
      "Training - Epoch [96/200], Loss: 0.0252\n",
      "Validation - Epoch [96/200], Loss: 0.0246\n",
      "Training - Epoch [97/200], Loss: 0.0252\n",
      "Validation - Epoch [97/200], Loss: 0.0247\n",
      "Training - Epoch [98/200], Loss: 0.0248\n",
      "Validation - Epoch [98/200], Loss: 0.0247\n",
      "Training - Epoch [99/200], Loss: 0.0244\n",
      "Validation - Epoch [99/200], Loss: 0.0240\n",
      "Training - Epoch [100/200], Loss: 0.0242\n",
      "Validation - Epoch [100/200], Loss: 0.0255\n",
      "Training - Epoch [101/200], Loss: 0.0241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch [101/200], Loss: 0.0258\n",
      "Training - Epoch [102/200], Loss: 0.0243\n",
      "Validation - Epoch [102/200], Loss: 0.0239\n",
      "Training - Epoch [103/200], Loss: 0.0241\n",
      "Validation - Epoch [103/200], Loss: 0.0254\n",
      "Training - Epoch [104/200], Loss: 0.0243\n",
      "Validation - Epoch [104/200], Loss: 0.0269\n",
      "Training - Epoch [105/200], Loss: 0.0243\n",
      "Validation - Epoch [105/200], Loss: 0.0246\n",
      "Training - Epoch [106/200], Loss: 0.0240\n",
      "Validation - Epoch [106/200], Loss: 0.0246\n",
      "Training - Epoch [107/200], Loss: 0.0240\n",
      "Validation - Epoch [107/200], Loss: 0.0242\n",
      "Training - Epoch [108/200], Loss: 0.0259\n",
      "Validation - Epoch [108/200], Loss: 0.0247\n",
      "Training - Epoch [109/200], Loss: 0.0245\n",
      "Validation - Epoch [109/200], Loss: 0.0243\n",
      "Training - Epoch [110/200], Loss: 0.0240\n",
      "Validation - Epoch [110/200], Loss: 0.0240\n",
      "Training - Epoch [111/200], Loss: 0.0240\n",
      "Validation - Epoch [111/200], Loss: 0.0244\n",
      "Training - Epoch [112/200], Loss: 0.0240\n",
      "Validation - Epoch [112/200], Loss: 0.0240\n",
      "Training - Epoch [113/200], Loss: 0.0239\n",
      "Validation - Epoch [113/200], Loss: 0.0254\n",
      "Training - Epoch [114/200], Loss: 0.0242\n",
      "Validation - Epoch [114/200], Loss: 0.0246\n",
      "Training - Epoch [115/200], Loss: 0.0239\n",
      "Validation - Epoch [115/200], Loss: 0.0243\n",
      "Training - Epoch [116/200], Loss: 0.0242\n",
      "Validation - Epoch [116/200], Loss: 0.0255\n",
      "Training - Epoch [117/200], Loss: 0.0244\n",
      "Validation - Epoch [117/200], Loss: 0.0258\n",
      "Training - Epoch [118/200], Loss: 0.0239\n",
      "Validation - Epoch [118/200], Loss: 0.0242\n",
      "Training - Epoch [119/200], Loss: 0.0240\n",
      "Validation - Epoch [119/200], Loss: 0.0249\n",
      "Training - Epoch [120/200], Loss: 0.0237\n",
      "Validation - Epoch [120/200], Loss: 0.0237\n",
      "Training - Epoch [121/200], Loss: 0.0238\n",
      "Validation - Epoch [121/200], Loss: 0.0241\n",
      "Training - Epoch [122/200], Loss: 0.0241\n",
      "Validation - Epoch [122/200], Loss: 0.0275\n",
      "Training - Epoch [123/200], Loss: 0.0248\n",
      "Validation - Epoch [123/200], Loss: 0.0242\n",
      "Training - Epoch [124/200], Loss: 0.0243\n",
      "Validation - Epoch [124/200], Loss: 0.0237\n",
      "Training - Epoch [125/200], Loss: 0.0236\n",
      "Validation - Epoch [125/200], Loss: 0.0248\n",
      "Training - Epoch [126/200], Loss: 0.0254\n",
      "Validation - Epoch [126/200], Loss: 0.0266\n",
      "Training - Epoch [127/200], Loss: 0.0243\n",
      "Validation - Epoch [127/200], Loss: 0.0240\n",
      "Training - Epoch [128/200], Loss: 0.0244\n",
      "Validation - Epoch [128/200], Loss: 0.0241\n",
      "Training - Epoch [129/200], Loss: 0.0240\n",
      "Validation - Epoch [129/200], Loss: 0.0264\n",
      "Training - Epoch [130/200], Loss: 0.0239\n",
      "Validation - Epoch [130/200], Loss: 0.0253\n",
      "Training - Epoch [131/200], Loss: 0.0239\n",
      "Validation - Epoch [131/200], Loss: 0.0237\n",
      "Training - Epoch [132/200], Loss: 0.0238\n",
      "Validation - Epoch [132/200], Loss: 0.0253\n",
      "Training - Epoch [133/200], Loss: 0.0239\n",
      "Validation - Epoch [133/200], Loss: 0.0239\n",
      "Training - Epoch [134/200], Loss: 0.0238\n",
      "Validation - Epoch [134/200], Loss: 0.0240\n",
      "Training - Epoch [135/200], Loss: 0.0240\n",
      "Validation - Epoch [135/200], Loss: 0.0240\n",
      "Training - Epoch [136/200], Loss: 0.0239\n",
      "Validation - Epoch [136/200], Loss: 0.0240\n",
      "Training - Epoch [137/200], Loss: 0.0238\n",
      "Validation - Epoch [137/200], Loss: 0.0236\n",
      "Training - Epoch [138/200], Loss: 0.0238\n",
      "Validation - Epoch [138/200], Loss: 0.0244\n",
      "Training - Epoch [139/200], Loss: 0.0237\n",
      "Validation - Epoch [139/200], Loss: 0.0236\n",
      "Training - Epoch [140/200], Loss: 0.0236\n",
      "Validation - Epoch [140/200], Loss: 0.0237\n",
      "Training - Epoch [141/200], Loss: 0.0235\n",
      "Validation - Epoch [141/200], Loss: 0.0248\n",
      "Training - Epoch [142/200], Loss: 0.0236\n",
      "Validation - Epoch [142/200], Loss: 0.0235\n",
      "Training - Epoch [143/200], Loss: 0.0235\n",
      "Validation - Epoch [143/200], Loss: 0.0256\n",
      "Training - Epoch [144/200], Loss: 0.0234\n",
      "Validation - Epoch [144/200], Loss: 0.0241\n",
      "Training - Epoch [145/200], Loss: 0.0235\n",
      "Validation - Epoch [145/200], Loss: 0.0236\n",
      "Training - Epoch [146/200], Loss: 0.0236\n",
      "Validation - Epoch [146/200], Loss: 0.0238\n",
      "Training - Epoch [147/200], Loss: 0.0244\n",
      "Validation - Epoch [147/200], Loss: 0.0306\n",
      "Training - Epoch [148/200], Loss: 0.0247\n",
      "Validation - Epoch [148/200], Loss: 0.0254\n",
      "Training - Epoch [149/200], Loss: 0.0237\n",
      "Validation - Epoch [149/200], Loss: 0.0239\n",
      "Training - Epoch [150/200], Loss: 0.0239\n",
      "Validation - Epoch [150/200], Loss: 0.0253\n",
      "Training - Epoch [151/200], Loss: 0.0236\n",
      "Validation - Epoch [151/200], Loss: 0.0236\n",
      "Training - Epoch [152/200], Loss: 0.0238\n",
      "Validation - Epoch [152/200], Loss: 0.0246\n",
      "Training - Epoch [153/200], Loss: 0.0236\n",
      "Validation - Epoch [153/200], Loss: 0.0247\n",
      "Training - Epoch [154/200], Loss: 0.0243\n",
      "Validation - Epoch [154/200], Loss: 0.0260\n",
      "Training - Epoch [155/200], Loss: 0.0251\n",
      "Validation - Epoch [155/200], Loss: 0.0298\n",
      "Training - Epoch [156/200], Loss: 0.0301\n",
      "Validation - Epoch [156/200], Loss: 0.0255\n",
      "Training - Epoch [157/200], Loss: 0.0265\n",
      "Validation - Epoch [157/200], Loss: 0.0258\n",
      "Training - Epoch [158/200], Loss: 0.0252\n",
      "Validation - Epoch [158/200], Loss: 0.0247\n",
      "Training - Epoch [159/200], Loss: 0.0247\n",
      "Validation - Epoch [159/200], Loss: 0.0253\n",
      "Training - Epoch [160/200], Loss: 0.0244\n",
      "Validation - Epoch [160/200], Loss: 0.0246\n",
      "Training - Epoch [161/200], Loss: 0.0240\n",
      "Validation - Epoch [161/200], Loss: 0.0249\n",
      "Training - Epoch [162/200], Loss: 0.0237\n",
      "Validation - Epoch [162/200], Loss: 0.0243\n",
      "Training - Epoch [163/200], Loss: 0.0242\n",
      "Validation - Epoch [163/200], Loss: 0.0254\n",
      "Training - Epoch [164/200], Loss: 0.0238\n",
      "Validation - Epoch [164/200], Loss: 0.0245\n",
      "Training - Epoch [165/200], Loss: 0.0239\n",
      "Validation - Epoch [165/200], Loss: 0.0239\n",
      "Training - Epoch [166/200], Loss: 0.0240\n",
      "Validation - Epoch [166/200], Loss: 0.0266\n",
      "Training - Epoch [167/200], Loss: 0.0249\n",
      "Validation - Epoch [167/200], Loss: 0.0241\n",
      "Training - Epoch [168/200], Loss: 0.0235\n",
      "Validation - Epoch [168/200], Loss: 0.0244\n",
      "Training - Epoch [169/200], Loss: 0.0236\n",
      "Validation - Epoch [169/200], Loss: 0.0249\n",
      "Training - Epoch [170/200], Loss: 0.0236\n",
      "Validation - Epoch [170/200], Loss: 0.0238\n",
      "Training - Epoch [171/200], Loss: 0.0234\n",
      "Validation - Epoch [171/200], Loss: 0.0240\n",
      "Training - Epoch [172/200], Loss: 0.0236\n",
      "Validation - Epoch [172/200], Loss: 0.0238\n",
      "Training - Epoch [173/200], Loss: 0.0234\n",
      "Validation - Epoch [173/200], Loss: 0.0249\n",
      "Training - Epoch [174/200], Loss: 0.0235\n",
      "Validation - Epoch [174/200], Loss: 0.0240\n",
      "Training - Epoch [175/200], Loss: 0.0234\n",
      "Validation - Epoch [175/200], Loss: 0.0245\n",
      "Training - Epoch [176/200], Loss: 0.0246\n",
      "Validation - Epoch [176/200], Loss: 0.0272\n",
      "Training - Epoch [177/200], Loss: 0.0258\n",
      "Validation - Epoch [177/200], Loss: 0.0264\n",
      "Training - Epoch [178/200], Loss: 0.0263\n",
      "Validation - Epoch [178/200], Loss: 0.0258\n",
      "Training - Epoch [179/200], Loss: 0.0242\n",
      "Validation - Epoch [179/200], Loss: 0.0245\n",
      "Training - Epoch [180/200], Loss: 0.0237\n",
      "Validation - Epoch [180/200], Loss: 0.0239\n",
      "Training - Epoch [181/200], Loss: 0.0235\n",
      "Validation - Epoch [181/200], Loss: 0.0242\n",
      "Training - Epoch [182/200], Loss: 0.0234\n",
      "Validation - Epoch [182/200], Loss: 0.0237\n",
      "Training - Epoch [183/200], Loss: 0.0235\n",
      "Validation - Epoch [183/200], Loss: 0.0243\n",
      "Training - Epoch [184/200], Loss: 0.0246\n",
      "Validation - Epoch [184/200], Loss: 0.0250\n",
      "Training - Epoch [185/200], Loss: 0.0239\n",
      "Validation - Epoch [185/200], Loss: 0.0237\n",
      "Training - Epoch [186/200], Loss: 0.0235\n",
      "Validation - Epoch [186/200], Loss: 0.0250\n",
      "Training - Epoch [187/200], Loss: 0.0233\n",
      "Validation - Epoch [187/200], Loss: 0.0253\n",
      "Training - Epoch [188/200], Loss: 0.0233\n",
      "Validation - Epoch [188/200], Loss: 0.0239\n",
      "Training - Epoch [189/200], Loss: 0.0235\n",
      "Validation - Epoch [189/200], Loss: 0.0235\n",
      "Training - Epoch [190/200], Loss: 0.0234\n",
      "Validation - Epoch [190/200], Loss: 0.0236\n",
      "Training - Epoch [191/200], Loss: 0.0234\n",
      "Validation - Epoch [191/200], Loss: 0.0248\n",
      "Training - Epoch [192/200], Loss: 0.0233\n",
      "Validation - Epoch [192/200], Loss: 0.0252\n",
      "Training - Epoch [193/200], Loss: 0.0234\n",
      "Validation - Epoch [193/200], Loss: 0.0249\n",
      "Training - Epoch [194/200], Loss: 0.0235\n",
      "Validation - Epoch [194/200], Loss: 0.0259\n",
      "Training - Epoch [195/200], Loss: 0.0233\n",
      "Validation - Epoch [195/200], Loss: 0.0248\n",
      "Training - Epoch [196/200], Loss: 0.0248\n",
      "Validation - Epoch [196/200], Loss: 0.0242\n",
      "Training - Epoch [197/200], Loss: 0.0242\n",
      "Validation - Epoch [197/200], Loss: 0.0239\n",
      "Training - Epoch [198/200], Loss: 0.0234\n",
      "Validation - Epoch [198/200], Loss: 0.0238\n",
      "Training - Epoch [199/200], Loss: 0.0232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch [199/200], Loss: 0.0238\n",
      "Training - Epoch [200/200], Loss: 0.0231\n",
      "Validation - Epoch [200/200], Loss: 0.0246\n"
     ]
    }
   ],
   "source": [
    "# Transformer Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, hidden_dim, num_layers, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.squeeze(1)\n",
    "        x = self.fc(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.tensor(features.values, dtype=torch.float32) \n",
    "        self.targets = torch.tensor(targets.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = X_train.shape[1]  # Dimension of input features\n",
    "num_heads = 2  # Number of attention heads = 2\n",
    "hidden_dim = 200  # Hidden layers of the model = 200\n",
    "num_layers = 2  # Number of transformer layers = 2\n",
    "dropout = 0.1  # Dropout probability = 0.1\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "model = TransformerModel(input_dim=input_dim, num_heads=num_heads, hidden_dim=hidden_dim,\n",
    "                          num_layers=num_layers, dropout=dropout)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression task\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Optimizer used is Adam and learning rate is 0.001\n",
    "\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(inputs)\n",
    "    average_loss = total_loss / len(train_dataset)\n",
    "    print(f'Training - Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for inputs, labels in test_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * len(inputs)\n",
    "        average_loss = total_loss / len(test_dataset)\n",
    "        print(f'Validation - Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        # Stored true labels and predictions\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(outputs.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48be41bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        # Stored true labels and predictions\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(outputs.numpy())\n",
    "\n",
    "# Converted y_true and y_pred to numpy arrays\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Computed confusion matrix\n",
    "cm = confusion_matrix(np.round(y_true), np.round(y_pred))\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab7a208c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.024576489\n",
      "Mean Absolute Error: 0.1006261\n",
      "Root Mean Squared Error: 0.1567689\n",
      "R-squared Score: 0.7063329510455799\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Computed Mean Squared Error\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "# Computed Mean Absolute Error\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# Computed Root Mean Squared Error\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Computed R2-Score\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1daeb404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alarm triggered for 12 consecutive faults on 2019-04-29.\n",
      "Alarm triggered for 9 consecutive faults on 2019-05-29.\n",
      "Alarm triggered for 8 consecutive faults on 2019-05-08.\n",
      "Alarm triggered for 8 consecutive faults on 2019-05-06.\n",
      "Alarm triggered for 7 consecutive faults on 2019-04-21.\n",
      "Alarm triggered for 7 consecutive faults on 2019-06-06.\n",
      "Alarm triggered for 7 consecutive faults on 2019-06-04.\n",
      "Alarm triggered for 7 consecutive faults on 2019-04-19.\n",
      "Alarm triggered for 7 consecutive faults on 2019-04-13.\n",
      "Alarm triggered for 6 consecutive faults on 2019-05-23.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-30.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-15.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-26.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-11.\n",
      "Alarm triggered for 6 consecutive faults on 2019-05-17.\n",
      "Alarm triggered for 6 consecutive faults on 2019-05-25.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-28.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-07.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-28.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-27.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-19.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-22.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-24.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-23.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-07.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-18.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-16.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-25.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-27.\n",
      "Alarm triggered for 4 consecutive faults on 2019-06-05.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-06.\n",
      "Alarm triggered for 4 consecutive faults on 2019-05-20.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-08.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-14.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-17.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-05.\n",
      "Alarm triggered for 4 consecutive faults on 2019-05-24.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-04.\n"
     ]
    }
   ],
   "source": [
    "# Function to check for four consecutive faults in a day and trigger alarms\n",
    "def check_consecutive_faults(fault_indices, df, window=3):\n",
    "    fault_timestamps = df.index[fault_indices]\n",
    "\n",
    "    grouped_by_day = fault_timestamps.to_series().dt.date\n",
    "\n",
    "    # Checked if there are three or more consecutive faults within the same day\n",
    "    daily_fault_count = grouped_by_day.value_counts()\n",
    "    for date, count in daily_fault_count.items():\n",
    "        if count >= window:\n",
    "            print(f\"Alarm triggered for {count} consecutive faults on {date}.\")\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_ac_power = model(X_test_tensor)  # Model predictions\n",
    "    actual_ac_power = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "    # Absolute residuals between predicted and actual AC power\n",
    "    residuals = torch.abs(predicted_ac_power - actual_ac_power)\n",
    "\n",
    "# Calculated the standard deviation for setting the fault threshold\n",
    "sigma = torch.std(residuals).item()\n",
    "threshold = 2 * sigma  # Set the threshold as 2 * sigma\n",
    "anomalies = (residuals > threshold).int()\n",
    "\n",
    "fault_indices = torch.nonzero(anomalies).squeeze().tolist()\n",
    "\n",
    "check_consecutive_faults(fault_indices, df, window=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f44ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
