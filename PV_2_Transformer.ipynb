{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21ac97cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score, classification_report, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea1b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\My PC\\Desktop\\Solar PV Fault Research\\IO_DATA_LABELED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c994eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Inv-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef3aa21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Inv</th>\n",
       "      <th>AC_Real_Power</th>\n",
       "      <th>AC_Current</th>\n",
       "      <th>DC_Power</th>\n",
       "      <th>DC_Current</th>\n",
       "      <th>Tilt_Irradiation_1</th>\n",
       "      <th>Temp_Ambient_1</th>\n",
       "      <th>Temp_Module_1</th>\n",
       "      <th>Wind_Speed_1</th>\n",
       "      <th>Hor_Irradiation_1</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>05:45:00</td>\n",
       "      <td>Inv-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>Inv-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>06:15:00</td>\n",
       "      <td>Inv-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.639</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>06:30:00</td>\n",
       "      <td>Inv-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.5</td>\n",
       "      <td>20.7</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>13.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>06:45:00</td>\n",
       "      <td>Inv-2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>10.79</td>\n",
       "      <td>2.72</td>\n",
       "      <td>5.96</td>\n",
       "      <td>30.1</td>\n",
       "      <td>21.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.500</td>\n",
       "      <td>30.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13872</th>\n",
       "      <td>13872</td>\n",
       "      <td>13872</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>18:30:00</td>\n",
       "      <td>Inv-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13873</th>\n",
       "      <td>13873</td>\n",
       "      <td>13873</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>18:45:00</td>\n",
       "      <td>Inv-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13874</th>\n",
       "      <td>13874</td>\n",
       "      <td>13874</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>Inv-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13875</th>\n",
       "      <td>13875</td>\n",
       "      <td>13875</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>19:15:00</td>\n",
       "      <td>Inv-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13876</th>\n",
       "      <td>13876</td>\n",
       "      <td>13876</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>19:30:00</td>\n",
       "      <td>Inv-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13877 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0        Date      Time    Inv  AC_Real_Power  \\\n",
       "0                 0           0  2019-04-04  05:45:00  Inv-2            0.0   \n",
       "1                 1           1  2019-04-04  06:00:00  Inv-2            0.0   \n",
       "2                 2           2  2019-04-04  06:15:00  Inv-2            0.0   \n",
       "3                 3           3  2019-04-04  06:30:00  Inv-2            0.0   \n",
       "4                 4           4  2019-04-04  06:45:00  Inv-2            2.2   \n",
       "...             ...         ...         ...       ...    ...            ...   \n",
       "13872         13872       13872  2020-04-01  18:30:00  Inv-2            0.0   \n",
       "13873         13873       13873  2020-04-01  18:45:00  Inv-2            0.0   \n",
       "13874         13874       13874  2020-04-01  19:00:00  Inv-2            0.0   \n",
       "13875         13875       13875  2020-04-01  19:15:00  Inv-2            0.0   \n",
       "13876         13876       13876  2020-04-01  19:30:00  Inv-2            0.0   \n",
       "\n",
       "       AC_Current  DC_Power  DC_Current  Tilt_Irradiation_1  Temp_Ambient_1  \\\n",
       "0            0.00      0.00        1.84                 0.0            20.0   \n",
       "1            0.00      0.00        1.23                 0.0            19.6   \n",
       "2            0.00      0.00        0.00                 0.0            19.6   \n",
       "3            0.00      0.00        0.00                12.5            20.7   \n",
       "4           10.79      2.72        5.96                30.1            21.3   \n",
       "...           ...       ...         ...                 ...             ...   \n",
       "13872        0.00      0.00        0.02                 0.0            15.9   \n",
       "13873        0.00      0.00        2.40                 0.0            15.1   \n",
       "13874        0.00      0.00        3.93                 0.0            14.2   \n",
       "13875        0.00      0.00        4.22                 0.0            14.3   \n",
       "13876        0.00      0.00        4.47                 0.0            14.2   \n",
       "\n",
       "       Temp_Module_1  Wind_Speed_1  Hor_Irradiation_1  Operation  \n",
       "0               21.7         0.500                0.0          1  \n",
       "1               21.6         0.500                0.0          1  \n",
       "2               21.5         0.639                2.6          1  \n",
       "3               22.1         0.500               13.4          1  \n",
       "4               23.3         0.500               30.2          1  \n",
       "...              ...           ...                ...        ...  \n",
       "13872           17.5         0.500                0.5          1  \n",
       "13873           16.7         0.500                0.5          1  \n",
       "13874           16.1         0.500                0.5          1  \n",
       "13875           15.9         0.500                0.5          1  \n",
       "13876           15.6         0.500                0.5          1  \n",
       "\n",
       "[13877 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce54243f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13877 entries, 0 to 13876\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Unnamed: 0.1        13877 non-null  int64  \n",
      " 1   Unnamed: 0          13877 non-null  int64  \n",
      " 2   Date                13877 non-null  object \n",
      " 3   Time                13877 non-null  object \n",
      " 4   Inv                 13877 non-null  object \n",
      " 5   AC_Real_Power       12979 non-null  float64\n",
      " 6   AC_Current          12979 non-null  float64\n",
      " 7   DC_Power            12979 non-null  float64\n",
      " 8   DC_Current          12979 non-null  float64\n",
      " 9   Tilt_Irradiation_1  13877 non-null  float64\n",
      " 10  Temp_Ambient_1      13877 non-null  float64\n",
      " 11  Temp_Module_1       13877 non-null  float64\n",
      " 12  Wind_Speed_1        13877 non-null  float64\n",
      " 13  Hor_Irradiation_1   13877 non-null  float64\n",
      " 14  Operation           13877 non-null  int64  \n",
      "dtypes: float64(9), int64(3), object(3)\n",
      "memory usage: 1.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Inv</th>\n",
       "      <th>AC_Real_Power</th>\n",
       "      <th>AC_Current</th>\n",
       "      <th>DC_Power</th>\n",
       "      <th>DC_Current</th>\n",
       "      <th>Tilt_Irradiation_1</th>\n",
       "      <th>Temp_Ambient_1</th>\n",
       "      <th>Temp_Module_1</th>\n",
       "      <th>Wind_Speed_1</th>\n",
       "      <th>Hor_Irradiation_1</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>05:45:00</td>\n",
       "      <td>Inv-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>Inv-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>06:15:00</td>\n",
       "      <td>Inv-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.639</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>06:30:00</td>\n",
       "      <td>Inv-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.5</td>\n",
       "      <td>20.7</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>13.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>06:45:00</td>\n",
       "      <td>Inv-2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>10.79</td>\n",
       "      <td>2.72</td>\n",
       "      <td>5.96</td>\n",
       "      <td>30.1</td>\n",
       "      <td>21.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.500</td>\n",
       "      <td>30.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0        Date      Time    Inv  AC_Real_Power  \\\n",
       "0             0           0  2019-04-04  05:45:00  Inv-2            0.0   \n",
       "1             1           1  2019-04-04  06:00:00  Inv-2            0.0   \n",
       "2             2           2  2019-04-04  06:15:00  Inv-2            0.0   \n",
       "3             3           3  2019-04-04  06:30:00  Inv-2            0.0   \n",
       "4             4           4  2019-04-04  06:45:00  Inv-2            2.2   \n",
       "\n",
       "   AC_Current  DC_Power  DC_Current  Tilt_Irradiation_1  Temp_Ambient_1  \\\n",
       "0        0.00      0.00        1.84                 0.0            20.0   \n",
       "1        0.00      0.00        1.23                 0.0            19.6   \n",
       "2        0.00      0.00        0.00                 0.0            19.6   \n",
       "3        0.00      0.00        0.00                12.5            20.7   \n",
       "4       10.79      2.72        5.96                30.1            21.3   \n",
       "\n",
       "   Temp_Module_1  Wind_Speed_1  Hor_Irradiation_1  Operation  \n",
       "0           21.7         0.500                0.0          1  \n",
       "1           21.6         0.500                0.0          1  \n",
       "2           21.5         0.639                2.6          1  \n",
       "3           22.1         0.500               13.4          1  \n",
       "4           23.3         0.500               30.2          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.info(),df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e069aed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 13877\n",
      "Number of columns: 15\n"
     ]
    }
   ],
   "source": [
    "num_rows, num_columns = df.shape\n",
    "\n",
    "print(\"Number of rows:\", num_rows)\n",
    "print(\"Number of columns:\", num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35cf7dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed60f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46a8feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('DateTime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74e530f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Date','Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a77f4e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = pd.Timestamp(\"07:00:00\")\n",
    "end_time = pd.Timestamp(\"18:30:00\")\n",
    "\n",
    "# Filtering the data to retain only the rows within the operational hours\n",
    "df = df[(df.index.time >= pd.to_datetime('7:00:00').time()) & (df.index.time <= pd.to_datetime('18:30:00').time())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c3527f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inv</th>\n",
       "      <th>AC_Real_Power</th>\n",
       "      <th>AC_Current</th>\n",
       "      <th>DC_Power</th>\n",
       "      <th>DC_Current</th>\n",
       "      <th>Tilt_Irradiation_1</th>\n",
       "      <th>Temp_Ambient_1</th>\n",
       "      <th>Temp_Module_1</th>\n",
       "      <th>Wind_Speed_1</th>\n",
       "      <th>Hor_Irradiation_1</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-04 07:00:00</th>\n",
       "      <td>Inv-2</td>\n",
       "      <td>13.14</td>\n",
       "      <td>24.15</td>\n",
       "      <td>15.97</td>\n",
       "      <td>28.72</td>\n",
       "      <td>48.3</td>\n",
       "      <td>23.1</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>49.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-04 07:15:00</th>\n",
       "      <td>Inv-2</td>\n",
       "      <td>29.61</td>\n",
       "      <td>54.39</td>\n",
       "      <td>34.90</td>\n",
       "      <td>59.12</td>\n",
       "      <td>65.4</td>\n",
       "      <td>25.3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>86.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-04 07:30:00</th>\n",
       "      <td>Inv-2</td>\n",
       "      <td>50.86</td>\n",
       "      <td>93.41</td>\n",
       "      <td>57.71</td>\n",
       "      <td>102.75</td>\n",
       "      <td>81.4</td>\n",
       "      <td>28.2</td>\n",
       "      <td>28.3</td>\n",
       "      <td>0.614</td>\n",
       "      <td>130.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-04 07:45:00</th>\n",
       "      <td>Inv-2</td>\n",
       "      <td>75.66</td>\n",
       "      <td>138.59</td>\n",
       "      <td>83.01</td>\n",
       "      <td>154.25</td>\n",
       "      <td>101.6</td>\n",
       "      <td>30.1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.728</td>\n",
       "      <td>180.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-04 08:00:00</th>\n",
       "      <td>Inv-2</td>\n",
       "      <td>110.43</td>\n",
       "      <td>200.43</td>\n",
       "      <td>119.29</td>\n",
       "      <td>200.88</td>\n",
       "      <td>308.8</td>\n",
       "      <td>31.5</td>\n",
       "      <td>35.4</td>\n",
       "      <td>0.827</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Inv  AC_Real_Power  AC_Current  DC_Power  DC_Current  \\\n",
       "DateTime                                                                      \n",
       "2019-04-04 07:00:00  Inv-2          13.14       24.15     15.97       28.72   \n",
       "2019-04-04 07:15:00  Inv-2          29.61       54.39     34.90       59.12   \n",
       "2019-04-04 07:30:00  Inv-2          50.86       93.41     57.71      102.75   \n",
       "2019-04-04 07:45:00  Inv-2          75.66      138.59     83.01      154.25   \n",
       "2019-04-04 08:00:00  Inv-2         110.43      200.43    119.29      200.88   \n",
       "\n",
       "                     Tilt_Irradiation_1  Temp_Ambient_1  Temp_Module_1  \\\n",
       "DateTime                                                                 \n",
       "2019-04-04 07:00:00                48.3            23.1           25.2   \n",
       "2019-04-04 07:15:00                65.4            25.3           27.0   \n",
       "2019-04-04 07:30:00                81.4            28.2           28.3   \n",
       "2019-04-04 07:45:00               101.6            30.1           30.0   \n",
       "2019-04-04 08:00:00               308.8            31.5           35.4   \n",
       "\n",
       "                     Wind_Speed_1  Hor_Irradiation_1  Operation  \n",
       "DateTime                                                         \n",
       "2019-04-04 07:00:00         0.500               49.6          1  \n",
       "2019-04-04 07:15:00         0.500               86.6          1  \n",
       "2019-04-04 07:30:00         0.614              130.6          1  \n",
       "2019-04-04 07:45:00         0.728              180.6          1  \n",
       "2019-04-04 08:00:00         0.827              236.0          1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fd6f798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inv                   0\n",
      "AC_Real_Power         0\n",
      "AC_Current            0\n",
      "DC_Power              0\n",
      "DC_Current            0\n",
      "Tilt_Irradiation_1    0\n",
      "Temp_Ambient_1        0\n",
      "Temp_Module_1         0\n",
      "Wind_Speed_1          0\n",
      "Hor_Irradiation_1     0\n",
      "Operation             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_data = df.isnull().sum()\n",
    "print(missing_data)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddc22891",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "operational_data = df\n",
    "numerical_features = ['AC_Real_Power','Tilt_Irradiation_1', 'Temp_Ambient_1', 'Hor_Irradiation_1']\n",
    "\n",
    "# Normalization of the features\n",
    "operational_data[numerical_features] = scaler.fit_transform(operational_data[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33865eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = operational_data[['Tilt_Irradiation_1', 'Temp_Ambient_1', 'Hor_Irradiation_1']]\n",
    "y = operational_data['AC_Real_Power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c7366e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch [1/200], Loss: 0.2050\n",
      "Validation - Epoch [1/200], Loss: 0.0324\n",
      "Training - Epoch [2/200], Loss: 0.0313\n",
      "Validation - Epoch [2/200], Loss: 0.0269\n",
      "Training - Epoch [3/200], Loss: 0.0306\n",
      "Validation - Epoch [3/200], Loss: 0.0432\n",
      "Training - Epoch [4/200], Loss: 0.0302\n",
      "Validation - Epoch [4/200], Loss: 0.0299\n",
      "Training - Epoch [5/200], Loss: 0.0284\n",
      "Validation - Epoch [5/200], Loss: 0.0403\n",
      "Training - Epoch [6/200], Loss: 0.0287\n",
      "Validation - Epoch [6/200], Loss: 0.0289\n",
      "Training - Epoch [7/200], Loss: 0.0276\n",
      "Validation - Epoch [7/200], Loss: 0.0297\n",
      "Training - Epoch [8/200], Loss: 0.0290\n",
      "Validation - Epoch [8/200], Loss: 0.0253\n",
      "Training - Epoch [9/200], Loss: 0.0280\n",
      "Validation - Epoch [9/200], Loss: 0.0258\n",
      "Training - Epoch [10/200], Loss: 0.0279\n",
      "Validation - Epoch [10/200], Loss: 0.0313\n",
      "Training - Epoch [11/200], Loss: 0.0289\n",
      "Validation - Epoch [11/200], Loss: 0.0256\n",
      "Training - Epoch [12/200], Loss: 0.0274\n",
      "Validation - Epoch [12/200], Loss: 0.0325\n",
      "Training - Epoch [13/200], Loss: 0.0280\n",
      "Validation - Epoch [13/200], Loss: 0.0291\n",
      "Training - Epoch [14/200], Loss: 0.0270\n",
      "Validation - Epoch [14/200], Loss: 0.0307\n",
      "Training - Epoch [15/200], Loss: 0.0276\n",
      "Validation - Epoch [15/200], Loss: 0.0316\n",
      "Training - Epoch [16/200], Loss: 0.0273\n",
      "Validation - Epoch [16/200], Loss: 0.0288\n",
      "Training - Epoch [17/200], Loss: 0.0273\n",
      "Validation - Epoch [17/200], Loss: 0.0255\n",
      "Training - Epoch [18/200], Loss: 0.0274\n",
      "Validation - Epoch [18/200], Loss: 0.0316\n",
      "Training - Epoch [19/200], Loss: 0.0271\n",
      "Validation - Epoch [19/200], Loss: 0.0250\n",
      "Training - Epoch [20/200], Loss: 0.0271\n",
      "Validation - Epoch [20/200], Loss: 0.0252\n",
      "Training - Epoch [21/200], Loss: 0.0270\n",
      "Validation - Epoch [21/200], Loss: 0.0251\n",
      "Training - Epoch [22/200], Loss: 0.0270\n",
      "Validation - Epoch [22/200], Loss: 0.0248\n",
      "Training - Epoch [23/200], Loss: 0.0268\n",
      "Validation - Epoch [23/200], Loss: 0.0252\n",
      "Training - Epoch [24/200], Loss: 0.0270\n",
      "Validation - Epoch [24/200], Loss: 0.0273\n",
      "Training - Epoch [25/200], Loss: 0.0272\n",
      "Validation - Epoch [25/200], Loss: 0.0269\n",
      "Training - Epoch [26/200], Loss: 0.0270\n",
      "Validation - Epoch [26/200], Loss: 0.0255\n",
      "Training - Epoch [27/200], Loss: 0.0272\n",
      "Validation - Epoch [27/200], Loss: 0.0261\n",
      "Training - Epoch [28/200], Loss: 0.0269\n",
      "Validation - Epoch [28/200], Loss: 0.0264\n",
      "Training - Epoch [29/200], Loss: 0.0270\n",
      "Validation - Epoch [29/200], Loss: 0.0275\n",
      "Training - Epoch [30/200], Loss: 0.0271\n",
      "Validation - Epoch [30/200], Loss: 0.0313\n",
      "Training - Epoch [31/200], Loss: 0.0268\n",
      "Validation - Epoch [31/200], Loss: 0.0258\n",
      "Training - Epoch [32/200], Loss: 0.0268\n",
      "Validation - Epoch [32/200], Loss: 0.0254\n",
      "Training - Epoch [33/200], Loss: 0.0272\n",
      "Validation - Epoch [33/200], Loss: 0.0251\n",
      "Training - Epoch [34/200], Loss: 0.0268\n",
      "Validation - Epoch [34/200], Loss: 0.0320\n",
      "Training - Epoch [35/200], Loss: 0.0282\n",
      "Validation - Epoch [35/200], Loss: 0.0283\n",
      "Training - Epoch [36/200], Loss: 0.0276\n",
      "Validation - Epoch [36/200], Loss: 0.0256\n",
      "Training - Epoch [37/200], Loss: 0.0270\n",
      "Validation - Epoch [37/200], Loss: 0.0298\n",
      "Training - Epoch [38/200], Loss: 0.0264\n",
      "Validation - Epoch [38/200], Loss: 0.0270\n",
      "Training - Epoch [39/200], Loss: 0.0269\n",
      "Validation - Epoch [39/200], Loss: 0.0278\n",
      "Training - Epoch [40/200], Loss: 0.0266\n",
      "Validation - Epoch [40/200], Loss: 0.0291\n",
      "Training - Epoch [41/200], Loss: 0.0265\n",
      "Validation - Epoch [41/200], Loss: 0.0274\n",
      "Training - Epoch [42/200], Loss: 0.0266\n",
      "Validation - Epoch [42/200], Loss: 0.0251\n",
      "Training - Epoch [43/200], Loss: 0.0271\n",
      "Validation - Epoch [43/200], Loss: 0.0257\n",
      "Training - Epoch [44/200], Loss: 0.0271\n",
      "Validation - Epoch [44/200], Loss: 0.0250\n",
      "Training - Epoch [45/200], Loss: 0.0266\n",
      "Validation - Epoch [45/200], Loss: 0.0271\n",
      "Training - Epoch [46/200], Loss: 0.0267\n",
      "Validation - Epoch [46/200], Loss: 0.0320\n",
      "Training - Epoch [47/200], Loss: 0.0266\n",
      "Validation - Epoch [47/200], Loss: 0.0273\n",
      "Training - Epoch [48/200], Loss: 0.0323\n",
      "Validation - Epoch [48/200], Loss: 0.0393\n",
      "Training - Epoch [49/200], Loss: 0.0314\n",
      "Validation - Epoch [49/200], Loss: 0.0390\n",
      "Training - Epoch [50/200], Loss: 0.0278\n",
      "Validation - Epoch [50/200], Loss: 0.0300\n",
      "Training - Epoch [51/200], Loss: 0.0279\n",
      "Validation - Epoch [51/200], Loss: 0.0306\n",
      "Training - Epoch [52/200], Loss: 0.0280\n",
      "Validation - Epoch [52/200], Loss: 0.0272\n",
      "Training - Epoch [53/200], Loss: 0.0277\n",
      "Validation - Epoch [53/200], Loss: 0.0261\n",
      "Training - Epoch [54/200], Loss: 0.0276\n",
      "Validation - Epoch [54/200], Loss: 0.0261\n",
      "Training - Epoch [55/200], Loss: 0.0281\n",
      "Validation - Epoch [55/200], Loss: 0.0328\n",
      "Training - Epoch [56/200], Loss: 0.0277\n",
      "Validation - Epoch [56/200], Loss: 0.0274\n",
      "Training - Epoch [57/200], Loss: 0.0276\n",
      "Validation - Epoch [57/200], Loss: 0.0266\n",
      "Training - Epoch [58/200], Loss: 0.0278\n",
      "Validation - Epoch [58/200], Loss: 0.0273\n",
      "Training - Epoch [59/200], Loss: 0.0277\n",
      "Validation - Epoch [59/200], Loss: 0.0259\n",
      "Training - Epoch [60/200], Loss: 0.0276\n",
      "Validation - Epoch [60/200], Loss: 0.0256\n",
      "Training - Epoch [61/200], Loss: 0.0292\n",
      "Validation - Epoch [61/200], Loss: 0.0275\n",
      "Training - Epoch [62/200], Loss: 0.0280\n",
      "Validation - Epoch [62/200], Loss: 0.0264\n",
      "Training - Epoch [63/200], Loss: 0.0279\n",
      "Validation - Epoch [63/200], Loss: 0.0276\n",
      "Training - Epoch [64/200], Loss: 0.0278\n",
      "Validation - Epoch [64/200], Loss: 0.0260\n",
      "Training - Epoch [65/200], Loss: 0.0275\n",
      "Validation - Epoch [65/200], Loss: 0.0277\n",
      "Training - Epoch [66/200], Loss: 0.0278\n",
      "Validation - Epoch [66/200], Loss: 0.0293\n",
      "Training - Epoch [67/200], Loss: 0.0271\n",
      "Validation - Epoch [67/200], Loss: 0.0258\n",
      "Training - Epoch [68/200], Loss: 0.0274\n",
      "Validation - Epoch [68/200], Loss: 0.0296\n",
      "Training - Epoch [69/200], Loss: 0.0271\n",
      "Validation - Epoch [69/200], Loss: 0.0267\n",
      "Training - Epoch [70/200], Loss: 0.0271\n",
      "Validation - Epoch [70/200], Loss: 0.0274\n",
      "Training - Epoch [71/200], Loss: 0.0279\n",
      "Validation - Epoch [71/200], Loss: 0.0270\n",
      "Training - Epoch [72/200], Loss: 0.0274\n",
      "Validation - Epoch [72/200], Loss: 0.0295\n",
      "Training - Epoch [73/200], Loss: 0.0279\n",
      "Validation - Epoch [73/200], Loss: 0.0278\n",
      "Training - Epoch [74/200], Loss: 0.0275\n",
      "Validation - Epoch [74/200], Loss: 0.0275\n",
      "Training - Epoch [75/200], Loss: 0.0267\n",
      "Validation - Epoch [75/200], Loss: 0.0264\n",
      "Training - Epoch [76/200], Loss: 0.0267\n",
      "Validation - Epoch [76/200], Loss: 0.0292\n",
      "Training - Epoch [77/200], Loss: 0.0271\n",
      "Validation - Epoch [77/200], Loss: 0.0289\n",
      "Training - Epoch [78/200], Loss: 0.0276\n",
      "Validation - Epoch [78/200], Loss: 0.0291\n",
      "Training - Epoch [79/200], Loss: 0.0269\n",
      "Validation - Epoch [79/200], Loss: 0.0256\n",
      "Training - Epoch [80/200], Loss: 0.0272\n",
      "Validation - Epoch [80/200], Loss: 0.0263\n",
      "Training - Epoch [81/200], Loss: 0.0269\n",
      "Validation - Epoch [81/200], Loss: 0.0252\n",
      "Training - Epoch [82/200], Loss: 0.0268\n",
      "Validation - Epoch [82/200], Loss: 0.0254\n",
      "Training - Epoch [83/200], Loss: 0.0265\n",
      "Validation - Epoch [83/200], Loss: 0.0295\n",
      "Training - Epoch [84/200], Loss: 0.0265\n",
      "Validation - Epoch [84/200], Loss: 0.0292\n",
      "Training - Epoch [85/200], Loss: 0.0267\n",
      "Validation - Epoch [85/200], Loss: 0.0282\n",
      "Training - Epoch [86/200], Loss: 0.0265\n",
      "Validation - Epoch [86/200], Loss: 0.0309\n",
      "Training - Epoch [87/200], Loss: 0.0271\n",
      "Validation - Epoch [87/200], Loss: 0.0279\n",
      "Training - Epoch [88/200], Loss: 0.0262\n",
      "Validation - Epoch [88/200], Loss: 0.0260\n",
      "Training - Epoch [89/200], Loss: 0.0266\n",
      "Validation - Epoch [89/200], Loss: 0.0263\n",
      "Training - Epoch [90/200], Loss: 0.0263\n",
      "Validation - Epoch [90/200], Loss: 0.0255\n",
      "Training - Epoch [91/200], Loss: 0.0261\n",
      "Validation - Epoch [91/200], Loss: 0.0263\n",
      "Training - Epoch [92/200], Loss: 0.0269\n",
      "Validation - Epoch [92/200], Loss: 0.0310\n",
      "Training - Epoch [93/200], Loss: 0.0278\n",
      "Validation - Epoch [93/200], Loss: 0.0278\n",
      "Training - Epoch [94/200], Loss: 0.0268\n",
      "Validation - Epoch [94/200], Loss: 0.0278\n",
      "Training - Epoch [95/200], Loss: 0.0267\n",
      "Validation - Epoch [95/200], Loss: 0.0251\n",
      "Training - Epoch [96/200], Loss: 0.0263\n",
      "Validation - Epoch [96/200], Loss: 0.0257\n",
      "Training - Epoch [97/200], Loss: 0.0262\n",
      "Validation - Epoch [97/200], Loss: 0.0259\n",
      "Training - Epoch [98/200], Loss: 0.0263\n",
      "Validation - Epoch [98/200], Loss: 0.0297\n",
      "Training - Epoch [99/200], Loss: 0.0265\n",
      "Validation - Epoch [99/200], Loss: 0.0354\n",
      "Training - Epoch [100/200], Loss: 0.0258\n",
      "Validation - Epoch [100/200], Loss: 0.0264\n",
      "Training - Epoch [101/200], Loss: 0.0258\n",
      "Validation - Epoch [101/200], Loss: 0.0266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch [102/200], Loss: 0.0261\n",
      "Validation - Epoch [102/200], Loss: 0.0264\n",
      "Training - Epoch [103/200], Loss: 0.0262\n",
      "Validation - Epoch [103/200], Loss: 0.0255\n",
      "Training - Epoch [104/200], Loss: 0.0260\n",
      "Validation - Epoch [104/200], Loss: 0.0269\n",
      "Training - Epoch [105/200], Loss: 0.0262\n",
      "Validation - Epoch [105/200], Loss: 0.0273\n",
      "Training - Epoch [106/200], Loss: 0.0259\n",
      "Validation - Epoch [106/200], Loss: 0.0308\n",
      "Training - Epoch [107/200], Loss: 0.0262\n",
      "Validation - Epoch [107/200], Loss: 0.0274\n",
      "Training - Epoch [108/200], Loss: 0.0260\n",
      "Validation - Epoch [108/200], Loss: 0.0265\n",
      "Training - Epoch [109/200], Loss: 0.0257\n",
      "Validation - Epoch [109/200], Loss: 0.0248\n",
      "Training - Epoch [110/200], Loss: 0.0260\n",
      "Validation - Epoch [110/200], Loss: 0.0280\n",
      "Training - Epoch [111/200], Loss: 0.0264\n",
      "Validation - Epoch [111/200], Loss: 0.0268\n",
      "Training - Epoch [112/200], Loss: 0.0261\n",
      "Validation - Epoch [112/200], Loss: 0.0280\n",
      "Training - Epoch [113/200], Loss: 0.0263\n",
      "Validation - Epoch [113/200], Loss: 0.0254\n",
      "Training - Epoch [114/200], Loss: 0.0259\n",
      "Validation - Epoch [114/200], Loss: 0.0267\n",
      "Training - Epoch [115/200], Loss: 0.0262\n",
      "Validation - Epoch [115/200], Loss: 0.0253\n",
      "Training - Epoch [116/200], Loss: 0.0257\n",
      "Validation - Epoch [116/200], Loss: 0.0251\n",
      "Training - Epoch [117/200], Loss: 0.0258\n",
      "Validation - Epoch [117/200], Loss: 0.0320\n",
      "Training - Epoch [118/200], Loss: 0.0261\n",
      "Validation - Epoch [118/200], Loss: 0.0257\n",
      "Training - Epoch [119/200], Loss: 0.0258\n",
      "Validation - Epoch [119/200], Loss: 0.0254\n",
      "Training - Epoch [120/200], Loss: 0.0254\n",
      "Validation - Epoch [120/200], Loss: 0.0273\n",
      "Training - Epoch [121/200], Loss: 0.0259\n",
      "Validation - Epoch [121/200], Loss: 0.0270\n",
      "Training - Epoch [122/200], Loss: 0.0260\n",
      "Validation - Epoch [122/200], Loss: 0.0284\n",
      "Training - Epoch [123/200], Loss: 0.0267\n",
      "Validation - Epoch [123/200], Loss: 0.0272\n",
      "Training - Epoch [124/200], Loss: 0.0258\n",
      "Validation - Epoch [124/200], Loss: 0.0261\n",
      "Training - Epoch [125/200], Loss: 0.0260\n",
      "Validation - Epoch [125/200], Loss: 0.0252\n",
      "Training - Epoch [126/200], Loss: 0.0259\n",
      "Validation - Epoch [126/200], Loss: 0.0249\n",
      "Training - Epoch [127/200], Loss: 0.0261\n",
      "Validation - Epoch [127/200], Loss: 0.0296\n",
      "Training - Epoch [128/200], Loss: 0.0257\n",
      "Validation - Epoch [128/200], Loss: 0.0250\n",
      "Training - Epoch [129/200], Loss: 0.0256\n",
      "Validation - Epoch [129/200], Loss: 0.0264\n",
      "Training - Epoch [130/200], Loss: 0.0256\n",
      "Validation - Epoch [130/200], Loss: 0.0276\n",
      "Training - Epoch [131/200], Loss: 0.0261\n",
      "Validation - Epoch [131/200], Loss: 0.0256\n",
      "Training - Epoch [132/200], Loss: 0.0255\n",
      "Validation - Epoch [132/200], Loss: 0.0254\n",
      "Training - Epoch [133/200], Loss: 0.0255\n",
      "Validation - Epoch [133/200], Loss: 0.0252\n",
      "Training - Epoch [134/200], Loss: 0.0256\n",
      "Validation - Epoch [134/200], Loss: 0.0251\n",
      "Training - Epoch [135/200], Loss: 0.0262\n",
      "Validation - Epoch [135/200], Loss: 0.0255\n",
      "Training - Epoch [136/200], Loss: 0.0256\n",
      "Validation - Epoch [136/200], Loss: 0.0296\n",
      "Training - Epoch [137/200], Loss: 0.0259\n",
      "Validation - Epoch [137/200], Loss: 0.0246\n",
      "Training - Epoch [138/200], Loss: 0.0258\n",
      "Validation - Epoch [138/200], Loss: 0.0250\n",
      "Training - Epoch [139/200], Loss: 0.0261\n",
      "Validation - Epoch [139/200], Loss: 0.0249\n",
      "Training - Epoch [140/200], Loss: 0.0258\n",
      "Validation - Epoch [140/200], Loss: 0.0249\n",
      "Training - Epoch [141/200], Loss: 0.0258\n",
      "Validation - Epoch [141/200], Loss: 0.0266\n",
      "Training - Epoch [142/200], Loss: 0.0257\n",
      "Validation - Epoch [142/200], Loss: 0.0277\n",
      "Training - Epoch [143/200], Loss: 0.0258\n",
      "Validation - Epoch [143/200], Loss: 0.0289\n",
      "Training - Epoch [144/200], Loss: 0.0256\n",
      "Validation - Epoch [144/200], Loss: 0.0269\n",
      "Training - Epoch [145/200], Loss: 0.0256\n",
      "Validation - Epoch [145/200], Loss: 0.0272\n",
      "Training - Epoch [146/200], Loss: 0.0254\n",
      "Validation - Epoch [146/200], Loss: 0.0252\n",
      "Training - Epoch [147/200], Loss: 0.0258\n",
      "Validation - Epoch [147/200], Loss: 0.0245\n",
      "Training - Epoch [148/200], Loss: 0.0256\n",
      "Validation - Epoch [148/200], Loss: 0.0250\n",
      "Training - Epoch [149/200], Loss: 0.0256\n",
      "Validation - Epoch [149/200], Loss: 0.0248\n",
      "Training - Epoch [150/200], Loss: 0.0262\n",
      "Validation - Epoch [150/200], Loss: 0.0275\n",
      "Training - Epoch [151/200], Loss: 0.0256\n",
      "Validation - Epoch [151/200], Loss: 0.0275\n",
      "Training - Epoch [152/200], Loss: 0.0253\n",
      "Validation - Epoch [152/200], Loss: 0.0243\n",
      "Training - Epoch [153/200], Loss: 0.0257\n",
      "Validation - Epoch [153/200], Loss: 0.0274\n",
      "Training - Epoch [154/200], Loss: 0.0256\n",
      "Validation - Epoch [154/200], Loss: 0.0279\n",
      "Training - Epoch [155/200], Loss: 0.0254\n",
      "Validation - Epoch [155/200], Loss: 0.0248\n",
      "Training - Epoch [156/200], Loss: 0.0252\n",
      "Validation - Epoch [156/200], Loss: 0.0268\n",
      "Training - Epoch [157/200], Loss: 0.0261\n",
      "Validation - Epoch [157/200], Loss: 0.0255\n",
      "Training - Epoch [158/200], Loss: 0.0255\n",
      "Validation - Epoch [158/200], Loss: 0.0286\n",
      "Training - Epoch [159/200], Loss: 0.0256\n",
      "Validation - Epoch [159/200], Loss: 0.0248\n",
      "Training - Epoch [160/200], Loss: 0.0253\n",
      "Validation - Epoch [160/200], Loss: 0.0255\n",
      "Training - Epoch [161/200], Loss: 0.0255\n",
      "Validation - Epoch [161/200], Loss: 0.0255\n",
      "Training - Epoch [162/200], Loss: 0.0253\n",
      "Validation - Epoch [162/200], Loss: 0.0256\n",
      "Training - Epoch [163/200], Loss: 0.0251\n",
      "Validation - Epoch [163/200], Loss: 0.0305\n",
      "Training - Epoch [164/200], Loss: 0.0270\n",
      "Validation - Epoch [164/200], Loss: 0.0260\n",
      "Training - Epoch [165/200], Loss: 0.0280\n",
      "Validation - Epoch [165/200], Loss: 0.0270\n",
      "Training - Epoch [166/200], Loss: 0.0266\n",
      "Validation - Epoch [166/200], Loss: 0.0246\n",
      "Training - Epoch [167/200], Loss: 0.0258\n",
      "Validation - Epoch [167/200], Loss: 0.0262\n",
      "Training - Epoch [168/200], Loss: 0.0254\n",
      "Validation - Epoch [168/200], Loss: 0.0263\n",
      "Training - Epoch [169/200], Loss: 0.0253\n",
      "Validation - Epoch [169/200], Loss: 0.0252\n",
      "Training - Epoch [170/200], Loss: 0.0255\n",
      "Validation - Epoch [170/200], Loss: 0.0281\n",
      "Training - Epoch [171/200], Loss: 0.0253\n",
      "Validation - Epoch [171/200], Loss: 0.0264\n",
      "Training - Epoch [172/200], Loss: 0.0252\n",
      "Validation - Epoch [172/200], Loss: 0.0248\n",
      "Training - Epoch [173/200], Loss: 0.0253\n",
      "Validation - Epoch [173/200], Loss: 0.0250\n",
      "Training - Epoch [174/200], Loss: 0.0252\n",
      "Validation - Epoch [174/200], Loss: 0.0253\n",
      "Training - Epoch [175/200], Loss: 0.0252\n",
      "Validation - Epoch [175/200], Loss: 0.0283\n",
      "Training - Epoch [176/200], Loss: 0.0260\n",
      "Validation - Epoch [176/200], Loss: 0.0255\n",
      "Training - Epoch [177/200], Loss: 0.0253\n",
      "Validation - Epoch [177/200], Loss: 0.0250\n",
      "Training - Epoch [178/200], Loss: 0.0252\n",
      "Validation - Epoch [178/200], Loss: 0.0248\n",
      "Training - Epoch [179/200], Loss: 0.0254\n",
      "Validation - Epoch [179/200], Loss: 0.0254\n",
      "Training - Epoch [180/200], Loss: 0.0251\n",
      "Validation - Epoch [180/200], Loss: 0.0248\n",
      "Training - Epoch [181/200], Loss: 0.0249\n",
      "Validation - Epoch [181/200], Loss: 0.0253\n",
      "Training - Epoch [182/200], Loss: 0.0250\n",
      "Validation - Epoch [182/200], Loss: 0.0239\n",
      "Training - Epoch [183/200], Loss: 0.0252\n",
      "Validation - Epoch [183/200], Loss: 0.0251\n",
      "Training - Epoch [184/200], Loss: 0.0267\n",
      "Validation - Epoch [184/200], Loss: 0.0276\n",
      "Training - Epoch [185/200], Loss: 0.0253\n",
      "Validation - Epoch [185/200], Loss: 0.0265\n",
      "Training - Epoch [186/200], Loss: 0.0259\n",
      "Validation - Epoch [186/200], Loss: 0.0253\n",
      "Training - Epoch [187/200], Loss: 0.0257\n",
      "Validation - Epoch [187/200], Loss: 0.0247\n",
      "Training - Epoch [188/200], Loss: 0.0255\n",
      "Validation - Epoch [188/200], Loss: 0.0249\n",
      "Training - Epoch [189/200], Loss: 0.0249\n",
      "Validation - Epoch [189/200], Loss: 0.0248\n",
      "Training - Epoch [190/200], Loss: 0.0254\n",
      "Validation - Epoch [190/200], Loss: 0.0263\n",
      "Training - Epoch [191/200], Loss: 0.0261\n",
      "Validation - Epoch [191/200], Loss: 0.0243\n",
      "Training - Epoch [192/200], Loss: 0.0255\n",
      "Validation - Epoch [192/200], Loss: 0.0246\n",
      "Training - Epoch [193/200], Loss: 0.0252\n",
      "Validation - Epoch [193/200], Loss: 0.0244\n",
      "Training - Epoch [194/200], Loss: 0.0253\n",
      "Validation - Epoch [194/200], Loss: 0.0246\n",
      "Training - Epoch [195/200], Loss: 0.0252\n",
      "Validation - Epoch [195/200], Loss: 0.0272\n",
      "Training - Epoch [196/200], Loss: 0.0250\n",
      "Validation - Epoch [196/200], Loss: 0.0242\n",
      "Training - Epoch [197/200], Loss: 0.0252\n",
      "Validation - Epoch [197/200], Loss: 0.0257\n",
      "Training - Epoch [198/200], Loss: 0.0250\n",
      "Validation - Epoch [198/200], Loss: 0.0239\n",
      "Training - Epoch [199/200], Loss: 0.0249\n",
      "Validation - Epoch [199/200], Loss: 0.0293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch [200/200], Loss: 0.0249\n",
      "Validation - Epoch [200/200], Loss: 0.0251\n"
     ]
    }
   ],
   "source": [
    "# Transformer Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, hidden_dim, num_layers, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.squeeze(1)\n",
    "        x = self.fc(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.tensor(features.values, dtype=torch.float32) \n",
    "        self.targets = torch.tensor(targets.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = X_train.shape[1]  # Dimension of input features\n",
    "num_heads = 2  # Number of attention heads = 2\n",
    "hidden_dim = 200  # Hidden layers of the model = 200\n",
    "num_layers = 2  # Number of transformer layers = 2\n",
    "dropout = 0.1  # Dropout probability = 0.1\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "model = TransformerModel(input_dim=input_dim, num_heads=num_heads, hidden_dim=hidden_dim,\n",
    "                          num_layers=num_layers, dropout=dropout)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression task\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Optimizer used is Adam and learning rate is 0.001\n",
    "\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(inputs)\n",
    "    average_loss = total_loss / len(train_dataset)\n",
    "    print(f'Training - Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for inputs, labels in test_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * len(inputs)\n",
    "        average_loss = total_loss / len(test_dataset)\n",
    "        print(f'Validation - Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        # Stored true labels and predictions\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(outputs.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "733126f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        # Stored true labels and predictions\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(outputs.numpy())\n",
    "\n",
    "# Converted y_true and y_pred to numpy arrays\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Computed confusion matrix\n",
    "cm = confusion_matrix(np.round(y_true), np.round(y_pred))\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c7dac54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.025086708\n",
      "Mean Absolute Error: 0.107695416\n",
      "Root Mean Squared Error: 0.15838784\n",
      "R-squared Score: 0.6969387518581306\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Computed Mean Squared Error\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "# Computed Mean Absolute Error\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# Computed Root Mean Squared Error\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Computed R2-Score\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15145aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alarm triggered for 11 consecutive faults on 2019-06-06.\n",
      "Alarm triggered for 10 consecutive faults on 2019-05-08.\n",
      "Alarm triggered for 8 consecutive faults on 2019-04-19.\n",
      "Alarm triggered for 7 consecutive faults on 2019-04-30.\n",
      "Alarm triggered for 7 consecutive faults on 2019-04-09.\n",
      "Alarm triggered for 7 consecutive faults on 2019-05-18.\n",
      "Alarm triggered for 7 consecutive faults on 2019-04-14.\n",
      "Alarm triggered for 7 consecutive faults on 2019-05-04.\n",
      "Alarm triggered for 7 consecutive faults on 2019-04-17.\n",
      "Alarm triggered for 7 consecutive faults on 2019-04-20.\n",
      "Alarm triggered for 6 consecutive faults on 2019-06-04.\n",
      "Alarm triggered for 6 consecutive faults on 2019-05-25.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-21.\n",
      "Alarm triggered for 6 consecutive faults on 2019-06-07.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-04.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-28.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-07.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-24.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-15.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-26.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-27.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-29.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-30.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-24.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-31.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-08.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-10.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-11.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-10.\n",
      "Alarm triggered for 4 consecutive faults on 2019-05-21.\n",
      "Alarm triggered for 4 consecutive faults on 2019-05-19.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-18.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-16.\n",
      "Alarm triggered for 4 consecutive faults on 2019-05-09.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-22.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-26.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-27.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-28.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-29.\n"
     ]
    }
   ],
   "source": [
    "# Function to check for four consecutive faults in a day and trigger alarms\n",
    "def check_consecutive_faults(fault_indices, df, window=3):\n",
    "    fault_timestamps = df.index[fault_indices]\n",
    "\n",
    "    grouped_by_day = fault_timestamps.to_series().dt.date\n",
    "\n",
    "    # Checked if there are three or more consecutive faults within the same day\n",
    "    daily_fault_count = grouped_by_day.value_counts()\n",
    "    for date, count in daily_fault_count.items():\n",
    "        if count >= window:\n",
    "            print(f\"Alarm triggered for {count} consecutive faults on {date}.\")\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_ac_power = model(X_test_tensor)  # Model predictions\n",
    "    actual_ac_power = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "    # Absolute residuals between predicted and actual AC power\n",
    "    residuals = torch.abs(predicted_ac_power - actual_ac_power)\n",
    "\n",
    "# Calculated the standard deviation for setting the fault threshold\n",
    "sigma = torch.std(residuals).item()\n",
    "threshold = 2 * sigma  # Set the threshold as 2 * sigma\n",
    "\n",
    "anomalies = (residuals > threshold).int()\n",
    "\n",
    "fault_indices = torch.nonzero(anomalies).squeeze().tolist()\n",
    "\n",
    "check_consecutive_faults(fault_indices, df, window=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b76ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
