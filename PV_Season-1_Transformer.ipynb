{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12f0fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score, classification_report, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22a86f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\My PC\\Desktop\\Solar PV Fault Research\\Seasonal_Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41e29b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Season-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce1683f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Inv</th>\n",
       "      <th>AC_Real_Power</th>\n",
       "      <th>AC_Current</th>\n",
       "      <th>DC_Power</th>\n",
       "      <th>DC_Current</th>\n",
       "      <th>Tilt_Irradiation_1</th>\n",
       "      <th>Temp_Ambient_1</th>\n",
       "      <th>Temp_Module_1</th>\n",
       "      <th>Wind_Speed_1</th>\n",
       "      <th>Hor_Irradiation_1</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12979</td>\n",
       "      <td>12979</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>05:45:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12980</td>\n",
       "      <td>12980</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12981</td>\n",
       "      <td>12981</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>06:15:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12982</td>\n",
       "      <td>12982</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>06:30:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12983</td>\n",
       "      <td>12983</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>06:45:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60398</th>\n",
       "      <td>13956</td>\n",
       "      <td>13956</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>18:30:00</td>\n",
       "      <td>Inv-16</td>\n",
       "      <td>5.07</td>\n",
       "      <td>12.17</td>\n",
       "      <td>6.26</td>\n",
       "      <td>13.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60399</th>\n",
       "      <td>13957</td>\n",
       "      <td>13957</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>18:45:00</td>\n",
       "      <td>Inv-16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.7</td>\n",
       "      <td>27.2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60400</th>\n",
       "      <td>13958</td>\n",
       "      <td>13958</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>Inv-16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60401</th>\n",
       "      <td>13959</td>\n",
       "      <td>13959</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>19:15:00</td>\n",
       "      <td>Inv-16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60402</th>\n",
       "      <td>13960</td>\n",
       "      <td>13960</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>19:30:00</td>\n",
       "      <td>Inv-16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.1</td>\n",
       "      <td>25.7</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60403 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0        Date      Time     Inv  AC_Real_Power  \\\n",
       "0             12979       12979  2020-01-01  05:45:00   Inv-1           0.00   \n",
       "1             12980       12980  2020-01-01  06:00:00   Inv-1           0.00   \n",
       "2             12981       12981  2020-01-01  06:15:00   Inv-1           0.00   \n",
       "3             12982       12982  2020-01-01  06:30:00   Inv-1           0.00   \n",
       "4             12983       12983  2020-01-01  06:45:00   Inv-1           0.00   \n",
       "...             ...         ...         ...       ...     ...            ...   \n",
       "60398         13956       13956  2020-02-29  18:30:00  Inv-16           5.07   \n",
       "60399         13957       13957  2020-02-29  18:45:00  Inv-16           0.12   \n",
       "60400         13958       13958  2020-02-29  19:00:00  Inv-16           0.00   \n",
       "60401         13959       13959  2020-02-29  19:15:00  Inv-16           0.00   \n",
       "60402         13960       13960  2020-02-29  19:30:00  Inv-16           0.00   \n",
       "\n",
       "       AC_Current  DC_Power  DC_Current  Tilt_Irradiation_1  Temp_Ambient_1  \\\n",
       "0            0.00      0.00        5.20                 0.0            13.0   \n",
       "1            0.00      0.00        5.16                 0.0            13.1   \n",
       "2            0.00      0.00        5.04                 0.0            12.9   \n",
       "3            0.00      0.00        5.06                 0.0            12.8   \n",
       "4            0.00      0.00        5.04                 0.0            12.8   \n",
       "...           ...       ...         ...                 ...             ...   \n",
       "60398       12.17      6.26       13.56                 0.0            26.4   \n",
       "60399        0.30      0.14        0.42                 0.0            25.7   \n",
       "60400        0.00      0.00        0.00                 0.0            24.1   \n",
       "60401        0.00      0.00        0.17                 0.0            24.3   \n",
       "60402        0.00      0.00        1.76                 0.0            25.1   \n",
       "\n",
       "       Temp_Module_1  Wind_Speed_1  Hor_Irradiation_1  Operation  \n",
       "0               15.2         0.594                0.4          1  \n",
       "1               15.3         0.609                0.4          1  \n",
       "2               15.0         0.535                0.4          1  \n",
       "3               15.0         0.619                0.4          1  \n",
       "4               15.0         0.752                0.5          1  \n",
       "...              ...           ...                ...        ...  \n",
       "60398           28.6         0.500                3.2          1  \n",
       "60399           27.2         0.500                0.2          1  \n",
       "60400           26.1         0.500                0.1          1  \n",
       "60401           25.7         0.728                0.1          1  \n",
       "60402           25.7         1.010                0.1          1  \n",
       "\n",
       "[60403 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a6d0d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60403 entries, 0 to 60402\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Unnamed: 0.1        60403 non-null  int64  \n",
      " 1   Unnamed: 0          60403 non-null  int64  \n",
      " 2   Date                60403 non-null  object \n",
      " 3   Time                60403 non-null  object \n",
      " 4   Inv                 60403 non-null  object \n",
      " 5   AC_Real_Power       60403 non-null  float64\n",
      " 6   AC_Current          60403 non-null  float64\n",
      " 7   DC_Power            60403 non-null  float64\n",
      " 8   DC_Current          60403 non-null  float64\n",
      " 9   Tilt_Irradiation_1  60403 non-null  float64\n",
      " 10  Temp_Ambient_1      60403 non-null  float64\n",
      " 11  Temp_Module_1       60403 non-null  float64\n",
      " 12  Wind_Speed_1        60403 non-null  float64\n",
      " 13  Hor_Irradiation_1   60403 non-null  float64\n",
      " 14  Operation           60403 non-null  int64  \n",
      "dtypes: float64(9), int64(3), object(3)\n",
      "memory usage: 6.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Inv</th>\n",
       "      <th>AC_Real_Power</th>\n",
       "      <th>AC_Current</th>\n",
       "      <th>DC_Power</th>\n",
       "      <th>DC_Current</th>\n",
       "      <th>Tilt_Irradiation_1</th>\n",
       "      <th>Temp_Ambient_1</th>\n",
       "      <th>Temp_Module_1</th>\n",
       "      <th>Wind_Speed_1</th>\n",
       "      <th>Hor_Irradiation_1</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12979</td>\n",
       "      <td>12979</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>05:45:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12980</td>\n",
       "      <td>12980</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12981</td>\n",
       "      <td>12981</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>06:15:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12982</td>\n",
       "      <td>12982</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>06:30:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12983</td>\n",
       "      <td>12983</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>06:45:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0        Date      Time    Inv  AC_Real_Power  \\\n",
       "0         12979       12979  2020-01-01  05:45:00  Inv-1            0.0   \n",
       "1         12980       12980  2020-01-01  06:00:00  Inv-1            0.0   \n",
       "2         12981       12981  2020-01-01  06:15:00  Inv-1            0.0   \n",
       "3         12982       12982  2020-01-01  06:30:00  Inv-1            0.0   \n",
       "4         12983       12983  2020-01-01  06:45:00  Inv-1            0.0   \n",
       "\n",
       "   AC_Current  DC_Power  DC_Current  Tilt_Irradiation_1  Temp_Ambient_1  \\\n",
       "0         0.0       0.0        5.20                 0.0            13.0   \n",
       "1         0.0       0.0        5.16                 0.0            13.1   \n",
       "2         0.0       0.0        5.04                 0.0            12.9   \n",
       "3         0.0       0.0        5.06                 0.0            12.8   \n",
       "4         0.0       0.0        5.04                 0.0            12.8   \n",
       "\n",
       "   Temp_Module_1  Wind_Speed_1  Hor_Irradiation_1  Operation  \n",
       "0           15.2         0.594                0.4          1  \n",
       "1           15.3         0.609                0.4          1  \n",
       "2           15.0         0.535                0.4          1  \n",
       "3           15.0         0.619                0.4          1  \n",
       "4           15.0         0.752                0.5          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.info(),df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7e5d962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 60403\n",
      "Number of columns: 15\n"
     ]
    }
   ],
   "source": [
    "num_rows, num_columns = df.shape\n",
    "\n",
    "print(\"Number of rows:\", num_rows)\n",
    "print(\"Number of columns:\", num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b73609de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "028b0ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4331e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('DateTime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "076396d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Date','Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e7d3adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = pd.Timestamp(\"07:00:00\")\n",
    "end_time = pd.Timestamp(\"18:30:00\")\n",
    "\n",
    "# Filtering the data to retain only the rows within the operational hours\n",
    "df = df[(df.index.time >= pd.to_datetime('7:00:00').time()) & (df.index.time <= pd.to_datetime('18:30:00').time())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f80ad2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inv</th>\n",
       "      <th>AC_Real_Power</th>\n",
       "      <th>AC_Current</th>\n",
       "      <th>DC_Power</th>\n",
       "      <th>DC_Current</th>\n",
       "      <th>Tilt_Irradiation_1</th>\n",
       "      <th>Temp_Ambient_1</th>\n",
       "      <th>Temp_Module_1</th>\n",
       "      <th>Wind_Speed_1</th>\n",
       "      <th>Hor_Irradiation_1</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 07:00:00</th>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 07:15:00</th>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.59</td>\n",
       "      <td>4.8</td>\n",
       "      <td>12.4</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.535</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 07:30:00</th>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.17</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.93</td>\n",
       "      <td>24.6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.540</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 07:45:00</th>\n",
       "      <td>Inv-1</td>\n",
       "      <td>5.88</td>\n",
       "      <td>10.41</td>\n",
       "      <td>7.25</td>\n",
       "      <td>19.57</td>\n",
       "      <td>57.9</td>\n",
       "      <td>13.8</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.193</td>\n",
       "      <td>42.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 08:00:00</th>\n",
       "      <td>Inv-1</td>\n",
       "      <td>16.84</td>\n",
       "      <td>31.47</td>\n",
       "      <td>20.38</td>\n",
       "      <td>40.12</td>\n",
       "      <td>101.8</td>\n",
       "      <td>14.7</td>\n",
       "      <td>18.3</td>\n",
       "      <td>1.213</td>\n",
       "      <td>67.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Inv  AC_Real_Power  AC_Current  DC_Power  DC_Current  \\\n",
       "DateTime                                                                      \n",
       "2020-01-01 07:00:00  Inv-1           0.00        0.00      0.00        2.97   \n",
       "2020-01-01 07:15:00  Inv-1           0.00        0.00      0.00        2.59   \n",
       "2020-01-01 07:30:00  Inv-1           0.17        3.92      0.21        3.93   \n",
       "2020-01-01 07:45:00  Inv-1           5.88       10.41      7.25       19.57   \n",
       "2020-01-01 08:00:00  Inv-1          16.84       31.47     20.38       40.12   \n",
       "\n",
       "                     Tilt_Irradiation_1  Temp_Ambient_1  Temp_Module_1  \\\n",
       "DateTime                                                                 \n",
       "2020-01-01 07:00:00                 0.0            12.5           14.5   \n",
       "2020-01-01 07:15:00                 4.8            12.4           14.5   \n",
       "2020-01-01 07:30:00                24.6            13.0           15.1   \n",
       "2020-01-01 07:45:00                57.9            13.8           16.5   \n",
       "2020-01-01 08:00:00               101.8            14.7           18.3   \n",
       "\n",
       "                     Wind_Speed_1  Hor_Irradiation_1  Operation  \n",
       "DateTime                                                         \n",
       "2020-01-01 07:00:00         0.500                2.4          1  \n",
       "2020-01-01 07:15:00         0.535                8.9          1  \n",
       "2020-01-01 07:30:00         0.540               23.0          1  \n",
       "2020-01-01 07:45:00         1.193               42.7          1  \n",
       "2020-01-01 08:00:00         1.213               67.2          1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "788c29a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inv                   0\n",
      "AC_Real_Power         0\n",
      "AC_Current            0\n",
      "DC_Power              0\n",
      "DC_Current            0\n",
      "Tilt_Irradiation_1    0\n",
      "Temp_Ambient_1        0\n",
      "Temp_Module_1         0\n",
      "Wind_Speed_1          0\n",
      "Hor_Irradiation_1     0\n",
      "Operation             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_data = df.isnull().sum()\n",
    "print(missing_data)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03cc0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "operational_data = df\n",
    "numerical_features = ['AC_Real_Power','Tilt_Irradiation_1', 'Temp_Ambient_1', 'Hor_Irradiation_1']\n",
    "\n",
    "# Normalization of the features\n",
    "operational_data[numerical_features] = scaler.fit_transform(operational_data[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58ea7af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = operational_data[['Tilt_Irradiation_1', 'Temp_Ambient_1', 'Hor_Irradiation_1']]\n",
    "y = operational_data['AC_Real_Power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f02489ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch [1/200], Loss: 0.0289\n",
      "Validation - Epoch [1/200], Loss: 0.0125\n",
      "Training - Epoch [2/200], Loss: 0.0099\n",
      "Validation - Epoch [2/200], Loss: 0.0116\n",
      "Training - Epoch [3/200], Loss: 0.0095\n",
      "Validation - Epoch [3/200], Loss: 0.0099\n",
      "Training - Epoch [4/200], Loss: 0.0091\n",
      "Validation - Epoch [4/200], Loss: 0.0100\n",
      "Training - Epoch [5/200], Loss: 0.0090\n",
      "Validation - Epoch [5/200], Loss: 0.0094\n",
      "Training - Epoch [6/200], Loss: 0.0092\n",
      "Validation - Epoch [6/200], Loss: 0.0077\n",
      "Training - Epoch [7/200], Loss: 0.0090\n",
      "Validation - Epoch [7/200], Loss: 0.0079\n",
      "Training - Epoch [8/200], Loss: 0.0097\n",
      "Validation - Epoch [8/200], Loss: 0.0119\n",
      "Training - Epoch [9/200], Loss: 0.0089\n",
      "Validation - Epoch [9/200], Loss: 0.0091\n",
      "Training - Epoch [10/200], Loss: 0.0101\n",
      "Validation - Epoch [10/200], Loss: 0.0084\n",
      "Training - Epoch [11/200], Loss: 0.0089\n",
      "Validation - Epoch [11/200], Loss: 0.0081\n",
      "Training - Epoch [12/200], Loss: 0.0085\n",
      "Validation - Epoch [12/200], Loss: 0.0104\n",
      "Training - Epoch [13/200], Loss: 0.0084\n",
      "Validation - Epoch [13/200], Loss: 0.0073\n",
      "Training - Epoch [14/200], Loss: 0.0166\n",
      "Validation - Epoch [14/200], Loss: 0.0114\n",
      "Training - Epoch [15/200], Loss: 0.0101\n",
      "Validation - Epoch [15/200], Loss: 0.0086\n",
      "Training - Epoch [16/200], Loss: 0.0098\n",
      "Validation - Epoch [16/200], Loss: 0.0103\n",
      "Training - Epoch [17/200], Loss: 0.0097\n",
      "Validation - Epoch [17/200], Loss: 0.0088\n",
      "Training - Epoch [18/200], Loss: 0.0104\n",
      "Validation - Epoch [18/200], Loss: 0.0095\n",
      "Training - Epoch [19/200], Loss: 0.0097\n",
      "Validation - Epoch [19/200], Loss: 0.0166\n",
      "Training - Epoch [20/200], Loss: 0.0096\n",
      "Validation - Epoch [20/200], Loss: 0.0086\n",
      "Training - Epoch [21/200], Loss: 0.0096\n",
      "Validation - Epoch [21/200], Loss: 0.0089\n",
      "Training - Epoch [22/200], Loss: 0.0094\n",
      "Validation - Epoch [22/200], Loss: 0.0083\n",
      "Training - Epoch [23/200], Loss: 0.0093\n",
      "Validation - Epoch [23/200], Loss: 0.0083\n",
      "Training - Epoch [24/200], Loss: 0.0091\n",
      "Validation - Epoch [24/200], Loss: 0.0084\n",
      "Training - Epoch [25/200], Loss: 0.0090\n",
      "Validation - Epoch [25/200], Loss: 0.0088\n",
      "Training - Epoch [26/200], Loss: 0.0089\n",
      "Validation - Epoch [26/200], Loss: 0.0086\n",
      "Training - Epoch [27/200], Loss: 0.0087\n",
      "Validation - Epoch [27/200], Loss: 0.0088\n",
      "Training - Epoch [28/200], Loss: 0.0099\n",
      "Validation - Epoch [28/200], Loss: 0.0084\n",
      "Training - Epoch [29/200], Loss: 0.0087\n",
      "Validation - Epoch [29/200], Loss: 0.0079\n",
      "Training - Epoch [30/200], Loss: 0.0082\n",
      "Validation - Epoch [30/200], Loss: 0.0091\n",
      "Training - Epoch [31/200], Loss: 0.0083\n",
      "Validation - Epoch [31/200], Loss: 0.0087\n",
      "Training - Epoch [32/200], Loss: 0.0083\n",
      "Validation - Epoch [32/200], Loss: 0.0077\n",
      "Training - Epoch [33/200], Loss: 0.0085\n",
      "Validation - Epoch [33/200], Loss: 0.0085\n",
      "Training - Epoch [34/200], Loss: 0.0083\n",
      "Validation - Epoch [34/200], Loss: 0.0084\n",
      "Training - Epoch [35/200], Loss: 0.0081\n",
      "Validation - Epoch [35/200], Loss: 0.0082\n",
      "Training - Epoch [36/200], Loss: 0.0082\n",
      "Validation - Epoch [36/200], Loss: 0.0082\n",
      "Training - Epoch [37/200], Loss: 0.0080\n",
      "Validation - Epoch [37/200], Loss: 0.0078\n",
      "Training - Epoch [38/200], Loss: 0.0079\n",
      "Validation - Epoch [38/200], Loss: 0.0076\n",
      "Training - Epoch [39/200], Loss: 0.0085\n",
      "Validation - Epoch [39/200], Loss: 0.0073\n",
      "Training - Epoch [40/200], Loss: 0.0080\n",
      "Validation - Epoch [40/200], Loss: 0.0078\n",
      "Training - Epoch [41/200], Loss: 0.0081\n",
      "Validation - Epoch [41/200], Loss: 0.0076\n",
      "Training - Epoch [42/200], Loss: 0.0079\n",
      "Validation - Epoch [42/200], Loss: 0.0087\n",
      "Training - Epoch [43/200], Loss: 0.0082\n",
      "Validation - Epoch [43/200], Loss: 0.0074\n",
      "Training - Epoch [44/200], Loss: 0.0080\n",
      "Validation - Epoch [44/200], Loss: 0.0084\n",
      "Training - Epoch [45/200], Loss: 0.0079\n",
      "Validation - Epoch [45/200], Loss: 0.0083\n",
      "Training - Epoch [46/200], Loss: 0.0085\n",
      "Validation - Epoch [46/200], Loss: 0.0080\n",
      "Training - Epoch [47/200], Loss: 0.0094\n",
      "Validation - Epoch [47/200], Loss: 0.0094\n",
      "Training - Epoch [48/200], Loss: 0.0082\n",
      "Validation - Epoch [48/200], Loss: 0.0082\n",
      "Training - Epoch [49/200], Loss: 0.0080\n",
      "Validation - Epoch [49/200], Loss: 0.0085\n",
      "Training - Epoch [50/200], Loss: 0.0080\n",
      "Validation - Epoch [50/200], Loss: 0.0083\n",
      "Training - Epoch [51/200], Loss: 0.0081\n",
      "Validation - Epoch [51/200], Loss: 0.0076\n",
      "Training - Epoch [52/200], Loss: 0.0081\n",
      "Validation - Epoch [52/200], Loss: 0.0081\n",
      "Training - Epoch [53/200], Loss: 0.0081\n",
      "Validation - Epoch [53/200], Loss: 0.0080\n",
      "Training - Epoch [54/200], Loss: 0.0140\n",
      "Validation - Epoch [54/200], Loss: 0.0081\n",
      "Training - Epoch [55/200], Loss: 0.0088\n",
      "Validation - Epoch [55/200], Loss: 0.0111\n",
      "Training - Epoch [56/200], Loss: 0.0084\n",
      "Validation - Epoch [56/200], Loss: 0.0088\n",
      "Training - Epoch [57/200], Loss: 0.0080\n",
      "Validation - Epoch [57/200], Loss: 0.0077\n",
      "Training - Epoch [58/200], Loss: 0.0079\n",
      "Validation - Epoch [58/200], Loss: 0.0077\n",
      "Training - Epoch [59/200], Loss: 0.0078\n",
      "Validation - Epoch [59/200], Loss: 0.0084\n",
      "Training - Epoch [60/200], Loss: 0.0079\n",
      "Validation - Epoch [60/200], Loss: 0.0097\n",
      "Training - Epoch [61/200], Loss: 0.0084\n",
      "Validation - Epoch [61/200], Loss: 0.0108\n",
      "Training - Epoch [62/200], Loss: 0.0086\n",
      "Validation - Epoch [62/200], Loss: 0.0087\n",
      "Training - Epoch [63/200], Loss: 0.0081\n",
      "Validation - Epoch [63/200], Loss: 0.0088\n",
      "Training - Epoch [64/200], Loss: 0.0080\n",
      "Validation - Epoch [64/200], Loss: 0.0072\n",
      "Training - Epoch [65/200], Loss: 0.0078\n",
      "Validation - Epoch [65/200], Loss: 0.0082\n",
      "Training - Epoch [66/200], Loss: 0.0079\n",
      "Validation - Epoch [66/200], Loss: 0.0082\n",
      "Training - Epoch [67/200], Loss: 0.0080\n",
      "Validation - Epoch [67/200], Loss: 0.0078\n",
      "Training - Epoch [68/200], Loss: 0.0078\n",
      "Validation - Epoch [68/200], Loss: 0.0076\n",
      "Training - Epoch [69/200], Loss: 0.0082\n",
      "Validation - Epoch [69/200], Loss: 0.0075\n",
      "Training - Epoch [70/200], Loss: 0.0079\n",
      "Validation - Epoch [70/200], Loss: 0.0079\n",
      "Training - Epoch [71/200], Loss: 0.0090\n",
      "Validation - Epoch [71/200], Loss: 0.0085\n",
      "Training - Epoch [72/200], Loss: 0.0129\n",
      "Validation - Epoch [72/200], Loss: 0.0114\n",
      "Training - Epoch [73/200], Loss: 0.0092\n",
      "Validation - Epoch [73/200], Loss: 0.0091\n",
      "Training - Epoch [74/200], Loss: 0.0088\n",
      "Validation - Epoch [74/200], Loss: 0.0087\n",
      "Training - Epoch [75/200], Loss: 0.0083\n",
      "Validation - Epoch [75/200], Loss: 0.0088\n",
      "Training - Epoch [76/200], Loss: 0.0079\n",
      "Validation - Epoch [76/200], Loss: 0.0082\n",
      "Training - Epoch [77/200], Loss: 0.0080\n",
      "Validation - Epoch [77/200], Loss: 0.0082\n",
      "Training - Epoch [78/200], Loss: 0.0078\n",
      "Validation - Epoch [78/200], Loss: 0.0079\n",
      "Training - Epoch [79/200], Loss: 0.0079\n",
      "Validation - Epoch [79/200], Loss: 0.0076\n",
      "Training - Epoch [80/200], Loss: 0.0081\n",
      "Validation - Epoch [80/200], Loss: 0.0082\n",
      "Training - Epoch [81/200], Loss: 0.0080\n",
      "Validation - Epoch [81/200], Loss: 0.0081\n",
      "Training - Epoch [82/200], Loss: 0.0079\n",
      "Validation - Epoch [82/200], Loss: 0.0091\n",
      "Training - Epoch [83/200], Loss: 0.0077\n",
      "Validation - Epoch [83/200], Loss: 0.0079\n",
      "Training - Epoch [84/200], Loss: 0.0078\n",
      "Validation - Epoch [84/200], Loss: 0.0084\n",
      "Training - Epoch [85/200], Loss: 0.0078\n",
      "Validation - Epoch [85/200], Loss: 0.0088\n",
      "Training - Epoch [86/200], Loss: 0.0077\n",
      "Validation - Epoch [86/200], Loss: 0.0088\n",
      "Training - Epoch [87/200], Loss: 0.0077\n",
      "Validation - Epoch [87/200], Loss: 0.0079\n",
      "Training - Epoch [88/200], Loss: 0.0089\n",
      "Validation - Epoch [88/200], Loss: 0.0088\n",
      "Training - Epoch [89/200], Loss: 0.0084\n",
      "Validation - Epoch [89/200], Loss: 0.0087\n",
      "Training - Epoch [90/200], Loss: 0.0080\n",
      "Validation - Epoch [90/200], Loss: 0.0089\n",
      "Training - Epoch [91/200], Loss: 0.0082\n",
      "Validation - Epoch [91/200], Loss: 0.0082\n",
      "Training - Epoch [92/200], Loss: 0.0078\n",
      "Validation - Epoch [92/200], Loss: 0.0078\n",
      "Training - Epoch [93/200], Loss: 0.0077\n",
      "Validation - Epoch [93/200], Loss: 0.0087\n",
      "Training - Epoch [94/200], Loss: 0.0078\n",
      "Validation - Epoch [94/200], Loss: 0.0081\n",
      "Training - Epoch [95/200], Loss: 0.0078\n",
      "Validation - Epoch [95/200], Loss: 0.0076\n",
      "Training - Epoch [96/200], Loss: 0.0082\n",
      "Validation - Epoch [96/200], Loss: 0.0092\n",
      "Training - Epoch [97/200], Loss: 0.0079\n",
      "Validation - Epoch [97/200], Loss: 0.0079\n",
      "Training - Epoch [98/200], Loss: 0.0081\n",
      "Validation - Epoch [98/200], Loss: 0.0082\n",
      "Training - Epoch [99/200], Loss: 0.0084\n",
      "Validation - Epoch [99/200], Loss: 0.0084\n",
      "Training - Epoch [100/200], Loss: 0.0081\n",
      "Validation - Epoch [100/200], Loss: 0.0078\n",
      "Training - Epoch [101/200], Loss: 0.0080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch [101/200], Loss: 0.0085\n",
      "Training - Epoch [102/200], Loss: 0.0077\n",
      "Validation - Epoch [102/200], Loss: 0.0082\n",
      "Training - Epoch [103/200], Loss: 0.0078\n",
      "Validation - Epoch [103/200], Loss: 0.0079\n",
      "Training - Epoch [104/200], Loss: 0.0077\n",
      "Validation - Epoch [104/200], Loss: 0.0074\n",
      "Training - Epoch [105/200], Loss: 0.0081\n",
      "Validation - Epoch [105/200], Loss: 0.0083\n",
      "Training - Epoch [106/200], Loss: 0.0080\n",
      "Validation - Epoch [106/200], Loss: 0.0075\n",
      "Training - Epoch [107/200], Loss: 0.0079\n",
      "Validation - Epoch [107/200], Loss: 0.0076\n",
      "Training - Epoch [108/200], Loss: 0.0078\n",
      "Validation - Epoch [108/200], Loss: 0.0076\n",
      "Training - Epoch [109/200], Loss: 0.0081\n",
      "Validation - Epoch [109/200], Loss: 0.0099\n",
      "Training - Epoch [110/200], Loss: 0.0083\n",
      "Validation - Epoch [110/200], Loss: 0.0074\n",
      "Training - Epoch [111/200], Loss: 0.0077\n",
      "Validation - Epoch [111/200], Loss: 0.0071\n",
      "Training - Epoch [112/200], Loss: 0.0077\n",
      "Validation - Epoch [112/200], Loss: 0.0075\n",
      "Training - Epoch [113/200], Loss: 0.0078\n",
      "Validation - Epoch [113/200], Loss: 0.0075\n",
      "Training - Epoch [114/200], Loss: 0.0079\n",
      "Validation - Epoch [114/200], Loss: 0.0085\n",
      "Training - Epoch [115/200], Loss: 0.0080\n",
      "Validation - Epoch [115/200], Loss: 0.0076\n",
      "Training - Epoch [116/200], Loss: 0.0078\n",
      "Validation - Epoch [116/200], Loss: 0.0078\n",
      "Training - Epoch [117/200], Loss: 0.0076\n",
      "Validation - Epoch [117/200], Loss: 0.0077\n",
      "Training - Epoch [118/200], Loss: 0.0076\n",
      "Validation - Epoch [118/200], Loss: 0.0081\n",
      "Training - Epoch [119/200], Loss: 0.0076\n",
      "Validation - Epoch [119/200], Loss: 0.0082\n",
      "Training - Epoch [120/200], Loss: 0.0076\n",
      "Validation - Epoch [120/200], Loss: 0.0095\n",
      "Training - Epoch [121/200], Loss: 0.0089\n",
      "Validation - Epoch [121/200], Loss: 0.0093\n",
      "Training - Epoch [122/200], Loss: 0.0083\n",
      "Validation - Epoch [122/200], Loss: 0.0083\n",
      "Training - Epoch [123/200], Loss: 0.0093\n",
      "Validation - Epoch [123/200], Loss: 0.0080\n",
      "Training - Epoch [124/200], Loss: 0.0081\n",
      "Validation - Epoch [124/200], Loss: 0.0078\n",
      "Training - Epoch [125/200], Loss: 0.0079\n",
      "Validation - Epoch [125/200], Loss: 0.0084\n",
      "Training - Epoch [126/200], Loss: 0.0079\n",
      "Validation - Epoch [126/200], Loss: 0.0079\n",
      "Training - Epoch [127/200], Loss: 0.0078\n",
      "Validation - Epoch [127/200], Loss: 0.0082\n",
      "Training - Epoch [128/200], Loss: 0.0077\n",
      "Validation - Epoch [128/200], Loss: 0.0073\n",
      "Training - Epoch [129/200], Loss: 0.0078\n",
      "Validation - Epoch [129/200], Loss: 0.0080\n",
      "Training - Epoch [130/200], Loss: 0.0081\n",
      "Validation - Epoch [130/200], Loss: 0.0086\n",
      "Training - Epoch [131/200], Loss: 0.0077\n",
      "Validation - Epoch [131/200], Loss: 0.0080\n",
      "Training - Epoch [132/200], Loss: 0.0078\n",
      "Validation - Epoch [132/200], Loss: 0.0082\n",
      "Training - Epoch [133/200], Loss: 0.0077\n",
      "Validation - Epoch [133/200], Loss: 0.0083\n",
      "Training - Epoch [134/200], Loss: 0.0079\n",
      "Validation - Epoch [134/200], Loss: 0.0075\n",
      "Training - Epoch [135/200], Loss: 0.0076\n",
      "Validation - Epoch [135/200], Loss: 0.0075\n",
      "Training - Epoch [136/200], Loss: 0.0076\n",
      "Validation - Epoch [136/200], Loss: 0.0086\n",
      "Training - Epoch [137/200], Loss: 0.0077\n",
      "Validation - Epoch [137/200], Loss: 0.0079\n",
      "Training - Epoch [138/200], Loss: 0.0104\n",
      "Validation - Epoch [138/200], Loss: 0.0082\n",
      "Training - Epoch [139/200], Loss: 0.0085\n",
      "Validation - Epoch [139/200], Loss: 0.0092\n",
      "Training - Epoch [140/200], Loss: 0.0083\n",
      "Validation - Epoch [140/200], Loss: 0.0083\n",
      "Training - Epoch [141/200], Loss: 0.0084\n",
      "Validation - Epoch [141/200], Loss: 0.0091\n",
      "Training - Epoch [142/200], Loss: 0.0080\n",
      "Validation - Epoch [142/200], Loss: 0.0075\n",
      "Training - Epoch [143/200], Loss: 0.0106\n",
      "Validation - Epoch [143/200], Loss: 0.0078\n",
      "Training - Epoch [144/200], Loss: 0.0086\n",
      "Validation - Epoch [144/200], Loss: 0.0084\n",
      "Training - Epoch [145/200], Loss: 0.0082\n",
      "Validation - Epoch [145/200], Loss: 0.0094\n",
      "Training - Epoch [146/200], Loss: 0.0087\n",
      "Validation - Epoch [146/200], Loss: 0.0091\n",
      "Training - Epoch [147/200], Loss: 0.0081\n",
      "Validation - Epoch [147/200], Loss: 0.0076\n",
      "Training - Epoch [148/200], Loss: 0.0079\n",
      "Validation - Epoch [148/200], Loss: 0.0082\n",
      "Training - Epoch [149/200], Loss: 0.0080\n",
      "Validation - Epoch [149/200], Loss: 0.0088\n",
      "Training - Epoch [150/200], Loss: 0.0078\n",
      "Validation - Epoch [150/200], Loss: 0.0076\n",
      "Training - Epoch [151/200], Loss: 0.0081\n",
      "Validation - Epoch [151/200], Loss: 0.0075\n",
      "Training - Epoch [152/200], Loss: 0.0080\n",
      "Validation - Epoch [152/200], Loss: 0.0090\n",
      "Training - Epoch [153/200], Loss: 0.0082\n",
      "Validation - Epoch [153/200], Loss: 0.0079\n",
      "Training - Epoch [154/200], Loss: 0.0078\n",
      "Validation - Epoch [154/200], Loss: 0.0082\n",
      "Training - Epoch [155/200], Loss: 0.0078\n",
      "Validation - Epoch [155/200], Loss: 0.0084\n",
      "Training - Epoch [156/200], Loss: 0.0077\n",
      "Validation - Epoch [156/200], Loss: 0.0079\n",
      "Training - Epoch [157/200], Loss: 0.0077\n",
      "Validation - Epoch [157/200], Loss: 0.0080\n",
      "Training - Epoch [158/200], Loss: 0.0080\n",
      "Validation - Epoch [158/200], Loss: 0.0082\n",
      "Training - Epoch [159/200], Loss: 0.0077\n",
      "Validation - Epoch [159/200], Loss: 0.0081\n",
      "Training - Epoch [160/200], Loss: 0.0080\n",
      "Validation - Epoch [160/200], Loss: 0.0079\n",
      "Training - Epoch [161/200], Loss: 0.0076\n",
      "Validation - Epoch [161/200], Loss: 0.0073\n",
      "Training - Epoch [162/200], Loss: 0.0076\n",
      "Validation - Epoch [162/200], Loss: 0.0087\n",
      "Training - Epoch [163/200], Loss: 0.0077\n",
      "Validation - Epoch [163/200], Loss: 0.0081\n",
      "Training - Epoch [164/200], Loss: 0.0077\n",
      "Validation - Epoch [164/200], Loss: 0.0074\n",
      "Training - Epoch [165/200], Loss: 0.0076\n",
      "Validation - Epoch [165/200], Loss: 0.0076\n",
      "Training - Epoch [166/200], Loss: 0.0078\n",
      "Validation - Epoch [166/200], Loss: 0.0082\n",
      "Training - Epoch [167/200], Loss: 0.0077\n",
      "Validation - Epoch [167/200], Loss: 0.0072\n",
      "Training - Epoch [168/200], Loss: 0.0075\n",
      "Validation - Epoch [168/200], Loss: 0.0076\n",
      "Training - Epoch [169/200], Loss: 0.0077\n",
      "Validation - Epoch [169/200], Loss: 0.0079\n",
      "Training - Epoch [170/200], Loss: 0.0078\n",
      "Validation - Epoch [170/200], Loss: 0.0078\n",
      "Training - Epoch [171/200], Loss: 0.0076\n",
      "Validation - Epoch [171/200], Loss: 0.0082\n",
      "Training - Epoch [172/200], Loss: 0.0075\n",
      "Validation - Epoch [172/200], Loss: 0.0087\n",
      "Training - Epoch [173/200], Loss: 0.0076\n",
      "Validation - Epoch [173/200], Loss: 0.0078\n",
      "Training - Epoch [174/200], Loss: 0.0076\n",
      "Validation - Epoch [174/200], Loss: 0.0074\n",
      "Training - Epoch [175/200], Loss: 0.0080\n",
      "Validation - Epoch [175/200], Loss: 0.0077\n",
      "Training - Epoch [176/200], Loss: 0.0078\n",
      "Validation - Epoch [176/200], Loss: 0.0075\n",
      "Training - Epoch [177/200], Loss: 0.0075\n",
      "Validation - Epoch [177/200], Loss: 0.0079\n",
      "Training - Epoch [178/200], Loss: 0.0076\n",
      "Validation - Epoch [178/200], Loss: 0.0078\n",
      "Training - Epoch [179/200], Loss: 0.0075\n",
      "Validation - Epoch [179/200], Loss: 0.0084\n",
      "Training - Epoch [180/200], Loss: 0.0076\n",
      "Validation - Epoch [180/200], Loss: 0.0081\n",
      "Training - Epoch [181/200], Loss: 0.0077\n",
      "Validation - Epoch [181/200], Loss: 0.0073\n",
      "Training - Epoch [182/200], Loss: 0.0080\n",
      "Validation - Epoch [182/200], Loss: 0.0081\n",
      "Training - Epoch [183/200], Loss: 0.0102\n",
      "Validation - Epoch [183/200], Loss: 0.0079\n",
      "Training - Epoch [184/200], Loss: 0.0083\n",
      "Validation - Epoch [184/200], Loss: 0.0087\n",
      "Training - Epoch [185/200], Loss: 0.0081\n",
      "Validation - Epoch [185/200], Loss: 0.0079\n",
      "Training - Epoch [186/200], Loss: 0.0078\n",
      "Validation - Epoch [186/200], Loss: 0.0079\n",
      "Training - Epoch [187/200], Loss: 0.0079\n",
      "Validation - Epoch [187/200], Loss: 0.0078\n",
      "Training - Epoch [188/200], Loss: 0.0076\n",
      "Validation - Epoch [188/200], Loss: 0.0078\n",
      "Training - Epoch [189/200], Loss: 0.0076\n",
      "Validation - Epoch [189/200], Loss: 0.0079\n",
      "Training - Epoch [190/200], Loss: 0.0076\n",
      "Validation - Epoch [190/200], Loss: 0.0073\n",
      "Training - Epoch [191/200], Loss: 0.0077\n",
      "Validation - Epoch [191/200], Loss: 0.0080\n",
      "Training - Epoch [192/200], Loss: 0.0078\n",
      "Validation - Epoch [192/200], Loss: 0.0079\n",
      "Training - Epoch [193/200], Loss: 0.0080\n",
      "Validation - Epoch [193/200], Loss: 0.0081\n",
      "Training - Epoch [194/200], Loss: 0.0080\n",
      "Validation - Epoch [194/200], Loss: 0.0084\n",
      "Training - Epoch [195/200], Loss: 0.0077\n",
      "Validation - Epoch [195/200], Loss: 0.0080\n",
      "Training - Epoch [196/200], Loss: 0.0076\n",
      "Validation - Epoch [196/200], Loss: 0.0079\n",
      "Training - Epoch [197/200], Loss: 0.0075\n",
      "Validation - Epoch [197/200], Loss: 0.0077\n",
      "Training - Epoch [198/200], Loss: 0.0090\n",
      "Validation - Epoch [198/200], Loss: 0.0086\n",
      "Training - Epoch [199/200], Loss: 0.0082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch [199/200], Loss: 0.0076\n",
      "Training - Epoch [200/200], Loss: 0.0078\n",
      "Validation - Epoch [200/200], Loss: 0.0076\n"
     ]
    }
   ],
   "source": [
    "# Transformer Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, hidden_dim, num_layers, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.squeeze(1)\n",
    "        x = self.fc(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.tensor(features.values, dtype=torch.float32) \n",
    "        self.targets = torch.tensor(targets.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = X_train.shape[1]  # Dimension of input features\n",
    "num_heads = 2  # Number of attention heads = 2\n",
    "hidden_dim = 200  # Hidden layers of the model = 200\n",
    "num_layers = 2  # Number of transformer layers = 2\n",
    "dropout = 0.1  # Dropout probability = 0.1\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "model = TransformerModel(input_dim=input_dim, num_heads=num_heads, hidden_dim=hidden_dim,\n",
    "                          num_layers=num_layers, dropout=dropout)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression task\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Optimizer used is Adam and learning rate is 0.001\n",
    "\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(inputs)\n",
    "    average_loss = total_loss / len(train_dataset)\n",
    "    print(f'Training - Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for inputs, labels in test_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * len(inputs)\n",
    "        average_loss = total_loss / len(test_dataset)\n",
    "        print(f'Validation - Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        # Stored true labels and predictions\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(outputs.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "094ecce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqsAAAIhCAYAAABpMPNPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzBUlEQVR4nO3deViVdf7/8deRVVYFBxEFFU1TK0Vcxl0zNTKTsUXTygUtl0pzHbXCZXIbGy1z37c0J7XRSstcyhJLHZ3SyBYXtCQVcgERWe7fH/08X0+Agh7kkzwf19U1nfv+nPu8b6+56tnNfR9slmVZAgAAAAxUoqgHAAAAAPJCrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCMNbXX3+tnj17qnLlyvL09JSPj4/q1q2rKVOmKDk5uVA/e//+/WrRooX8/f1ls9k0ffp0p3+GzWbTmDFjnH7cG1myZIlsNptsNpt27NiRY79lWapatapsNptatmx5U58xa9YsLVmypEDv2bFjR54zASi+XIt6AADIzfz589W/f39Vr15dw4YNU82aNZWRkaG9e/dqzpw5iouL0/r16wvt83v16qXU1FStXr1apUuXVqVKlZz+GXFxcapQoYLTj5tfvr6+WrhwYY4g/fTTT/XTTz/J19f3po89a9YslSlTRj169Mj3e+rWrau4uDjVrFnzpj8XwJ2HWAVgnLi4OPXr109t2rTRe++9Jw8PD/u+Nm3aaMiQIdq8eXOhznDw4EH16dNHUVFRhfYZf/3rXwvt2PnRuXNnrVy5UjNnzpSfn599+8KFC9WoUSNduHDhtsyRkZEhm80mPz+/Iv8zAWAebgMAYJwJEybIZrNp3rx5DqF6lbu7ux555BH76+zsbE2ZMkV33323PDw8FBQUpGeeeUYnT550eF/Lli11zz33aM+ePWrWrJm8vLwUHh6uSZMmKTs7W9L//Yg8MzNTs2fPtv+4XJLGjBlj//trXX3PsWPH7Nu2bdumli1bKjAwUCVLllRYWJgeffRRXbp0yb4mt9sADh48qI4dO6p06dLy9PRUnTp1tHTpUoc1V39cvmrVKo0ePVohISHy8/PTAw88oMOHD+fvD1nSk08+KUlatWqVfdv58+e1du1a9erVK9f3jB07Vg0bNlRAQID8/PxUt25dLVy4UJZl2ddUqlRJhw4d0qeffmr/87t6Zfrq7MuXL9eQIUNUvnx5eXh46Mcff8xxG8DZs2cVGhqqxo0bKyMjw378b7/9Vt7e3nr66afzfa4A/ryIVQBGycrK0rZt2xQZGanQ0NB8vadfv34aMWKE2rRpow0bNmj8+PHavHmzGjdurLNnzzqsTUxMVLdu3fTUU09pw4YNioqK0siRI7VixQpJUvv27RUXFydJeuyxxxQXF2d/nV/Hjh1T+/bt5e7urkWLFmnz5s2aNGmSvL29deXKlTzfd/jwYTVu3FiHDh3Sm2++qXXr1qlmzZrq0aOHpkyZkmP9qFGjdPz4cS1YsEDz5s3TDz/8oA4dOigrKytfc/r5+emxxx7TokWL7NtWrVqlEiVKqHPnznme23PPPac1a9Zo3bp16tSpk1544QWNHz/evmb9+vUKDw9XRESE/c/vj7dsjBw5UgkJCZozZ442btyooKCgHJ9VpkwZrV69Wnv27NGIESMkSZcuXdLjjz+usLAwzZkzJ1/nCeBPzgIAgyQmJlqSrC5duuRrfXx8vCXJ6t+/v8P2L7/80pJkjRo1yr6tRYsWliTryy+/dFhbs2ZNq127dg7bJFkDBgxw2BYbG2vl9o/NxYsXW5Kso0ePWpZlWe+++64lyTpw4MB1Z5dkxcbG2l936dLF8vDwsBISEhzWRUVFWV5eXta5c+csy7Ks7du3W5Kshx56yGHdmjVrLElWXFzcdT/36rx79uyxH+vgwYOWZVlW/fr1rR49eliWZVm1atWyWrRokedxsrKyrIyMDGvcuHFWYGCglZ2dbd+X13uvfl7z5s3z3Ld9+3aH7ZMnT7YkWevXr7e6d+9ulSxZ0vr666+ve44A7hxcWQXwp7Z9+3ZJyvEgT4MGDVSjRg1t3brVYXtwcLAaNGjgsO2+++7T8ePHnTZTnTp15O7urmeffVZLly7VkSNH8vW+bdu2qXXr1jmuKPfo0UOXLl3KcYX32lshpN/PQ1KBzqVFixaqUqWKFi1apG+++UZ79uzJ8xaAqzM+8MAD8vf3l4uLi9zc3PTqq68qKSlJp0+fzvfnPvroo/leO2zYMLVv315PPvmkli5dqhkzZujee+/N9/sB/LkRqwCMUqZMGXl5eeno0aP5Wp+UlCRJKleuXI59ISEh9v1XBQYG5ljn4eGhtLS0m5g2d1WqVNEnn3yioKAgDRgwQFWqVFGVKlX0xhtvXPd9SUlJeZ7H1f3X+uO5XL2/tyDnYrPZ1LNnT61YsUJz5sxRtWrV1KxZs1zXfvXVV2rbtq2k37+t4YsvvtCePXs0evToAn9ubud5vRl79Oihy5cvKzg4mHtVgWKGWAVgFBcXF7Vu3Vr79u3L8YBUbq4G26lTp3Ls++WXX1SmTBmnzebp6SlJSk9Pd9j+x/tiJalZs2bauHGjzp8/r927d6tRo0YaNGiQVq9enefxAwMD8zwPSU49l2v16NFDZ8+e1Zw5c9SzZ888161evVpubm56//339cQTT6hx48aqV6/eTX1mbg+q5eXUqVMaMGCA6tSpo6SkJA0dOvSmPhPAnxOxCsA4I0eOlGVZ6tOnT64PJGVkZGjjxo2SpPvvv1+S7A9IXbVnzx7Fx8erdevWTpvr6hPtX3/9tcP2q7PkxsXFRQ0bNtTMmTMlSf/973/zXNu6dWtt27bNHqdXLVu2TF5eXoX2tU7ly5fXsGHD1KFDB3Xv3j3PdTabTa6urnJxcbFvS0tL0/Lly3OsddbV6qysLD355JOy2WzatGmTJk6cqBkzZmjdunW3fGwAfw58zyoA4zRq1EizZ89W//79FRkZqX79+qlWrVrKyMjQ/v37NW/ePN1zzz3q0KGDqlevrmeffVYzZsxQiRIlFBUVpWPHjumVV15RaGioXnrpJafN9dBDDykgIEAxMTEaN26cXF1dtWTJEp04ccJh3Zw5c7Rt2za1b99eYWFhunz5sv2J+wceeCDP48fGxur9999Xq1at9OqrryogIEArV67UBx98oClTpsjf399p5/JHkyZNuuGa9u3b61//+pe6du2qZ599VklJSZo6dWquXy927733avXq1XrnnXcUHh4uT0/Pm7rPNDY2Vjt37tTHH3+s4OBgDRkyRJ9++qliYmIUERGhypUrF/iYAP5ciFUARurTp48aNGigadOmafLkyUpMTJSbm5uqVaumrl276vnnn7evnT17tqpUqaKFCxdq5syZ8vf314MPPqiJEyfmeo/qzfLz89PmzZs1aNAgPfXUUypVqpR69+6tqKgo9e7d276uTp06+vjjjxUbG6vExET5+Pjonnvu0YYNG+z3fOamevXq2rVrl0aNGqUBAwYoLS1NNWrU0OLFiwv0m6AKy/33369FixZp8uTJ6tChg8qXL68+ffooKChIMTExDmvHjh2rU6dOqU+fPrp48aIqVqzo8D20+bFlyxZNnDhRr7zyisMV8iVLligiIkKdO3fW559/Lnd3d2ecHgBD2Szrmm9yBgAAAAzCPasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAw1h35SwFKRjx/40UA8Cdy9NNpRT0CADhVsJ9bvtZxZRUAAADGIlYBAABgLGIVAAAAxiJWAQAAYCxiFQAAAMYiVgEAAGAsYhUAAADGIlYBAABgLGIVAAAAxiJWAQAAYCxiFQAAAMYiVgEAAGAsYhUAAADGIlYBAABgLGIVAAAAxiJWAQAAYCxiFQAAAMYiVgEAAGAsYhUAAADGIlYBAABgLGIVAAAAxiJWAQAAYCxiFQAAAMYiVgEAAGAsYhUAAADGIlYBAABgLGIVAAAAxiJWAQAAYCxiFQAAAMYiVgEAAGAsYhUAAADGIlYBAABgLGIVAAAAxiJWAQAAYCxiFQAAAMYiVgEAAGAsYhUAAADGIlYBAABgLGIVAAAAxiJWAQAAYCxiFQAAAMYiVgEAAGAsYhUAAADGIlYBAABgLGIVAAAAxiJWAQAAYCxiFQAAAMYiVgEAAGAsYhUAAADGIlYBAABgLGIVAAAAxiJWAQAAYCxiFQAAAMYiVgEAAGAsYhUAAADGIlYBAABgLGIVAAAAxiJWAQAAYCxiFQAAAMYiVgEAAGAsYhUAAADGIlYBAABgLGIVAAAAxiJWAQAAYCxiFQAAAMYiVgEAAGAsYhUAAADGIlYBAABgLGIVAAAAxiJWAQAAYCxiFQAAAMYiVgEAAGAsYhUAAADGIlYBAABgLGIVAAAAxiJWAQAAYCxiFQAAAMYiVgEAAGAsYhUAAADGIlYBAABgLGIVAAAAxiJWAQAAYCxiFQAAAMYiVgEAAGAsYhUAAADGIlYBAABgLGIVAAAAxiJWAQAAYCxiFQAAAMYiVgEAAGAsYhUAAADGIlYBAABgLGIVAAAAxiJWAQAAYCxiFQAAAMYiVgEAAGAsYhUAAADGIlYBAABgLGIVAAAAxiJWAQAAYCxiFQAAAMYiVgEAAGAsYhUAAADGIlYBAABgLGIVAAAAxiJWAQAAYCxiFQAAAMYiVgEAAGAsYhUAAADGci3qAQBTDO3VVuNfeERvrdyuYVPXSpLS9r+V69pR09Zr2rKtkqSP5g9U83p3Oez/90f79MzfF9tff/fBWFUMCXRYM3Xxx3rlzQ3OPAUAyGHxvJlaMn+2w7aAgECt/+hTSVJy0lnNnTFNe77cpZSLF1U7IlIDh41ShbCKkqQL589r0byZ2rt7l07/mij/UqXUtOX9iun7gnx8fG/7+aD4IVYBSZE1wxTTqbG+/v6kw/ZKD4x0eN22SS3Nie2q9VsPOGxfuPYLjZ/9vv11WnpGjs8YO+t9LV73hf11yqV0J0wOADdWObyqXp+5wP7axeX3H6xalqXRwwbK1dVVr019U97ePlrz9jINHtBbS9f8RyVLeunsmdNKOnNa/QYOVaXwcP166pRenzROSWfOaNzkaUV1SihGiFUUe94l3bV4Qg/1H79Kf+/9oMO+X5MuOrzu0PJefbrnBx37Oclhe9rlKznW/lFK6uUbrgGAwuDi4qLAMmVybD+ZcFzffvM/LVn9nipXqSpJemnEy4pu11xbP/pQD0c/pvCqd2n8lOn295SvEKbe/V7Ua6/+XZmZmXJ1JSVQuIr0ntWTJ09q9OjRatWqlWrUqKGaNWuqVatWGj16tE6cOFGUo6EYmT6yszbvPKjtXx6+7rqgAF892PQeLX0vLse+zg/V04ltk7Tv3dGa+NLf5OPlkWPN4B5tdHL7ZO1e/XcNj2knN1cXp50DAFzPyRMJ6hTVSp07ttPYUUP1y8nf/x17JeOKJMndw92+1sXFRa6ubvrmwP48j5eaclFe3j6EKm6LIvt/2eeff66oqCiFhoaqbdu2atu2rSzL0unTp/Xee+9pxowZ2rRpk5o0aXLd46Snpys93fHHqVZ2lmwlCAHc2OPtIhVRI1RNuk254dqnOjTUxUuX9d62Aw7bV3+4R8d+SdKvZy+oVtUQjXuhg+6tVl4P9/u/+11nvr1D+787oXMXLqnePRU17oVHVKl8oPqPe9vZpwQADmrUuk+jxk5QhbCK+i0pScsXzdWAmKe05J3/qGKlygouF6J5M9/Q0JGvyrOkl9asXKrkpLNKSjqT6/HOnzunZQvn6pFOj9/mM0FxZbMsyyqKD65fv76aNm2qadNyv9/lpZde0ueff649e/Zc9zhjxozR2LFjHba5lK0vt3INnDYr7kwVypbS5yuHq0P/mfrm+58l/f6w1NeHT9ofsLrWgXUva9uXhzV48r+ve9yIGqHa9fYINXpykg58dzLXNdGt62jV1N4q33KEks+n3vrJ4I539FPuDYRzpKVdUtfoKHV5ppc6d+uuw/GHNGX8q/rxh8NycXFRZP2/ylbi9x+8TnnD8cGs1JQUDX3hWfn4+mniv2bI1dWtKE4Bd4hgv/z9/6fIrqwePHhQK1asyHP/c889pzlz5tzwOCNHjtTgwYMdtgU1G3HL8+HOF1EjTGUD/bRr5XD7NldXFzWtW0V9OzeXf8NBys7+/b/lmkRUUfXKwXr6mif887I//oSuZGSqalhQnrH61ddHJUlVQssQqwBuq5IlvVS56l06eeK4JKl6jVpa+PZapaRcVGZGhkqVDlDfHk+qeo1aDu+7lJqqYS8+p5IlvfSPf75BqOK2KbJYLVeunHbt2qXq1avnuj8uLk7lypW74XE8PDzk4eF4fyC3ACA/tn91WJGPveawbd7Yp3T46K96fckWe6hKUvfoRtr3bYL9Cuz11KxSTu5urjp19nyea2rfHSpJSjx74SanB4Cbc+XKFSUcO6r76kQ6bL/6NVQnE47rcPwhxfR93r4vNSVFQ198Tu5ubprwrxk5/r0LFKYii9WhQ4eqb9++2rdvn9q0aaOyZcvKZrMpMTFRW7Zs0YIFCzR9+vSiGg/FQMqldH370ymHbalpV5R8PtVhu6+3pzq1idDf/7U+xzEqVyijLg/V00eff6uzv6WoRpVgTXqpk/bHn1DcgSOSpIb3VVaDeyvp0z3f63zKZdWrFaYpQx/Vxh1f60Tib4V7kgCKvVnT/6nGzVqqbHA5/fZbspYtnKvU1BQ9+HBHSdL2Tz5SqdKlVbZsOR356QfNeH2Smra4X/X/+vszI5dSUzX0hWd1+XKaXh73hlJTUpWa8vtPhEqVLi0XFy4QoXAVWaz2799fgYGBmjZtmubOnausrCxJvz+FGBkZqWXLlumJJ54oqvEAu8fbRcomm9Zs3ptjX0ZGplo1qK4BT7aSj5e7Tiae0+bPD+q1uZvsV2bTr2TosbZ1Neq5KHm4uSrhVLIWrdulfy3dcrtPBUAxdOb0rxr38nCdP/ebSpUOUM177tPsRW8ruFyIJCnp7BnNnDZFvyUnKbDMX9TuoUf0TO++9vcf/u6Qvj34tSSp698ecjj26v98pHIh5W/fyaBYKrIHrK6VkZGhs2fPSpLKlCkjN7dbuw+mZMTzN14EAH8iPGAF4E5j/ANW13Jzc8vX/akAAAAoXor0lwIAAAAA10OsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIzlmp9FGzZsyPcBH3nkkZseBgAAALhWvmI1Ojo6Xwez2WzKysq6lXkAAAAAu3zFanZ2dmHPAQAAAORwS/esXr582VlzAAAAADkUOFazsrI0fvx4lS9fXj4+Pjpy5Igk6ZVXXtHChQudPiAAAACKrwLH6muvvaYlS5ZoypQpcnd3t2+/9957tWDBAqcOBwAAgOKtwLG6bNkyzZs3T926dZOLi4t9+3333afvvvvOqcMBAACgeCtwrP7888+qWrVqju3Z2dnKyMhwylAAAACAdBOxWqtWLe3cuTPH9n//+9+KiIhwylAAAACAlM+vrrpWbGysnn76af3888/Kzs7WunXrdPjwYS1btkzvv/9+YcwIAACAYqrAV1Y7dOigd955Rx9++KFsNpteffVVxcfHa+PGjWrTpk1hzAgAAIBiymZZllXUQzhbyYjni3oEAHCqo59OK+oRAMCpgv3c8rWuwLcBXLV3717Fx8fLZrOpRo0aioyMvNlDAQAAALkqcKyePHlSTz75pL744guVKlVKknTu3Dk1btxYq1atUmhoqLNnBAAAQDFV4HtWe/XqpYyMDMXHxys5OVnJycmKj4+XZVmKiYkpjBkBAABQTBX4yurOnTu1a9cuVa9e3b6tevXqmjFjhpo0aeLU4QAAAFC8FfjKalhYWK5f/p+Zmany5cs7ZSgAAABAuolYnTJlil544QXt3btXV79IYO/evRo4cKCmTp3q9AEBAABQfOXrq6tKly4tm81mf52amqrMzEy5uv5+F8HVv/f29lZycnLhTZtPfHUVgDsNX10F4E7j1K+umj59+q3MAgAAANyUfMVq9+7dC3sOAAAAIIeb/qUAkpSWlpbjYSs/P79bGggAAAC4qsAPWKWmpur5559XUFCQfHx8VLp0aYe/AAAAAGcpcKwOHz5c27Zt06xZs+Th4aEFCxZo7NixCgkJ0bJlywpjRgAAABRTBb4NYOPGjVq2bJlatmypXr16qVmzZqpataoqVqyolStXqlu3boUxJwAAAIqhAl9ZTU5OVuXKlSX9fn/q1a+qatq0qT777DPnTgcAAIBircCxGh4ermPHjkmSatasqTVr1kj6/YprqVKlnDkbAAAAirkCx2rPnj31v//9T5I0cuRI+72rL730koYNG+b0AQEAAFB85es3WF1PQkKC9u7dqypVqqh27drOmuuW8BusANxp+A1WAO40+f0NVgW+svpHYWFh6tSpkwICAtSrV69bPRwAAABgd8uxelVycrKWLl3qrMMBAAAAzotVAAAAwNmIVQAAABiLWAUAAICx8v0brDp16nTd/efOnbvVWZzmtz1vFfUIAOBUpZuPKuoRAMCp0nZNyNe6fMeqv7//Dfc/88wz+T0cAAAAcEP5jtXFixcX5hwAAABADtyzCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAY91UrC5fvlxNmjRRSEiIjh8/LkmaPn26/vOf/zh1OAAAABRvBY7V2bNna/DgwXrooYd07tw5ZWVlSZJKlSql6dOnO3s+AAAAFGMFjtUZM2Zo/vz5Gj16tFxcXOzb69Wrp2+++capwwEAAKB4K3CsHj16VBERETm2e3h4KDU11SlDAQAAANJNxGrlypV14MCBHNs3bdqkmjVrOmMmAAAAQFIBft3qVcOGDdOAAQN0+fJlWZalr776SqtWrdLEiRO1YMGCwpgRAAAAxVSBY7Vnz57KzMzU8OHDdenSJXXt2lXly5fXG2+8oS5duhTGjAAAACimbJZlWTf75rNnzyo7O1tBQUHOnOmWXc4s6gkAwLlKNx9V1CMAgFOl7ZqQr3UFvrJ6rTJlytzK2wEAAIDrKnCsVq5cWTabLc/9R44cuaWBAAAAgKsKHKuDBg1yeJ2RkaH9+/dr8+bNGjZsmLPmAgAAAAoeqwMHDsx1+8yZM7V3795bHggAAAC4qsDfs5qXqKgorV271lmHAwAAAJwXq++++64CAgKcdTgAAACg4LcBREREODxgZVmWEhMTdebMGc2aNcupwwEAAKB4K3CsRkdHO7wuUaKE/vKXv6hly5a6++67nTUXAAAAULBYzczMVKVKldSuXTsFBwcX1kwAAACApALes+rq6qp+/fopPT29sOYBAAAA7Ar8gFXDhg21f//+wpgFAAAAcFDge1b79++vIUOG6OTJk4qMjJS3t7fD/vvuu89pwwEAAKB4s1mWZeVnYa9evTR9+nSVKlUq50FsNlmWJZvNpqysLGfPWGCXM4t6AgBwrtLNRxX1CADgVGm7JuRrXb5j1cXFRadOnVJaWtp111WsWDFfH1yYiFUAdxpiFcCdJr+xmu/bAK42rQkxCgAAgOKhQA9YXfvLAAAAAIDCVqAHrKpVq3bDYE1OTr6lgQAAAICrChSrY8eOlb+/f2HNAgAAADgoUKx26dJFQUFBhTULAAAA4CDf96xyvyoAAABut3zHaj6/4QoAAABwmnzfBpCdnV2YcwAAAAA5FOirqwAAAIDbiVgFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxiFUAAAAYi1gFAACAsYhVAAAAGItYBQAAgLGIVQAAABiLWAUAAICxXIt6AMAkC+fP1dYtH+vo0SPy8PRUnToRGjR4qCpVDpckZWRk6K03p+vznZ/p5MkT8vXxUcNGjTXwpSEKCiprP864Ma/qy927dOb0aXl5ean2/z9O5fAqRXVqAIqhoU+30Ph+7fTWO19o2BsfSJLmjX5UT7ePdFj31cEEtXh2jiQpLLiUDq8bnuvxuo1+W+u2H5QkVQ0N1ITno9To3opyd3PRoZ9+1Zh5W/TZf48U4hmhOCJWgWvs3fOVOj/ZTbXuvVdZmVma8eY09e0To3UbPpCXl5cuX76s7+K/1bN9+6l69bt14cIFTZk0QQOf76dVa9bZj1OzZi21f7iDgsuV04Xz5zV75gz17ROjDz/eKhcXlyI8QwDFRWSN8orpWF9f/3Aqx76P4g7rudfW2l9fyciy//3J0+dV6eEJDut7dWygwd2a6aPd39u3rZ/aXT+cOKuoFxYqLT1Dz3duonX/fEa1Hp+qX5NTCuGMUFwRq8A1Zs9b6PB63D8mqlWzRor/9pAi69WXr6+v5i5Y7LDm76NeVrcuj+vUL7+oXEiIJOmxJzrb95cvX0HPvzhIj3fqqF9+/lmhYWGFfyIAijXvku5aHNtZ/Set1997tMqx/0pGVp5BmZ1t5dj3SIuaenfrN0pNuyJJCvT3UtXQMuo7YZ0O/pQoSXpl9mb1ffSvqlG5LLEKp+KeVeA6Ui5elCT5+fvnvSYlRTabTb5+frnuv3Tpkv6zfp3KV6ig4ODgQpkTAK41fcgj2rzrO23f+1Ou+5tFVNbxD0bp69WDNfPvf9NfSnvneayI6iGqUy1ESzfutW9LOn9J8UdPq2tUhLw83eTiUkK9OzZQYtJF7T/8s9PPB8Wb0VdWT5w4odjYWC1atCjPNenp6UpPT3fYZrl4yMPDo7DHwx3OsixNnTJREXUjdddd1XJdk56erjemTVVU+4fl4+PjsO+dVSs17fWpSku7pMrh4Zo7f7Hc3N1vx+gAirHHH7hPEXeXV5NeM3Pd//Hu77Vu+0ElJJ5TpXKl9WqfB7RpRm817vmWw+0AV3XvUE/xR09r98EEh+0PD1ykNZOf0plPYpWdben0bynqOHiJzqdcLpTzQvFl9JXV5ORkLV269LprJk6cKH9/f4e//jl54m2aEHeyif8Ypx++/16T//mvXPdnZGRoxNCXlJ1tafQrY3Lsf+jhR/TO2vVatHSFwsIqatiQQTn+wwoAnKlCkL/+Oehh9RzzjtKvZOa65t2t32jzrsP69siv+vCL7xQ9ZKnuCg1UVOO7c6z1dHdV5za1tfT9vTn2TR/2iM78lqoH+s1Ts96ztXFnvNb98xkFB/o6/bxQvBXpldUNGzZcd/+RIzd+onDkyJEaPHiwwzbLhauquDUTXxuvHTu2adHSFSqby4/uMzIyNGzIIP188qTmL16a46qqJPn6+srX11cVK1bSfffVVtPGDbTtky2Kav/w7TgFAMVQxN0hKhvgo12LBti3ubq6qGmdSur76F/l3/JVZWdbDu9JTLqohMRzqhoamON4f7v/Hnl5umnlpv0O21tGVtFDje9WuXbjdfHS7/8RPmjqBrWuX1VPPRShqcs/K4SzQ3FVpLEaHR0tm80my7LyXGOz2a57DA+PnD/yv5z7f0wCN2RZlia+Nl7btm7RwiXLVaFCaI41V0M14fhxLVi8TKVKlc7vwXXlyhUnTwwA/2f73p8U+dQbDtvmjX5Uh4+f0esrPssRqpIU4FdSFYL8dersxRz7ejxcTx98/p3Onkt12O7l6SZJyv7Dv7+zs60b/nsbKKgijdVy5cpp5syZio6OznX/gQMHFBkZmes+oDBMGD9Wmz58X9NnzJK3l7fOnjkjSfLx9ZWnp6cyMzM19KUXFR//rWbMnKvsrCz7Gn9/f7m5u+vkiRP6aPOHatS4iUqXDtDp079q8cL58vDwVNPmLYry9ADc4VIuXdG3R3512JaadkXJ5y/p2yO/yruku16Oaa33dhzUqbMXVbFcaY3r21ZJ5y9pw2eHHN4XXj5ATetUUvSQnLfjfXkwQb9dTNOClx/ThMXblJaeoV6P1FelkNLavOtwoZ4jip8ijdXIyEj997//zTNWb3TVFXC2Ne+skiTF9HjaYfu4f0xUx7910q+/JmrH9m2SpCce7eiwZsHiZarfoKHcPdz13317tWL5Ul04f0GBZQIVGVlPy1auUmBgzh+zAcDtkpWVrVpVyqprVIRK+XgqMemiPt13RE+/sloplxx/8tP94Xr65cwFffLVjzmOk3T+kjoOXqIxz7XRphm95eZaQvFHT+vxESv0zY+Jt+t0UEzYrCKswZ07dyo1NVUPPvhgrvtTU1O1d+9etWhRsKtR3AYA4E5Tuvmooh4BAJwqbdeEGy9SEV9Zbdas2XX3e3t7FzhUAQAAcOcw+qurAAAAULwRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGPZLMuyinoI4M8oPT1dEydO1MiRI+Xh4VHU4wDALeOfazARsQrcpAsXLsjf31/nz5+Xn59fUY8DALeMf67BRNwGAAAAAGMRqwAAADAWsQoAAABjEavATfLw8FBsbCwPIQC4Y/DPNZiIB6wAAABgLK6sAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCN2nWrFmqXLmyPD09FRkZqZ07dxb1SABwUz777DN16NBBISEhstlseu+994p6JMCOWAVuwjvvvKNBgwZp9OjR2r9/v5o1a6aoqCglJCQU9WgAUGCpqamqXbu23nrrraIeBciBr64CbkLDhg1Vt25dzZ49276tRo0aio6O1sSJE4twMgC4NTabTevXr1d0dHRRjwJI4soqUGBXrlzRvn371LZtW4ftbdu21a5du4poKgAA7kzEKlBAZ8+eVVZWlsqWLeuwvWzZskpMTCyiqQAAuDMRq8BNstlsDq8ty8qxDQAA3BpiFSigMmXKyMXFJcdV1NOnT+e42goAAG4NsQoUkLu7uyIjI7VlyxaH7Vu2bFHjxo2LaCoAAO5MrkU9APBnNHjwYD399NOqV6+eGjVqpHnz5ikhIUF9+/Yt6tEAoMBSUlL0448/2l8fPXpUBw4cUEBAgMLCwopwMoCvrgJu2qxZszRlyhSdOnVK99xzj6ZNm6bmzZsX9VgAUGA7duxQq1atcmzv3r27lixZcvsHAq5BrAIAAMBY3LMKAAAAYxGrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgC3aMyYMapTp479dY8ePRQdHX3b5zh27JhsNpsOHDhQaJ/xx3O9GbdjTgB3DmIVwB2pR48estlsstlscnNzU3h4uIYOHarU1NRC/+w33ngj37+i8naHW8uWLTVo0KDb8lkA4AyuRT0AABSWBx98UIsXL1ZGRoZ27typ3r17KzU1VbNnz86xNiMjQ25ubk75XH9/f6ccBwDAlVUAdzAPDw8FBwcrNDRUXbt2Vbdu3fTee+9J+r8fZy9atEjh4eHy8PCQZVk6f/68nn32WQUFBcnPz0/333+//ve//zkcd9KkSSpbtqx8fX0VExOjy5cvO+z/420A2dnZmjx5sqpWrSoPDw+FhYXptddekyRVrlxZkhQRESGbzaaWLVva37d48WLVqFFDnp6euvvuuzVr1iyHz/nqq68UEREhT09P1atXT/v377/lP7MRI0aoWrVq8vLyUnh4uF555RVlZGTkWDd37lyFhobKy8tLjz/+uM6dO+ew/0azA0B+cWUVQLFRsmRJh/D68ccftWbNGq1du1YuLi6SpPbt2ysgIEAffvih/P39NXfuXLVu3Vrff/+9AgICtGbNGsXGxmrmzJlq1qyZli9frjfffFPh4eF5fu7IkSM1f/58TZs2TU2bNtWpU6f03XffSfo9OBs0aKBPPvlEtWrVkru7uyRp/vz5io2N1VtvvaWIiAjt379fffr0kbe3t7p3767U1FQ9/PDDuv/++7VixQodPXpUAwcOvOU/I19fXy1ZskQhISH65ptv1KdPH/n6+mr48OE5/tw2btyoCxcuKCYmRgMGDNDKlSvzNTsAFIgFAHeg7t27Wx07drS//vLLL63AwEDriSeesCzLsmJjYy03Nzfr9OnT9jVbt261/Pz8rMuXLzscq0qVKtbcuXMty7KsRo0aWX379nXY37BhQ6t27dq5fvaFCxcsDw8Pa/78+bnOefToUUuStX//foftoaGh1ttvv+2wbfz48VajRo0sy7KsuXPnWgEBAVZqaqp9/+zZs3M91rVatGhhDRw4MM/9fzRlyhQrMjLS/jo2NtZycXGxTpw4Yd+2adMmq0SJEtapU6fyNXte5wwAueHKKoA71vvvvy8fHx9lZmYqIyNDHTt21IwZM+z7K1asqL/85S/21/v27VNKSooCAwMdjpOWlqaffvpJkhQfH6++ffs67G/UqJG2b9+e6wzx8fFKT09X69at8z33mTNndOLECcXExKhPnz727ZmZmfb7YePj41W7dm15eXk5zHGr3n33XU2fPl0//vijUlJSlJmZKT8/P4c1YWFhqlChgsPnZmdn6/Dhw3Jxcbnh7ABQEMQqgDtWq1atNHv2bLm5uSkkJCTHA1Te3t4Or7Ozs1WuXDnt2LEjx7FKlSp1UzOULFmywO/Jzs6W9PuP0xs2bOiw7+rtCpZl3dQ817N792516dJFY8eOVbt27eTv76/Vq1fr9ddfv+77bDab/X/zMzsAFASxCuCO5e3trapVq+Z7fd26dZWYmChXV1dVqlQp1zU1atTQ7t279cwzz9i37d69O89j3nXXXSpZsqS2bt2q3r1759h/9R7VrKws+7ayZcuqfPnyOnLkiLp165brcWvWrKnly5crLS3NHsTXmyM/vvjiC1WsWFGjR4+2bzt+/HiOdQkJCfrll18UEhIiSYqLi1OJEiVUrVq1fM0OAAVBrALA//fAAw+oUaNGio6O1uTJk1W9enX98ssv+vDDDxUdHa169epp4MCB6t69u+rVq6emTZtq5cqVOnToUJ4PWHl6emrEiBEaPny43N3d1aRJE505c0aHDh1STEyMgoKCVLJkSW3evFkVKlSQp6en/P39NWbMGL344ovy8/NTVFSU0tPTtXfvXv32228aPHiwunbtqtGjRysmJkYvv/yyjh07pqlTp+brPM+cOZPje12Dg4NVtWpVJSQkaPXq1apfv74++OADrV+/Ptdz6t69u6ZOnaoLFy7oxRdf1BNPPKHg4GBJuuHsAFAgRX3TLAAUhj8+YPVHsbGxDg9FXXXhwgXrhRdesEJCQiw3NzcrNDTU6tatm5WQkGBf89prr1llypSxfHx8rO7du1vDhw/P8wEry7KsrKws6x//+IdVsWJFy83NzQoLC7MmTJhg3z9//nwrNDTUKlGihNWiRQv79pUrV1p16tSx3N3drdKlS1vNmze31q1bZ98fFxdn1a5d23J3d7fq1KljrV27Nl8PWEnK8VdsbKxlWZY1bNgwKzAw0PLx8bE6d+5sTZs2zfL398/x5zZr1iwrJCTE8vT0tDp16mQlJyc7fM71ZucBKwAFYbOsQrjxCQAAAHACfikAAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACM9f8AXPmjFe6676AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        # Stored true labels and predictions\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(outputs.numpy())\n",
    "\n",
    "# Converted y_true and y_pred to numpy arrays\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Computed confusion matrix\n",
    "cm = confusion_matrix(np.round(y_true), np.round(y_pred))\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04bb03c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0075874734\n",
      "Mean Absolute Error: 0.055780057\n",
      "Root Mean Squared Error: 0.0871061\n",
      "R-squared Score: 0.8964366144946971\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Computed Mean Squared Error\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "# Computed Mean Absolute Error\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# Computed Root Mean Squared Error\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Computed R2-Score\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90a137c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alarm triggered for 29 consecutive faults on 2020-02-13.\n",
      "Alarm triggered for 24 consecutive faults on 2020-02-01.\n",
      "Alarm triggered for 23 consecutive faults on 2020-02-27.\n",
      "Alarm triggered for 22 consecutive faults on 2020-01-27.\n",
      "Alarm triggered for 21 consecutive faults on 2020-01-26.\n",
      "Alarm triggered for 20 consecutive faults on 2020-01-01.\n",
      "Alarm triggered for 18 consecutive faults on 2020-01-29.\n",
      "Alarm triggered for 18 consecutive faults on 2020-02-21.\n",
      "Alarm triggered for 18 consecutive faults on 2020-01-28.\n",
      "Alarm triggered for 17 consecutive faults on 2020-01-31.\n",
      "Alarm triggered for 17 consecutive faults on 2020-02-14.\n",
      "Alarm triggered for 17 consecutive faults on 2020-02-28.\n",
      "Alarm triggered for 17 consecutive faults on 2020-02-22.\n",
      "Alarm triggered for 17 consecutive faults on 2020-02-02.\n",
      "Alarm triggered for 16 consecutive faults on 2020-01-13.\n",
      "Alarm triggered for 16 consecutive faults on 2020-02-16.\n",
      "Alarm triggered for 16 consecutive faults on 2020-01-25.\n",
      "Alarm triggered for 16 consecutive faults on 2020-02-23.\n",
      "Alarm triggered for 15 consecutive faults on 2020-02-20.\n",
      "Alarm triggered for 15 consecutive faults on 2020-02-19.\n",
      "Alarm triggered for 15 consecutive faults on 2020-02-25.\n",
      "Alarm triggered for 15 consecutive faults on 2020-02-24.\n",
      "Alarm triggered for 14 consecutive faults on 2020-02-18.\n",
      "Alarm triggered for 14 consecutive faults on 2020-02-17.\n",
      "Alarm triggered for 14 consecutive faults on 2019-12-11.\n",
      "Alarm triggered for 13 consecutive faults on 2020-01-30.\n",
      "Alarm triggered for 13 consecutive faults on 2020-01-23.\n",
      "Alarm triggered for 12 consecutive faults on 2020-01-02.\n",
      "Alarm triggered for 12 consecutive faults on 2020-01-18.\n",
      "Alarm triggered for 12 consecutive faults on 2020-01-19.\n",
      "Alarm triggered for 11 consecutive faults on 2019-12-08.\n",
      "Alarm triggered for 11 consecutive faults on 2020-02-29.\n",
      "Alarm triggered for 11 consecutive faults on 2020-02-15.\n",
      "Alarm triggered for 11 consecutive faults on 2020-02-12.\n",
      "Alarm triggered for 11 consecutive faults on 2020-01-14.\n",
      "Alarm triggered for 11 consecutive faults on 2020-01-12.\n",
      "Alarm triggered for 11 consecutive faults on 2020-01-20.\n",
      "Alarm triggered for 10 consecutive faults on 2020-01-21.\n",
      "Alarm triggered for 10 consecutive faults on 2020-01-05.\n",
      "Alarm triggered for 10 consecutive faults on 2020-01-06.\n",
      "Alarm triggered for 10 consecutive faults on 2020-01-07.\n",
      "Alarm triggered for 10 consecutive faults on 2020-01-11.\n",
      "Alarm triggered for 10 consecutive faults on 2020-01-24.\n",
      "Alarm triggered for 9 consecutive faults on 2019-12-04.\n",
      "Alarm triggered for 9 consecutive faults on 2019-12-10.\n",
      "Alarm triggered for 8 consecutive faults on 2020-01-15.\n",
      "Alarm triggered for 8 consecutive faults on 2020-02-10.\n",
      "Alarm triggered for 8 consecutive faults on 2019-12-07.\n",
      "Alarm triggered for 8 consecutive faults on 2020-01-17.\n",
      "Alarm triggered for 8 consecutive faults on 2019-12-06.\n",
      "Alarm triggered for 7 consecutive faults on 2020-02-09.\n",
      "Alarm triggered for 7 consecutive faults on 2020-01-04.\n",
      "Alarm triggered for 7 consecutive faults on 2020-02-05.\n",
      "Alarm triggered for 6 consecutive faults on 2019-12-09.\n",
      "Alarm triggered for 6 consecutive faults on 2020-01-08.\n",
      "Alarm triggered for 6 consecutive faults on 2019-12-23.\n",
      "Alarm triggered for 5 consecutive faults on 2019-12-22.\n",
      "Alarm triggered for 5 consecutive faults on 2019-12-14.\n",
      "Alarm triggered for 5 consecutive faults on 2019-12-16.\n",
      "Alarm triggered for 5 consecutive faults on 2019-12-18.\n",
      "Alarm triggered for 5 consecutive faults on 2019-12-17.\n",
      "Alarm triggered for 5 consecutive faults on 2020-02-08.\n",
      "Alarm triggered for 5 consecutive faults on 2020-02-04.\n",
      "Alarm triggered for 5 consecutive faults on 2020-02-07.\n",
      "Alarm triggered for 5 consecutive faults on 2020-02-11.\n",
      "Alarm triggered for 4 consecutive faults on 2019-12-05.\n",
      "Alarm triggered for 4 consecutive faults on 2019-12-13.\n",
      "Alarm triggered for 4 consecutive faults on 2020-01-10.\n",
      "Alarm triggered for 4 consecutive faults on 2020-02-06.\n",
      "Alarm triggered for 4 consecutive faults on 2019-12-24.\n"
     ]
    }
   ],
   "source": [
    "# Function to check for four consecutive faults in a day and trigger alarms where Threshold = 2 * sigma\n",
    "def check_consecutive_faults(fault_indices, df, window=3):\n",
    "    fault_timestamps = df.index[fault_indices]\n",
    "\n",
    "    grouped_by_day = fault_timestamps.to_series().dt.date\n",
    "\n",
    "    # Checked if there are three or more consecutive faults within the same day\n",
    "    daily_fault_count = grouped_by_day.value_counts()\n",
    "    for date, count in daily_fault_count.items():\n",
    "        if count >= window:\n",
    "            print(f\"Alarm triggered for {count} consecutive faults on {date}.\")\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_ac_power = model(X_test_tensor)  # Model predictions\n",
    "    actual_ac_power = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "    # Absolute residuals between predicted and actual AC power\n",
    "    residuals = torch.abs(predicted_ac_power - actual_ac_power)\n",
    "\n",
    "# Calculated the standard deviation for setting the fault threshold\n",
    "sigma = torch.std(residuals).item()\n",
    "threshold = 2 * sigma  # Set the threshold as 2 * sigma\n",
    "\n",
    "anomalies = (residuals > threshold).int()\n",
    "\n",
    "fault_indices = torch.nonzero(anomalies).squeeze().tolist()\n",
    "\n",
    "check_consecutive_faults(fault_indices, df, window=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "114f01e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alarm triggered for 17 consecutive faults on 2020-02-27.\n",
      "Alarm triggered for 14 consecutive faults on 2020-02-13.\n",
      "Alarm triggered for 13 consecutive faults on 2020-01-26.\n",
      "Alarm triggered for 11 consecutive faults on 2020-01-01.\n",
      "Alarm triggered for 11 consecutive faults on 2020-02-28.\n",
      "Alarm triggered for 10 consecutive faults on 2020-02-23.\n",
      "Alarm triggered for 10 consecutive faults on 2020-01-29.\n",
      "Alarm triggered for 9 consecutive faults on 2020-01-14.\n",
      "Alarm triggered for 8 consecutive faults on 2020-01-23.\n",
      "Alarm triggered for 8 consecutive faults on 2020-02-20.\n",
      "Alarm triggered for 8 consecutive faults on 2020-02-22.\n",
      "Alarm triggered for 8 consecutive faults on 2020-02-16.\n",
      "Alarm triggered for 8 consecutive faults on 2020-02-01.\n",
      "Alarm triggered for 8 consecutive faults on 2020-01-31.\n",
      "Alarm triggered for 8 consecutive faults on 2020-02-15.\n",
      "Alarm triggered for 8 consecutive faults on 2020-01-05.\n",
      "Alarm triggered for 7 consecutive faults on 2020-01-18.\n",
      "Alarm triggered for 7 consecutive faults on 2020-01-30.\n",
      "Alarm triggered for 7 consecutive faults on 2020-02-19.\n",
      "Alarm triggered for 7 consecutive faults on 2020-01-19.\n",
      "Alarm triggered for 7 consecutive faults on 2019-12-11.\n",
      "Alarm triggered for 7 consecutive faults on 2020-02-25.\n",
      "Alarm triggered for 7 consecutive faults on 2020-02-14.\n",
      "Alarm triggered for 7 consecutive faults on 2020-01-06.\n",
      "Alarm triggered for 7 consecutive faults on 2020-01-28.\n",
      "Alarm triggered for 7 consecutive faults on 2020-01-13.\n",
      "Alarm triggered for 7 consecutive faults on 2020-01-25.\n",
      "Alarm triggered for 6 consecutive faults on 2020-02-12.\n",
      "Alarm triggered for 6 consecutive faults on 2020-01-21.\n",
      "Alarm triggered for 6 consecutive faults on 2020-01-27.\n",
      "Alarm triggered for 6 consecutive faults on 2019-12-04.\n",
      "Alarm triggered for 6 consecutive faults on 2019-12-06.\n",
      "Alarm triggered for 6 consecutive faults on 2020-01-12.\n",
      "Alarm triggered for 6 consecutive faults on 2020-02-02.\n",
      "Alarm triggered for 6 consecutive faults on 2020-02-10.\n",
      "Alarm triggered for 5 consecutive faults on 2020-01-07.\n",
      "Alarm triggered for 5 consecutive faults on 2020-01-15.\n",
      "Alarm triggered for 5 consecutive faults on 2019-12-09.\n",
      "Alarm triggered for 5 consecutive faults on 2020-01-17.\n",
      "Alarm triggered for 5 consecutive faults on 2020-02-21.\n",
      "Alarm triggered for 5 consecutive faults on 2019-12-18.\n",
      "Alarm triggered for 5 consecutive faults on 2019-12-23.\n",
      "Alarm triggered for 5 consecutive faults on 2019-12-07.\n",
      "Alarm triggered for 5 consecutive faults on 2020-02-17.\n",
      "Alarm triggered for 5 consecutive faults on 2020-01-02.\n",
      "Alarm triggered for 4 consecutive faults on 2020-02-29.\n",
      "Alarm triggered for 4 consecutive faults on 2020-01-04.\n",
      "Alarm triggered for 4 consecutive faults on 2020-02-18.\n",
      "Alarm triggered for 4 consecutive faults on 2020-01-11.\n",
      "Alarm triggered for 4 consecutive faults on 2019-12-13.\n",
      "Alarm triggered for 4 consecutive faults on 2020-01-08.\n",
      "Alarm triggered for 4 consecutive faults on 2020-01-20.\n",
      "Alarm triggered for 4 consecutive faults on 2020-01-24.\n"
     ]
    }
   ],
   "source": [
    "# Function to check for four consecutive faults in a day and trigger alarms where Threshold = 3 * sigma\n",
    "def check_consecutive_faults(fault_indices, df, window=3):\n",
    "    fault_timestamps = df.index[fault_indices]\n",
    "\n",
    "    grouped_by_day = fault_timestamps.to_series().dt.date\n",
    "\n",
    "    # Checked if there are three or more consecutive faults within the same day\n",
    "    daily_fault_count = grouped_by_day.value_counts()\n",
    "    for date, count in daily_fault_count.items():\n",
    "        if count >= window:\n",
    "            print(f\"Alarm triggered for {count} consecutive faults on {date}.\")\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_ac_power = model(X_test_tensor)  # Model predictions\n",
    "    actual_ac_power = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "    # Absolute residuals between predicted and actual AC power\n",
    "    residuals = torch.abs(predicted_ac_power - actual_ac_power)\n",
    "\n",
    "# Calculated the standard deviation for setting the fault threshold\n",
    "sigma = torch.std(residuals).item()\n",
    "threshold = 3 * sigma  # Set the threshold as 3 * sigma\n",
    "\n",
    "anomalies = (residuals > threshold).int()\n",
    "\n",
    "fault_indices = torch.nonzero(anomalies).squeeze().tolist()\n",
    "\n",
    "check_consecutive_faults(fault_indices, df, window=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fda326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
