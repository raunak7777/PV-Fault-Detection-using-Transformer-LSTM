{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3139b38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score, classification_report, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d1b8b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\My PC\\Desktop\\Solar PV Fault Research\\IO_DATA_LABELED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d64ca175",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Inv-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efe80506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Inv</th>\n",
       "      <th>AC_Real_Power</th>\n",
       "      <th>AC_Current</th>\n",
       "      <th>DC_Power</th>\n",
       "      <th>DC_Current</th>\n",
       "      <th>Tilt_Irradiation_1</th>\n",
       "      <th>Temp_Ambient_1</th>\n",
       "      <th>Temp_Module_1</th>\n",
       "      <th>Wind_Speed_1</th>\n",
       "      <th>Hor_Irradiation_1</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>05:45:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:15:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:30:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7.2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.510</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:45:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>1.27</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.57</td>\n",
       "      <td>5.20</td>\n",
       "      <td>25.9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.569</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16001</th>\n",
       "      <td>16001</td>\n",
       "      <td>16001</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>18:30:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>6.38</td>\n",
       "      <td>13.18</td>\n",
       "      <td>7.85</td>\n",
       "      <td>16.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16002</th>\n",
       "      <td>16002</td>\n",
       "      <td>16002</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>18:45:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.7</td>\n",
       "      <td>27.2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16003</th>\n",
       "      <td>16003</td>\n",
       "      <td>16003</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16004</th>\n",
       "      <td>16004</td>\n",
       "      <td>16004</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>19:15:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16005</th>\n",
       "      <td>16005</td>\n",
       "      <td>16005</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>19:30:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.1</td>\n",
       "      <td>25.7</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16006 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0        Date      Time    Inv  AC_Real_Power  \\\n",
       "0                 0           0  2019-04-01  05:45:00  Inv-1           0.00   \n",
       "1                 1           1  2019-04-01  06:00:00  Inv-1           0.00   \n",
       "2                 2           2  2019-04-01  06:15:00  Inv-1           0.00   \n",
       "3                 3           3  2019-04-01  06:30:00  Inv-1           0.00   \n",
       "4                 4           4  2019-04-01  06:45:00  Inv-1           1.27   \n",
       "...             ...         ...         ...       ...    ...            ...   \n",
       "16001         16001       16001  2020-02-29  18:30:00  Inv-1           6.38   \n",
       "16002         16002       16002  2020-02-29  18:45:00  Inv-1           0.00   \n",
       "16003         16003       16003  2020-02-29  19:00:00  Inv-1           0.00   \n",
       "16004         16004       16004  2020-02-29  19:15:00  Inv-1           0.00   \n",
       "16005         16005       16005  2020-02-29  19:30:00  Inv-1           0.00   \n",
       "\n",
       "       AC_Current  DC_Power  DC_Current  Tilt_Irradiation_1  Temp_Ambient_1  \\\n",
       "0            0.00      0.00        5.00                 0.0            17.7   \n",
       "1            0.00      0.00        4.90                 0.0            19.2   \n",
       "2            0.00      0.00        0.61                 0.0            19.0   \n",
       "3            0.00      0.00        0.80                 7.2            19.0   \n",
       "4            6.00      1.57        5.20                25.9            19.7   \n",
       "...           ...       ...         ...                 ...             ...   \n",
       "16001       13.18      7.85       16.93                 0.0            26.4   \n",
       "16002        0.00      0.00        0.44                 0.0            25.7   \n",
       "16003        0.00      0.00        0.45                 0.0            24.1   \n",
       "16004        0.00      0.00        1.23                 0.0            24.3   \n",
       "16005        0.00      0.00        3.63                 0.0            25.1   \n",
       "\n",
       "       Temp_Module_1  Wind_Speed_1  Hor_Irradiation_1  Operation  \n",
       "0               19.6         0.500                0.0          1  \n",
       "1               20.1         0.535                0.0          1  \n",
       "2               20.1         0.500                1.6          1  \n",
       "3               20.6         0.510               10.4          1  \n",
       "4               21.1         0.569               27.0          1  \n",
       "...              ...           ...                ...        ...  \n",
       "16001           28.6         0.500                3.2          1  \n",
       "16002           27.2         0.500                0.2          1  \n",
       "16003           26.1         0.500                0.1          1  \n",
       "16004           25.7         0.728                0.1          1  \n",
       "16005           25.7         1.010                0.1          1  \n",
       "\n",
       "[16006 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e1eff43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16006 entries, 0 to 16005\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Unnamed: 0.1        16006 non-null  int64  \n",
      " 1   Unnamed: 0          16006 non-null  int64  \n",
      " 2   Date                16006 non-null  object \n",
      " 3   Time                16006 non-null  object \n",
      " 4   Inv                 16006 non-null  object \n",
      " 5   AC_Real_Power       15979 non-null  float64\n",
      " 6   AC_Current          15979 non-null  float64\n",
      " 7   DC_Power            15979 non-null  float64\n",
      " 8   DC_Current          15979 non-null  float64\n",
      " 9   Tilt_Irradiation_1  16006 non-null  float64\n",
      " 10  Temp_Ambient_1      16006 non-null  float64\n",
      " 11  Temp_Module_1       16006 non-null  float64\n",
      " 12  Wind_Speed_1        16006 non-null  float64\n",
      " 13  Hor_Irradiation_1   16006 non-null  float64\n",
      " 14  Operation           16006 non-null  int64  \n",
      "dtypes: float64(9), int64(3), object(3)\n",
      "memory usage: 1.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Inv</th>\n",
       "      <th>AC_Real_Power</th>\n",
       "      <th>AC_Current</th>\n",
       "      <th>DC_Power</th>\n",
       "      <th>DC_Current</th>\n",
       "      <th>Tilt_Irradiation_1</th>\n",
       "      <th>Temp_Ambient_1</th>\n",
       "      <th>Temp_Module_1</th>\n",
       "      <th>Wind_Speed_1</th>\n",
       "      <th>Hor_Irradiation_1</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>05:45:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:15:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:30:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7.2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.510</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:45:00</td>\n",
       "      <td>Inv-1</td>\n",
       "      <td>1.27</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.57</td>\n",
       "      <td>5.20</td>\n",
       "      <td>25.9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.569</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0        Date      Time    Inv  AC_Real_Power  \\\n",
       "0             0           0  2019-04-01  05:45:00  Inv-1           0.00   \n",
       "1             1           1  2019-04-01  06:00:00  Inv-1           0.00   \n",
       "2             2           2  2019-04-01  06:15:00  Inv-1           0.00   \n",
       "3             3           3  2019-04-01  06:30:00  Inv-1           0.00   \n",
       "4             4           4  2019-04-01  06:45:00  Inv-1           1.27   \n",
       "\n",
       "   AC_Current  DC_Power  DC_Current  Tilt_Irradiation_1  Temp_Ambient_1  \\\n",
       "0         0.0      0.00        5.00                 0.0            17.7   \n",
       "1         0.0      0.00        4.90                 0.0            19.2   \n",
       "2         0.0      0.00        0.61                 0.0            19.0   \n",
       "3         0.0      0.00        0.80                 7.2            19.0   \n",
       "4         6.0      1.57        5.20                25.9            19.7   \n",
       "\n",
       "   Temp_Module_1  Wind_Speed_1  Hor_Irradiation_1  Operation  \n",
       "0           19.6         0.500                0.0          1  \n",
       "1           20.1         0.535                0.0          1  \n",
       "2           20.1         0.500                1.6          1  \n",
       "3           20.6         0.510               10.4          1  \n",
       "4           21.1         0.569               27.0          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.info(),df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b85fa3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 16006\n",
      "Number of columns: 15\n"
     ]
    }
   ],
   "source": [
    "num_rows, num_columns = df.shape\n",
    "\n",
    "print(\"Number of rows:\", num_rows)\n",
    "print(\"Number of columns:\", num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7955081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3d07424",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f564a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('DateTime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3951202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Date','Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83ca7f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = pd.Timestamp(\"07:00:00\")\n",
    "end_time = pd.Timestamp(\"18:30:00\")\n",
    "\n",
    "# Filtering the data to retain only the rows within the operational hours\n",
    "df = df[(df.index.time >= pd.to_datetime('7:00:00').time()) & (df.index.time <= pd.to_datetime('18:30:00').time())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "156809b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inv</th>\n",
       "      <th>AC_Real_Power</th>\n",
       "      <th>AC_Current</th>\n",
       "      <th>DC_Power</th>\n",
       "      <th>DC_Current</th>\n",
       "      <th>Tilt_Irradiation_1</th>\n",
       "      <th>Temp_Ambient_1</th>\n",
       "      <th>Temp_Module_1</th>\n",
       "      <th>Wind_Speed_1</th>\n",
       "      <th>Hor_Irradiation_1</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-01 07:00:00</th>\n",
       "      <td>Inv-1</td>\n",
       "      <td>10.97</td>\n",
       "      <td>21.24</td>\n",
       "      <td>13.39</td>\n",
       "      <td>27.23</td>\n",
       "      <td>44.8</td>\n",
       "      <td>20.2</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.500</td>\n",
       "      <td>48.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 07:15:00</th>\n",
       "      <td>Inv-1</td>\n",
       "      <td>26.38</td>\n",
       "      <td>48.04</td>\n",
       "      <td>31.29</td>\n",
       "      <td>55.98</td>\n",
       "      <td>64.6</td>\n",
       "      <td>22.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>0.614</td>\n",
       "      <td>79.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 07:30:00</th>\n",
       "      <td>Inv-1</td>\n",
       "      <td>47.87</td>\n",
       "      <td>87.27</td>\n",
       "      <td>54.62</td>\n",
       "      <td>93.37</td>\n",
       "      <td>82.6</td>\n",
       "      <td>23.9</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.802</td>\n",
       "      <td>119.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 07:45:00</th>\n",
       "      <td>Inv-1</td>\n",
       "      <td>74.23</td>\n",
       "      <td>135.42</td>\n",
       "      <td>81.58</td>\n",
       "      <td>138.43</td>\n",
       "      <td>103.8</td>\n",
       "      <td>24.6</td>\n",
       "      <td>27.2</td>\n",
       "      <td>1.599</td>\n",
       "      <td>167.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 08:00:00</th>\n",
       "      <td>Inv-1</td>\n",
       "      <td>106.22</td>\n",
       "      <td>193.12</td>\n",
       "      <td>114.93</td>\n",
       "      <td>191.31</td>\n",
       "      <td>281.8</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0.960</td>\n",
       "      <td>220.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Inv  AC_Real_Power  AC_Current  DC_Power  DC_Current  \\\n",
       "DateTime                                                                      \n",
       "2019-04-01 07:00:00  Inv-1          10.97       21.24     13.39       27.23   \n",
       "2019-04-01 07:15:00  Inv-1          26.38       48.04     31.29       55.98   \n",
       "2019-04-01 07:30:00  Inv-1          47.87       87.27     54.62       93.37   \n",
       "2019-04-01 07:45:00  Inv-1          74.23      135.42     81.58      138.43   \n",
       "2019-04-01 08:00:00  Inv-1         106.22      193.12    114.93      191.31   \n",
       "\n",
       "                     Tilt_Irradiation_1  Temp_Ambient_1  Temp_Module_1  \\\n",
       "DateTime                                                                 \n",
       "2019-04-01 07:00:00                44.8            20.2           22.9   \n",
       "2019-04-01 07:15:00                64.6            22.4           24.8   \n",
       "2019-04-01 07:30:00                82.6            23.9           26.1   \n",
       "2019-04-01 07:45:00               103.8            24.6           27.2   \n",
       "2019-04-01 08:00:00               281.8            26.5           31.2   \n",
       "\n",
       "                     Wind_Speed_1  Hor_Irradiation_1  Operation  \n",
       "DateTime                                                         \n",
       "2019-04-01 07:00:00         0.500               48.1          1  \n",
       "2019-04-01 07:15:00         0.614               79.8          1  \n",
       "2019-04-01 07:30:00         0.802              119.5          1  \n",
       "2019-04-01 07:45:00         1.599              167.4          1  \n",
       "2019-04-01 08:00:00         0.960              220.1          1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2354e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inv                   0\n",
      "AC_Real_Power         0\n",
      "AC_Current            0\n",
      "DC_Power              0\n",
      "DC_Current            0\n",
      "Tilt_Irradiation_1    0\n",
      "Temp_Ambient_1        0\n",
      "Temp_Module_1         0\n",
      "Wind_Speed_1          0\n",
      "Hor_Irradiation_1     0\n",
      "Operation             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_data = df.isnull().sum()\n",
    "print(missing_data)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71fbd64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "operational_data = df\n",
    "numerical_features = ['AC_Real_Power','Tilt_Irradiation_1', 'Temp_Ambient_1', 'Hor_Irradiation_1']\n",
    "\n",
    "# Normalization of the features\n",
    "operational_data[numerical_features] = scaler.fit_transform(operational_data[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c10bb0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = operational_data[['Tilt_Irradiation_1', 'Temp_Ambient_1', 'Hor_Irradiation_1']]\n",
    "y = operational_data['AC_Real_Power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb62b8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch [1/200], Loss: 0.1770\n",
      "Validation - Epoch [1/200], Loss: 0.0101\n",
      "Training - Epoch [2/200], Loss: 0.0129\n",
      "Validation - Epoch [2/200], Loss: 0.0159\n",
      "Training - Epoch [3/200], Loss: 0.0122\n",
      "Validation - Epoch [3/200], Loss: 0.0100\n",
      "Training - Epoch [4/200], Loss: 0.0119\n",
      "Validation - Epoch [4/200], Loss: 0.0097\n",
      "Training - Epoch [5/200], Loss: 0.0115\n",
      "Validation - Epoch [5/200], Loss: 0.0121\n",
      "Training - Epoch [6/200], Loss: 0.0108\n",
      "Validation - Epoch [6/200], Loss: 0.0092\n",
      "Training - Epoch [7/200], Loss: 0.0111\n",
      "Validation - Epoch [7/200], Loss: 0.0102\n",
      "Training - Epoch [8/200], Loss: 0.0105\n",
      "Validation - Epoch [8/200], Loss: 0.0146\n",
      "Training - Epoch [9/200], Loss: 0.0106\n",
      "Validation - Epoch [9/200], Loss: 0.0133\n",
      "Training - Epoch [10/200], Loss: 0.0101\n",
      "Validation - Epoch [10/200], Loss: 0.0093\n",
      "Training - Epoch [11/200], Loss: 0.0104\n",
      "Validation - Epoch [11/200], Loss: 0.0129\n",
      "Training - Epoch [12/200], Loss: 0.0105\n",
      "Validation - Epoch [12/200], Loss: 0.0090\n",
      "Training - Epoch [13/200], Loss: 0.0104\n",
      "Validation - Epoch [13/200], Loss: 0.0089\n",
      "Training - Epoch [14/200], Loss: 0.0099\n",
      "Validation - Epoch [14/200], Loss: 0.0081\n",
      "Training - Epoch [15/200], Loss: 0.0095\n",
      "Validation - Epoch [15/200], Loss: 0.0088\n",
      "Training - Epoch [16/200], Loss: 0.0103\n",
      "Validation - Epoch [16/200], Loss: 0.0095\n",
      "Training - Epoch [17/200], Loss: 0.0101\n",
      "Validation - Epoch [17/200], Loss: 0.0082\n",
      "Training - Epoch [18/200], Loss: 0.0101\n",
      "Validation - Epoch [18/200], Loss: 0.0107\n",
      "Training - Epoch [19/200], Loss: 0.0097\n",
      "Validation - Epoch [19/200], Loss: 0.0091\n",
      "Training - Epoch [20/200], Loss: 0.0094\n",
      "Validation - Epoch [20/200], Loss: 0.0151\n",
      "Training - Epoch [21/200], Loss: 0.0100\n",
      "Validation - Epoch [21/200], Loss: 0.0103\n",
      "Training - Epoch [22/200], Loss: 0.0094\n",
      "Validation - Epoch [22/200], Loss: 0.0087\n",
      "Training - Epoch [23/200], Loss: 0.0111\n",
      "Validation - Epoch [23/200], Loss: 0.0105\n",
      "Training - Epoch [24/200], Loss: 0.0097\n",
      "Validation - Epoch [24/200], Loss: 0.0086\n",
      "Training - Epoch [25/200], Loss: 0.0097\n",
      "Validation - Epoch [25/200], Loss: 0.0095\n",
      "Training - Epoch [26/200], Loss: 0.0100\n",
      "Validation - Epoch [26/200], Loss: 0.0091\n",
      "Training - Epoch [27/200], Loss: 0.0096\n",
      "Validation - Epoch [27/200], Loss: 0.0097\n",
      "Training - Epoch [28/200], Loss: 0.0095\n",
      "Validation - Epoch [28/200], Loss: 0.0093\n",
      "Training - Epoch [29/200], Loss: 0.0095\n",
      "Validation - Epoch [29/200], Loss: 0.0080\n",
      "Training - Epoch [30/200], Loss: 0.0094\n",
      "Validation - Epoch [30/200], Loss: 0.0101\n",
      "Training - Epoch [31/200], Loss: 0.0091\n",
      "Validation - Epoch [31/200], Loss: 0.0084\n",
      "Training - Epoch [32/200], Loss: 0.0094\n",
      "Validation - Epoch [32/200], Loss: 0.0089\n",
      "Training - Epoch [33/200], Loss: 0.0367\n",
      "Validation - Epoch [33/200], Loss: 0.0795\n",
      "Training - Epoch [34/200], Loss: 0.0608\n",
      "Validation - Epoch [34/200], Loss: 0.0680\n",
      "Training - Epoch [35/200], Loss: 0.0714\n",
      "Validation - Epoch [35/200], Loss: 0.0811\n",
      "Training - Epoch [36/200], Loss: 0.0749\n",
      "Validation - Epoch [36/200], Loss: 0.0535\n",
      "Training - Epoch [37/200], Loss: 0.0568\n",
      "Validation - Epoch [37/200], Loss: 0.0701\n",
      "Training - Epoch [38/200], Loss: 0.0554\n",
      "Validation - Epoch [38/200], Loss: 0.0468\n",
      "Training - Epoch [39/200], Loss: 0.0359\n",
      "Validation - Epoch [39/200], Loss: 0.0304\n",
      "Training - Epoch [40/200], Loss: 0.0271\n",
      "Validation - Epoch [40/200], Loss: 0.0214\n",
      "Training - Epoch [41/200], Loss: 0.0202\n",
      "Validation - Epoch [41/200], Loss: 0.0141\n",
      "Training - Epoch [42/200], Loss: 0.0155\n",
      "Validation - Epoch [42/200], Loss: 0.0118\n",
      "Training - Epoch [43/200], Loss: 0.0137\n",
      "Validation - Epoch [43/200], Loss: 0.0116\n",
      "Training - Epoch [44/200], Loss: 0.0121\n",
      "Validation - Epoch [44/200], Loss: 0.0137\n",
      "Training - Epoch [45/200], Loss: 0.0115\n",
      "Validation - Epoch [45/200], Loss: 0.0104\n",
      "Training - Epoch [46/200], Loss: 0.0114\n",
      "Validation - Epoch [46/200], Loss: 0.0104\n",
      "Training - Epoch [47/200], Loss: 0.0113\n",
      "Validation - Epoch [47/200], Loss: 0.0098\n",
      "Training - Epoch [48/200], Loss: 0.0128\n",
      "Validation - Epoch [48/200], Loss: 0.0137\n",
      "Training - Epoch [49/200], Loss: 0.0110\n",
      "Validation - Epoch [49/200], Loss: 0.0097\n",
      "Training - Epoch [50/200], Loss: 0.0112\n",
      "Validation - Epoch [50/200], Loss: 0.0113\n",
      "Training - Epoch [51/200], Loss: 0.0110\n",
      "Validation - Epoch [51/200], Loss: 0.0103\n",
      "Training - Epoch [52/200], Loss: 0.0118\n",
      "Validation - Epoch [52/200], Loss: 0.0107\n",
      "Training - Epoch [53/200], Loss: 0.0109\n",
      "Validation - Epoch [53/200], Loss: 0.0119\n",
      "Training - Epoch [54/200], Loss: 0.0107\n",
      "Validation - Epoch [54/200], Loss: 0.0095\n",
      "Training - Epoch [55/200], Loss: 0.0105\n",
      "Validation - Epoch [55/200], Loss: 0.0134\n",
      "Training - Epoch [56/200], Loss: 0.0106\n",
      "Validation - Epoch [56/200], Loss: 0.0100\n",
      "Training - Epoch [57/200], Loss: 0.0107\n",
      "Validation - Epoch [57/200], Loss: 0.0094\n",
      "Training - Epoch [58/200], Loss: 0.0104\n",
      "Validation - Epoch [58/200], Loss: 0.0131\n",
      "Training - Epoch [59/200], Loss: 0.0106\n",
      "Validation - Epoch [59/200], Loss: 0.0096\n",
      "Training - Epoch [60/200], Loss: 0.0109\n",
      "Validation - Epoch [60/200], Loss: 0.0096\n",
      "Training - Epoch [61/200], Loss: 0.0105\n",
      "Validation - Epoch [61/200], Loss: 0.0094\n",
      "Training - Epoch [62/200], Loss: 0.0104\n",
      "Validation - Epoch [62/200], Loss: 0.0107\n",
      "Training - Epoch [63/200], Loss: 0.0107\n",
      "Validation - Epoch [63/200], Loss: 0.0100\n",
      "Training - Epoch [64/200], Loss: 0.0105\n",
      "Validation - Epoch [64/200], Loss: 0.0100\n",
      "Training - Epoch [65/200], Loss: 0.0102\n",
      "Validation - Epoch [65/200], Loss: 0.0090\n",
      "Training - Epoch [66/200], Loss: 0.0108\n",
      "Validation - Epoch [66/200], Loss: 0.0103\n",
      "Training - Epoch [67/200], Loss: 0.0105\n",
      "Validation - Epoch [67/200], Loss: 0.0097\n",
      "Training - Epoch [68/200], Loss: 0.0104\n",
      "Validation - Epoch [68/200], Loss: 0.0102\n",
      "Training - Epoch [69/200], Loss: 0.0103\n",
      "Validation - Epoch [69/200], Loss: 0.0104\n",
      "Training - Epoch [70/200], Loss: 0.0103\n",
      "Validation - Epoch [70/200], Loss: 0.0102\n",
      "Training - Epoch [71/200], Loss: 0.0102\n",
      "Validation - Epoch [71/200], Loss: 0.0106\n",
      "Training - Epoch [72/200], Loss: 0.0103\n",
      "Validation - Epoch [72/200], Loss: 0.0092\n",
      "Training - Epoch [73/200], Loss: 0.0102\n",
      "Validation - Epoch [73/200], Loss: 0.0094\n",
      "Training - Epoch [74/200], Loss: 0.0103\n",
      "Validation - Epoch [74/200], Loss: 0.0096\n",
      "Training - Epoch [75/200], Loss: 0.0100\n",
      "Validation - Epoch [75/200], Loss: 0.0093\n",
      "Training - Epoch [76/200], Loss: 0.0106\n",
      "Validation - Epoch [76/200], Loss: 0.0090\n",
      "Training - Epoch [77/200], Loss: 0.0102\n",
      "Validation - Epoch [77/200], Loss: 0.0099\n",
      "Training - Epoch [78/200], Loss: 0.0101\n",
      "Validation - Epoch [78/200], Loss: 0.0101\n",
      "Training - Epoch [79/200], Loss: 0.0102\n",
      "Validation - Epoch [79/200], Loss: 0.0094\n",
      "Training - Epoch [80/200], Loss: 0.0103\n",
      "Validation - Epoch [80/200], Loss: 0.0110\n",
      "Training - Epoch [81/200], Loss: 0.0104\n",
      "Validation - Epoch [81/200], Loss: 0.0104\n",
      "Training - Epoch [82/200], Loss: 0.0102\n",
      "Validation - Epoch [82/200], Loss: 0.0098\n",
      "Training - Epoch [83/200], Loss: 0.0101\n",
      "Validation - Epoch [83/200], Loss: 0.0091\n",
      "Training - Epoch [84/200], Loss: 0.0101\n",
      "Validation - Epoch [84/200], Loss: 0.0104\n",
      "Training - Epoch [85/200], Loss: 0.0103\n",
      "Validation - Epoch [85/200], Loss: 0.0094\n",
      "Training - Epoch [86/200], Loss: 0.0101\n",
      "Validation - Epoch [86/200], Loss: 0.0106\n",
      "Training - Epoch [87/200], Loss: 0.0102\n",
      "Validation - Epoch [87/200], Loss: 0.0100\n",
      "Training - Epoch [88/200], Loss: 0.0101\n",
      "Validation - Epoch [88/200], Loss: 0.0095\n",
      "Training - Epoch [89/200], Loss: 0.0101\n",
      "Validation - Epoch [89/200], Loss: 0.0113\n",
      "Training - Epoch [90/200], Loss: 0.0103\n",
      "Validation - Epoch [90/200], Loss: 0.0107\n",
      "Training - Epoch [91/200], Loss: 0.0102\n",
      "Validation - Epoch [91/200], Loss: 0.0096\n",
      "Training - Epoch [92/200], Loss: 0.0100\n",
      "Validation - Epoch [92/200], Loss: 0.0099\n",
      "Training - Epoch [93/200], Loss: 0.0103\n",
      "Validation - Epoch [93/200], Loss: 0.0100\n",
      "Training - Epoch [94/200], Loss: 0.0100\n",
      "Validation - Epoch [94/200], Loss: 0.0093\n",
      "Training - Epoch [95/200], Loss: 0.0099\n",
      "Validation - Epoch [95/200], Loss: 0.0117\n",
      "Training - Epoch [96/200], Loss: 0.0101\n",
      "Validation - Epoch [96/200], Loss: 0.0091\n",
      "Training - Epoch [97/200], Loss: 0.0098\n",
      "Validation - Epoch [97/200], Loss: 0.0095\n",
      "Training - Epoch [98/200], Loss: 0.0101\n",
      "Validation - Epoch [98/200], Loss: 0.0093\n",
      "Training - Epoch [99/200], Loss: 0.0101\n",
      "Validation - Epoch [99/200], Loss: 0.0095\n",
      "Training - Epoch [100/200], Loss: 0.0099\n",
      "Validation - Epoch [100/200], Loss: 0.0094\n",
      "Training - Epoch [101/200], Loss: 0.0101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch [101/200], Loss: 0.0100\n",
      "Training - Epoch [102/200], Loss: 0.0100\n",
      "Validation - Epoch [102/200], Loss: 0.0106\n",
      "Training - Epoch [103/200], Loss: 0.0101\n",
      "Validation - Epoch [103/200], Loss: 0.0099\n",
      "Training - Epoch [104/200], Loss: 0.0103\n",
      "Validation - Epoch [104/200], Loss: 0.0110\n",
      "Training - Epoch [105/200], Loss: 0.0099\n",
      "Validation - Epoch [105/200], Loss: 0.0108\n",
      "Training - Epoch [106/200], Loss: 0.0100\n",
      "Validation - Epoch [106/200], Loss: 0.0092\n",
      "Training - Epoch [107/200], Loss: 0.0097\n",
      "Validation - Epoch [107/200], Loss: 0.0091\n",
      "Training - Epoch [108/200], Loss: 0.0100\n",
      "Validation - Epoch [108/200], Loss: 0.0093\n",
      "Training - Epoch [109/200], Loss: 0.0104\n",
      "Validation - Epoch [109/200], Loss: 0.0091\n",
      "Training - Epoch [110/200], Loss: 0.0102\n",
      "Validation - Epoch [110/200], Loss: 0.0103\n",
      "Training - Epoch [111/200], Loss: 0.0104\n",
      "Validation - Epoch [111/200], Loss: 0.0093\n",
      "Training - Epoch [112/200], Loss: 0.0097\n",
      "Validation - Epoch [112/200], Loss: 0.0095\n",
      "Training - Epoch [113/200], Loss: 0.0098\n",
      "Validation - Epoch [113/200], Loss: 0.0100\n",
      "Training - Epoch [114/200], Loss: 0.0098\n",
      "Validation - Epoch [114/200], Loss: 0.0101\n",
      "Training - Epoch [115/200], Loss: 0.0099\n",
      "Validation - Epoch [115/200], Loss: 0.0101\n",
      "Training - Epoch [116/200], Loss: 0.0097\n",
      "Validation - Epoch [116/200], Loss: 0.0094\n",
      "Training - Epoch [117/200], Loss: 0.0102\n",
      "Validation - Epoch [117/200], Loss: 0.0101\n",
      "Training - Epoch [118/200], Loss: 0.0098\n",
      "Validation - Epoch [118/200], Loss: 0.0102\n",
      "Training - Epoch [119/200], Loss: 0.0100\n",
      "Validation - Epoch [119/200], Loss: 0.0092\n",
      "Training - Epoch [120/200], Loss: 0.0097\n",
      "Validation - Epoch [120/200], Loss: 0.0092\n",
      "Training - Epoch [121/200], Loss: 0.0099\n",
      "Validation - Epoch [121/200], Loss: 0.0090\n",
      "Training - Epoch [122/200], Loss: 0.0100\n",
      "Validation - Epoch [122/200], Loss: 0.0097\n",
      "Training - Epoch [123/200], Loss: 0.0098\n",
      "Validation - Epoch [123/200], Loss: 0.0102\n",
      "Training - Epoch [124/200], Loss: 0.0101\n",
      "Validation - Epoch [124/200], Loss: 0.0101\n",
      "Training - Epoch [125/200], Loss: 0.0097\n",
      "Validation - Epoch [125/200], Loss: 0.0096\n",
      "Training - Epoch [126/200], Loss: 0.0098\n",
      "Validation - Epoch [126/200], Loss: 0.0101\n",
      "Training - Epoch [127/200], Loss: 0.0095\n",
      "Validation - Epoch [127/200], Loss: 0.0093\n",
      "Training - Epoch [128/200], Loss: 0.0097\n",
      "Validation - Epoch [128/200], Loss: 0.0091\n",
      "Training - Epoch [129/200], Loss: 0.0097\n",
      "Validation - Epoch [129/200], Loss: 0.0101\n",
      "Training - Epoch [130/200], Loss: 0.0099\n",
      "Validation - Epoch [130/200], Loss: 0.0093\n",
      "Training - Epoch [131/200], Loss: 0.0100\n",
      "Validation - Epoch [131/200], Loss: 0.0106\n",
      "Training - Epoch [132/200], Loss: 0.0098\n",
      "Validation - Epoch [132/200], Loss: 0.0094\n",
      "Training - Epoch [133/200], Loss: 0.0122\n",
      "Validation - Epoch [133/200], Loss: 0.0121\n",
      "Training - Epoch [134/200], Loss: 0.0106\n",
      "Validation - Epoch [134/200], Loss: 0.0097\n",
      "Training - Epoch [135/200], Loss: 0.0097\n",
      "Validation - Epoch [135/200], Loss: 0.0098\n",
      "Training - Epoch [136/200], Loss: 0.0096\n",
      "Validation - Epoch [136/200], Loss: 0.0096\n",
      "Training - Epoch [137/200], Loss: 0.0098\n",
      "Validation - Epoch [137/200], Loss: 0.0100\n",
      "Training - Epoch [138/200], Loss: 0.0096\n",
      "Validation - Epoch [138/200], Loss: 0.0094\n",
      "Training - Epoch [139/200], Loss: 0.0095\n",
      "Validation - Epoch [139/200], Loss: 0.0094\n",
      "Training - Epoch [140/200], Loss: 0.0097\n",
      "Validation - Epoch [140/200], Loss: 0.0091\n",
      "Training - Epoch [141/200], Loss: 0.0096\n",
      "Validation - Epoch [141/200], Loss: 0.0102\n",
      "Training - Epoch [142/200], Loss: 0.0095\n",
      "Validation - Epoch [142/200], Loss: 0.0094\n",
      "Training - Epoch [143/200], Loss: 0.0096\n",
      "Validation - Epoch [143/200], Loss: 0.0096\n",
      "Training - Epoch [144/200], Loss: 0.0093\n",
      "Validation - Epoch [144/200], Loss: 0.0097\n",
      "Training - Epoch [145/200], Loss: 0.0100\n",
      "Validation - Epoch [145/200], Loss: 0.0090\n",
      "Training - Epoch [146/200], Loss: 0.0097\n",
      "Validation - Epoch [146/200], Loss: 0.0094\n",
      "Training - Epoch [147/200], Loss: 0.0095\n",
      "Validation - Epoch [147/200], Loss: 0.0090\n",
      "Training - Epoch [148/200], Loss: 0.0098\n",
      "Validation - Epoch [148/200], Loss: 0.0089\n",
      "Training - Epoch [149/200], Loss: 0.0096\n",
      "Validation - Epoch [149/200], Loss: 0.0108\n",
      "Training - Epoch [150/200], Loss: 0.0097\n",
      "Validation - Epoch [150/200], Loss: 0.0091\n",
      "Training - Epoch [151/200], Loss: 0.0097\n",
      "Validation - Epoch [151/200], Loss: 0.0095\n",
      "Training - Epoch [152/200], Loss: 0.0098\n",
      "Validation - Epoch [152/200], Loss: 0.0100\n",
      "Training - Epoch [153/200], Loss: 0.0095\n",
      "Validation - Epoch [153/200], Loss: 0.0093\n",
      "Training - Epoch [154/200], Loss: 0.0097\n",
      "Validation - Epoch [154/200], Loss: 0.0097\n",
      "Training - Epoch [155/200], Loss: 0.0106\n",
      "Validation - Epoch [155/200], Loss: 0.0134\n",
      "Training - Epoch [156/200], Loss: 0.0111\n",
      "Validation - Epoch [156/200], Loss: 0.0094\n",
      "Training - Epoch [157/200], Loss: 0.0098\n",
      "Validation - Epoch [157/200], Loss: 0.0103\n",
      "Training - Epoch [158/200], Loss: 0.0098\n",
      "Validation - Epoch [158/200], Loss: 0.0093\n",
      "Training - Epoch [159/200], Loss: 0.0097\n",
      "Validation - Epoch [159/200], Loss: 0.0105\n",
      "Training - Epoch [160/200], Loss: 0.0096\n",
      "Validation - Epoch [160/200], Loss: 0.0089\n",
      "Training - Epoch [161/200], Loss: 0.0096\n",
      "Validation - Epoch [161/200], Loss: 0.0100\n",
      "Training - Epoch [162/200], Loss: 0.0094\n",
      "Validation - Epoch [162/200], Loss: 0.0092\n",
      "Training - Epoch [163/200], Loss: 0.0094\n",
      "Validation - Epoch [163/200], Loss: 0.0091\n",
      "Training - Epoch [164/200], Loss: 0.0094\n",
      "Validation - Epoch [164/200], Loss: 0.0089\n",
      "Training - Epoch [165/200], Loss: 0.0098\n",
      "Validation - Epoch [165/200], Loss: 0.0093\n",
      "Training - Epoch [166/200], Loss: 0.0094\n",
      "Validation - Epoch [166/200], Loss: 0.0096\n",
      "Training - Epoch [167/200], Loss: 0.0096\n",
      "Validation - Epoch [167/200], Loss: 0.0094\n",
      "Training - Epoch [168/200], Loss: 0.0098\n",
      "Validation - Epoch [168/200], Loss: 0.0093\n",
      "Training - Epoch [169/200], Loss: 0.0095\n",
      "Validation - Epoch [169/200], Loss: 0.0089\n",
      "Training - Epoch [170/200], Loss: 0.0096\n",
      "Validation - Epoch [170/200], Loss: 0.0093\n",
      "Training - Epoch [171/200], Loss: 0.0094\n",
      "Validation - Epoch [171/200], Loss: 0.0105\n",
      "Training - Epoch [172/200], Loss: 0.0094\n",
      "Validation - Epoch [172/200], Loss: 0.0096\n",
      "Training - Epoch [173/200], Loss: 0.0094\n",
      "Validation - Epoch [173/200], Loss: 0.0092\n",
      "Training - Epoch [174/200], Loss: 0.0096\n",
      "Validation - Epoch [174/200], Loss: 0.0110\n",
      "Training - Epoch [175/200], Loss: 0.0096\n",
      "Validation - Epoch [175/200], Loss: 0.0096\n",
      "Training - Epoch [176/200], Loss: 0.0096\n",
      "Validation - Epoch [176/200], Loss: 0.0089\n",
      "Training - Epoch [177/200], Loss: 0.0094\n",
      "Validation - Epoch [177/200], Loss: 0.0100\n",
      "Training - Epoch [178/200], Loss: 0.0095\n",
      "Validation - Epoch [178/200], Loss: 0.0092\n",
      "Training - Epoch [179/200], Loss: 0.0095\n",
      "Validation - Epoch [179/200], Loss: 0.0097\n",
      "Training - Epoch [180/200], Loss: 0.0094\n",
      "Validation - Epoch [180/200], Loss: 0.0091\n",
      "Training - Epoch [181/200], Loss: 0.0096\n",
      "Validation - Epoch [181/200], Loss: 0.0092\n",
      "Training - Epoch [182/200], Loss: 0.0098\n",
      "Validation - Epoch [182/200], Loss: 0.0091\n",
      "Training - Epoch [183/200], Loss: 0.0095\n",
      "Validation - Epoch [183/200], Loss: 0.0093\n",
      "Training - Epoch [184/200], Loss: 0.0098\n",
      "Validation - Epoch [184/200], Loss: 0.0095\n",
      "Training - Epoch [185/200], Loss: 0.0095\n",
      "Validation - Epoch [185/200], Loss: 0.0092\n",
      "Training - Epoch [186/200], Loss: 0.0094\n",
      "Validation - Epoch [186/200], Loss: 0.0091\n",
      "Training - Epoch [187/200], Loss: 0.0095\n",
      "Validation - Epoch [187/200], Loss: 0.0090\n",
      "Training - Epoch [188/200], Loss: 0.0093\n",
      "Validation - Epoch [188/200], Loss: 0.0096\n",
      "Training - Epoch [189/200], Loss: 0.0095\n",
      "Validation - Epoch [189/200], Loss: 0.0091\n",
      "Training - Epoch [190/200], Loss: 0.0093\n",
      "Validation - Epoch [190/200], Loss: 0.0098\n",
      "Training - Epoch [191/200], Loss: 0.0094\n",
      "Validation - Epoch [191/200], Loss: 0.0103\n",
      "Training - Epoch [192/200], Loss: 0.0094\n",
      "Validation - Epoch [192/200], Loss: 0.0092\n",
      "Training - Epoch [193/200], Loss: 0.0094\n",
      "Validation - Epoch [193/200], Loss: 0.0092\n",
      "Training - Epoch [194/200], Loss: 0.0093\n",
      "Validation - Epoch [194/200], Loss: 0.0091\n",
      "Training - Epoch [195/200], Loss: 0.0095\n",
      "Validation - Epoch [195/200], Loss: 0.0095\n",
      "Training - Epoch [196/200], Loss: 0.0094\n",
      "Validation - Epoch [196/200], Loss: 0.0092\n",
      "Training - Epoch [197/200], Loss: 0.0093\n",
      "Validation - Epoch [197/200], Loss: 0.0091\n",
      "Training - Epoch [198/200], Loss: 0.0097\n",
      "Validation - Epoch [198/200], Loss: 0.0107\n",
      "Training - Epoch [199/200], Loss: 0.0098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch [199/200], Loss: 0.0096\n",
      "Training - Epoch [200/200], Loss: 0.0094\n",
      "Validation - Epoch [200/200], Loss: 0.0091\n"
     ]
    }
   ],
   "source": [
    "# Transformer Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, hidden_dim, num_layers, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.squeeze(1)\n",
    "        x = self.fc(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.tensor(features.values, dtype=torch.float32) \n",
    "        self.targets = torch.tensor(targets.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = X_train.shape[1]  # Dimension of input features\n",
    "num_heads = 2  # Number of attention heads = 2\n",
    "hidden_dim = 200  # Hidden layers of the model = 200\n",
    "num_layers = 2  # Number of transformer layers = 2\n",
    "dropout = 0.1  # Dropout probability = 0.1\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "model = TransformerModel(input_dim=input_dim, num_heads=num_heads, hidden_dim=hidden_dim,\n",
    "                          num_layers=num_layers, dropout=dropout)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression task\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Optimizer used is Adam and learning rate is 0.001\n",
    "\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(inputs)\n",
    "    average_loss = total_loss / len(train_dataset)\n",
    "    print(f'Training - Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for inputs, labels in test_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * len(inputs)\n",
    "        average_loss = total_loss / len(test_dataset)\n",
    "        print(f'Validation - Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        # Stored true labels and predictions\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(outputs.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c07091a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        # Stored true labels and predictions\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(outputs.numpy())\n",
    "\n",
    "# Converted y_true and y_pred to numpy arrays\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Computed confusion matrix\n",
    "cm = confusion_matrix(np.round(y_true), np.round(y_pred))\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be64d6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.009082953\n",
      "Mean Absolute Error: 0.063675724\n",
      "Root Mean Squared Error: 0.09530453\n",
      "R-squared Score: 0.8852351047321867\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Computed Mean Squared Error\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "# Computed Mean Absolute Error\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# Computed Root Mean Squared Error\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Computed R2-Score\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1921802c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alarm triggered for 8 consecutive faults on 2019-06-01.\n",
      "Alarm triggered for 8 consecutive faults on 2019-04-04.\n",
      "Alarm triggered for 8 consecutive faults on 2019-05-10.\n",
      "Alarm triggered for 7 consecutive faults on 2019-05-30.\n",
      "Alarm triggered for 7 consecutive faults on 2019-05-28.\n",
      "Alarm triggered for 7 consecutive faults on 2019-04-17.\n",
      "Alarm triggered for 7 consecutive faults on 2019-04-15.\n",
      "Alarm triggered for 7 consecutive faults on 2019-05-21.\n",
      "Alarm triggered for 6 consecutive faults on 2019-05-29.\n",
      "Alarm triggered for 6 consecutive faults on 2019-05-04.\n",
      "Alarm triggered for 6 consecutive faults on 2019-05-22.\n",
      "Alarm triggered for 6 consecutive faults on 2019-06-04.\n",
      "Alarm triggered for 6 consecutive faults on 2019-05-27.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-05.\n",
      "Alarm triggered for 6 consecutive faults on 2019-05-05.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-08.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-11.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-07.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-08.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-19.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-06.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-21.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-03.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-12.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-27.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-28.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-16.\n",
      "Alarm triggered for 4 consecutive faults on 2019-05-20.\n",
      "Alarm triggered for 4 consecutive faults on 2019-06-02.\n",
      "Alarm triggered for 4 consecutive faults on 2019-06-03.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-20.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-29.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-24.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-18.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-14.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-10.\n",
      "Alarm triggered for 4 consecutive faults on 2019-06-05.\n"
     ]
    }
   ],
   "source": [
    "# Function to check for four consecutive faults in a day and trigger alarms\n",
    "def check_consecutive_faults(fault_indices, df, window=3):\n",
    "    fault_timestamps = df.index[fault_indices]\n",
    "\n",
    "    grouped_by_day = fault_timestamps.to_series().dt.date\n",
    "\n",
    "    # Checked if there are three or more consecutive faults within the same day\n",
    "    daily_fault_count = grouped_by_day.value_counts()\n",
    "    for date, count in daily_fault_count.items():\n",
    "        if count >= window:\n",
    "            print(f\"Alarm triggered for {count} consecutive faults on {date}.\")\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_ac_power = model(X_test_tensor)  # Model predictions\n",
    "    actual_ac_power = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "    # Absolute residuals between predicted and actual AC power\n",
    "    residuals = torch.abs(predicted_ac_power - actual_ac_power)\n",
    "\n",
    "# Calculated the standard deviation for setting the fault threshold\n",
    "sigma = torch.std(residuals).item()\n",
    "threshold = 2 * sigma  # Set the threshold as 2 * sigma\n",
    "\n",
    "anomalies = (residuals > threshold).int()\n",
    "\n",
    "fault_indices = torch.nonzero(anomalies).squeeze().tolist()\n",
    "\n",
    "check_consecutive_faults(fault_indices, df, window=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b234b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
