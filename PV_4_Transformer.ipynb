{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e506f466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score, classification_report, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a10f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\My PC\\Desktop\\Solar PV Fault Research\\IO_DATA_LABELED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fca8806",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Inv-3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98ddeaa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Inv</th>\n",
       "      <th>AC_Real_Power</th>\n",
       "      <th>AC_Current</th>\n",
       "      <th>DC_Power</th>\n",
       "      <th>DC_Current</th>\n",
       "      <th>Tilt_Irradiation_1</th>\n",
       "      <th>Temp_Ambient_1</th>\n",
       "      <th>Temp_Module_1</th>\n",
       "      <th>Wind_Speed_1</th>\n",
       "      <th>Hor_Irradiation_1</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>05:45:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:15:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:30:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.510</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:45:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>1.09</td>\n",
       "      <td>6.02</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.91</td>\n",
       "      <td>25.9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.569</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16001</th>\n",
       "      <td>16001</td>\n",
       "      <td>16001</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>18:30:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>5.19</td>\n",
       "      <td>9.88</td>\n",
       "      <td>6.40</td>\n",
       "      <td>13.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16002</th>\n",
       "      <td>16002</td>\n",
       "      <td>16002</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>18:45:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.7</td>\n",
       "      <td>27.2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16003</th>\n",
       "      <td>16003</td>\n",
       "      <td>16003</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16004</th>\n",
       "      <td>16004</td>\n",
       "      <td>16004</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>19:15:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16005</th>\n",
       "      <td>16005</td>\n",
       "      <td>16005</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>19:30:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.1</td>\n",
       "      <td>25.7</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16006 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0        Date      Time    Inv  AC_Real_Power  \\\n",
       "0                 0           0  2019-04-01  05:45:00  Inv-3           0.00   \n",
       "1                 1           1  2019-04-01  06:00:00  Inv-3           0.00   \n",
       "2                 2           2  2019-04-01  06:15:00  Inv-3           0.00   \n",
       "3                 3           3  2019-04-01  06:30:00  Inv-3           0.00   \n",
       "4                 4           4  2019-04-01  06:45:00  Inv-3           1.09   \n",
       "...             ...         ...         ...       ...    ...            ...   \n",
       "16001         16001       16001  2020-02-29  18:30:00  Inv-3           5.19   \n",
       "16002         16002       16002  2020-02-29  18:45:00  Inv-3           0.00   \n",
       "16003         16003       16003  2020-02-29  19:00:00  Inv-3           0.00   \n",
       "16004         16004       16004  2020-02-29  19:15:00  Inv-3           0.00   \n",
       "16005         16005       16005  2020-02-29  19:30:00  Inv-3           0.00   \n",
       "\n",
       "       AC_Current  DC_Power  DC_Current  Tilt_Irradiation_1  Temp_Ambient_1  \\\n",
       "0            0.00      0.00        3.66                 0.0            17.7   \n",
       "1            0.00      0.00        2.84                 0.0            19.2   \n",
       "2            0.00      0.00        0.00                 0.0            19.0   \n",
       "3            0.00      0.00        0.00                 7.2            19.0   \n",
       "4            6.02      1.35        3.91                25.9            19.7   \n",
       "...           ...       ...         ...                 ...             ...   \n",
       "16001        9.88      6.40       13.46                 0.0            26.4   \n",
       "16002        0.00      0.00        0.00                 0.0            25.7   \n",
       "16003        0.00      0.00        0.00                 0.0            24.1   \n",
       "16004        0.00      0.00        0.37                 0.0            24.3   \n",
       "16005        0.00      0.00        1.26                 0.0            25.1   \n",
       "\n",
       "       Temp_Module_1  Wind_Speed_1  Hor_Irradiation_1  Operation  \n",
       "0               19.6         0.500                0.0          1  \n",
       "1               20.1         0.535                0.0          1  \n",
       "2               20.1         0.500                1.6          1  \n",
       "3               20.6         0.510               10.4          1  \n",
       "4               21.1         0.569               27.0          1  \n",
       "...              ...           ...                ...        ...  \n",
       "16001           28.6         0.500                3.2          1  \n",
       "16002           27.2         0.500                0.2          1  \n",
       "16003           26.1         0.500                0.1          1  \n",
       "16004           25.7         0.728                0.1          1  \n",
       "16005           25.7         1.010                0.1          1  \n",
       "\n",
       "[16006 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af09a94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16006 entries, 0 to 16005\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Unnamed: 0.1        16006 non-null  int64  \n",
      " 1   Unnamed: 0          16006 non-null  int64  \n",
      " 2   Date                16006 non-null  object \n",
      " 3   Time                16006 non-null  object \n",
      " 4   Inv                 16006 non-null  object \n",
      " 5   AC_Real_Power       16002 non-null  float64\n",
      " 6   AC_Current          16002 non-null  float64\n",
      " 7   DC_Power            16002 non-null  float64\n",
      " 8   DC_Current          16002 non-null  float64\n",
      " 9   Tilt_Irradiation_1  16006 non-null  float64\n",
      " 10  Temp_Ambient_1      16006 non-null  float64\n",
      " 11  Temp_Module_1       16006 non-null  float64\n",
      " 12  Wind_Speed_1        16006 non-null  float64\n",
      " 13  Hor_Irradiation_1   16006 non-null  float64\n",
      " 14  Operation           16006 non-null  int64  \n",
      "dtypes: float64(9), int64(3), object(3)\n",
      "memory usage: 1.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Inv</th>\n",
       "      <th>AC_Real_Power</th>\n",
       "      <th>AC_Current</th>\n",
       "      <th>DC_Power</th>\n",
       "      <th>DC_Current</th>\n",
       "      <th>Tilt_Irradiation_1</th>\n",
       "      <th>Temp_Ambient_1</th>\n",
       "      <th>Temp_Module_1</th>\n",
       "      <th>Wind_Speed_1</th>\n",
       "      <th>Hor_Irradiation_1</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>05:45:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:15:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:30:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.510</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>06:45:00</td>\n",
       "      <td>Inv-3</td>\n",
       "      <td>1.09</td>\n",
       "      <td>6.02</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.91</td>\n",
       "      <td>25.9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.569</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0        Date      Time    Inv  AC_Real_Power  \\\n",
       "0             0           0  2019-04-01  05:45:00  Inv-3           0.00   \n",
       "1             1           1  2019-04-01  06:00:00  Inv-3           0.00   \n",
       "2             2           2  2019-04-01  06:15:00  Inv-3           0.00   \n",
       "3             3           3  2019-04-01  06:30:00  Inv-3           0.00   \n",
       "4             4           4  2019-04-01  06:45:00  Inv-3           1.09   \n",
       "\n",
       "   AC_Current  DC_Power  DC_Current  Tilt_Irradiation_1  Temp_Ambient_1  \\\n",
       "0        0.00      0.00        3.66                 0.0            17.7   \n",
       "1        0.00      0.00        2.84                 0.0            19.2   \n",
       "2        0.00      0.00        0.00                 0.0            19.0   \n",
       "3        0.00      0.00        0.00                 7.2            19.0   \n",
       "4        6.02      1.35        3.91                25.9            19.7   \n",
       "\n",
       "   Temp_Module_1  Wind_Speed_1  Hor_Irradiation_1  Operation  \n",
       "0           19.6         0.500                0.0          1  \n",
       "1           20.1         0.535                0.0          1  \n",
       "2           20.1         0.500                1.6          1  \n",
       "3           20.6         0.510               10.4          1  \n",
       "4           21.1         0.569               27.0          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.info(),df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d1a152e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 16006\n",
      "Number of columns: 15\n"
     ]
    }
   ],
   "source": [
    "num_rows, num_columns = df.shape\n",
    "\n",
    "print(\"Number of rows:\", num_rows)\n",
    "print(\"Number of columns:\", num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39f6fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54b1bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e2bcfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('DateTime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c87b6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Date','Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4a9881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = pd.Timestamp(\"07:00:00\")\n",
    "end_time = pd.Timestamp(\"18:30:00\")\n",
    "\n",
    "# Filtering the data to retain only the rows within the operational hours\n",
    "df = df[(df.index.time >= pd.to_datetime('7:00:00').time()) & (df.index.time <= pd.to_datetime('18:30:00').time())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d91fc142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inv</th>\n",
       "      <th>AC_Real_Power</th>\n",
       "      <th>AC_Current</th>\n",
       "      <th>DC_Power</th>\n",
       "      <th>DC_Current</th>\n",
       "      <th>Tilt_Irradiation_1</th>\n",
       "      <th>Temp_Ambient_1</th>\n",
       "      <th>Temp_Module_1</th>\n",
       "      <th>Wind_Speed_1</th>\n",
       "      <th>Hor_Irradiation_1</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-01 07:00:00</th>\n",
       "      <td>Inv-3</td>\n",
       "      <td>10.28</td>\n",
       "      <td>19.65</td>\n",
       "      <td>12.56</td>\n",
       "      <td>24.98</td>\n",
       "      <td>44.8</td>\n",
       "      <td>20.2</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.500</td>\n",
       "      <td>48.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 07:15:00</th>\n",
       "      <td>Inv-3</td>\n",
       "      <td>26.17</td>\n",
       "      <td>47.72</td>\n",
       "      <td>31.05</td>\n",
       "      <td>54.93</td>\n",
       "      <td>64.6</td>\n",
       "      <td>22.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>0.614</td>\n",
       "      <td>79.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 07:30:00</th>\n",
       "      <td>Inv-3</td>\n",
       "      <td>45.80</td>\n",
       "      <td>83.65</td>\n",
       "      <td>52.47</td>\n",
       "      <td>93.66</td>\n",
       "      <td>82.6</td>\n",
       "      <td>23.9</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.802</td>\n",
       "      <td>119.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 07:45:00</th>\n",
       "      <td>Inv-3</td>\n",
       "      <td>68.18</td>\n",
       "      <td>124.36</td>\n",
       "      <td>75.33</td>\n",
       "      <td>140.61</td>\n",
       "      <td>103.8</td>\n",
       "      <td>24.6</td>\n",
       "      <td>27.2</td>\n",
       "      <td>1.599</td>\n",
       "      <td>167.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 08:00:00</th>\n",
       "      <td>Inv-3</td>\n",
       "      <td>97.92</td>\n",
       "      <td>178.64</td>\n",
       "      <td>106.32</td>\n",
       "      <td>194.83</td>\n",
       "      <td>281.8</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0.960</td>\n",
       "      <td>220.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Inv  AC_Real_Power  AC_Current  DC_Power  DC_Current  \\\n",
       "DateTime                                                                      \n",
       "2019-04-01 07:00:00  Inv-3          10.28       19.65     12.56       24.98   \n",
       "2019-04-01 07:15:00  Inv-3          26.17       47.72     31.05       54.93   \n",
       "2019-04-01 07:30:00  Inv-3          45.80       83.65     52.47       93.66   \n",
       "2019-04-01 07:45:00  Inv-3          68.18      124.36     75.33      140.61   \n",
       "2019-04-01 08:00:00  Inv-3          97.92      178.64    106.32      194.83   \n",
       "\n",
       "                     Tilt_Irradiation_1  Temp_Ambient_1  Temp_Module_1  \\\n",
       "DateTime                                                                 \n",
       "2019-04-01 07:00:00                44.8            20.2           22.9   \n",
       "2019-04-01 07:15:00                64.6            22.4           24.8   \n",
       "2019-04-01 07:30:00                82.6            23.9           26.1   \n",
       "2019-04-01 07:45:00               103.8            24.6           27.2   \n",
       "2019-04-01 08:00:00               281.8            26.5           31.2   \n",
       "\n",
       "                     Wind_Speed_1  Hor_Irradiation_1  Operation  \n",
       "DateTime                                                         \n",
       "2019-04-01 07:00:00         0.500               48.1          1  \n",
       "2019-04-01 07:15:00         0.614               79.8          1  \n",
       "2019-04-01 07:30:00         0.802              119.5          1  \n",
       "2019-04-01 07:45:00         1.599              167.4          1  \n",
       "2019-04-01 08:00:00         0.960              220.1          1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71ae9ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inv                   0\n",
      "AC_Real_Power         0\n",
      "AC_Current            0\n",
      "DC_Power              0\n",
      "DC_Current            0\n",
      "Tilt_Irradiation_1    0\n",
      "Temp_Ambient_1        0\n",
      "Temp_Module_1         0\n",
      "Wind_Speed_1          0\n",
      "Hor_Irradiation_1     0\n",
      "Operation             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_data = df.isnull().sum()\n",
    "print(missing_data)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64cae150",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "operational_data = df\n",
    "numerical_features = ['AC_Real_Power','Tilt_Irradiation_1', 'Temp_Ambient_1', 'Hor_Irradiation_1']\n",
    "\n",
    "# Normalization of the features\n",
    "operational_data[numerical_features] = scaler.fit_transform(operational_data[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e4bd3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = operational_data[['Tilt_Irradiation_1', 'Temp_Ambient_1', 'Hor_Irradiation_1']]\n",
    "y = operational_data['AC_Real_Power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af14a491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch [1/200], Loss: 0.1578\n",
      "Validation - Epoch [1/200], Loss: 0.0266\n",
      "Training - Epoch [2/200], Loss: 0.0145\n",
      "Validation - Epoch [2/200], Loss: 0.0095\n",
      "Training - Epoch [3/200], Loss: 0.0127\n",
      "Validation - Epoch [3/200], Loss: 0.0122\n",
      "Training - Epoch [4/200], Loss: 0.0123\n",
      "Validation - Epoch [4/200], Loss: 0.0102\n",
      "Training - Epoch [5/200], Loss: 0.0118\n",
      "Validation - Epoch [5/200], Loss: 0.0134\n",
      "Training - Epoch [6/200], Loss: 0.0115\n",
      "Validation - Epoch [6/200], Loss: 0.0089\n",
      "Training - Epoch [7/200], Loss: 0.0112\n",
      "Validation - Epoch [7/200], Loss: 0.0171\n",
      "Training - Epoch [8/200], Loss: 0.0111\n",
      "Validation - Epoch [8/200], Loss: 0.0091\n",
      "Training - Epoch [9/200], Loss: 0.0111\n",
      "Validation - Epoch [9/200], Loss: 0.0114\n",
      "Training - Epoch [10/200], Loss: 0.0105\n",
      "Validation - Epoch [10/200], Loss: 0.0099\n",
      "Training - Epoch [11/200], Loss: 0.0106\n",
      "Validation - Epoch [11/200], Loss: 0.0083\n",
      "Training - Epoch [12/200], Loss: 0.0106\n",
      "Validation - Epoch [12/200], Loss: 0.0111\n",
      "Training - Epoch [13/200], Loss: 0.0102\n",
      "Validation - Epoch [13/200], Loss: 0.0109\n",
      "Training - Epoch [14/200], Loss: 0.0105\n",
      "Validation - Epoch [14/200], Loss: 0.0084\n",
      "Training - Epoch [15/200], Loss: 0.0100\n",
      "Validation - Epoch [15/200], Loss: 0.0106\n",
      "Training - Epoch [16/200], Loss: 0.0102\n",
      "Validation - Epoch [16/200], Loss: 0.0084\n",
      "Training - Epoch [17/200], Loss: 0.0104\n",
      "Validation - Epoch [17/200], Loss: 0.0129\n",
      "Training - Epoch [18/200], Loss: 0.0101\n",
      "Validation - Epoch [18/200], Loss: 0.0136\n",
      "Training - Epoch [19/200], Loss: 0.0102\n",
      "Validation - Epoch [19/200], Loss: 0.0089\n",
      "Training - Epoch [20/200], Loss: 0.0102\n",
      "Validation - Epoch [20/200], Loss: 0.0087\n",
      "Training - Epoch [21/200], Loss: 0.0104\n",
      "Validation - Epoch [21/200], Loss: 0.0083\n",
      "Training - Epoch [22/200], Loss: 0.0105\n",
      "Validation - Epoch [22/200], Loss: 0.0104\n",
      "Training - Epoch [23/200], Loss: 0.0105\n",
      "Validation - Epoch [23/200], Loss: 0.0155\n",
      "Training - Epoch [24/200], Loss: 0.0103\n",
      "Validation - Epoch [24/200], Loss: 0.0081\n",
      "Training - Epoch [25/200], Loss: 0.0097\n",
      "Validation - Epoch [25/200], Loss: 0.0092\n",
      "Training - Epoch [26/200], Loss: 0.0108\n",
      "Validation - Epoch [26/200], Loss: 0.0090\n",
      "Training - Epoch [27/200], Loss: 0.0101\n",
      "Validation - Epoch [27/200], Loss: 0.0091\n",
      "Training - Epoch [28/200], Loss: 0.0103\n",
      "Validation - Epoch [28/200], Loss: 0.0111\n",
      "Training - Epoch [29/200], Loss: 0.0097\n",
      "Validation - Epoch [29/200], Loss: 0.0114\n",
      "Training - Epoch [30/200], Loss: 0.0105\n",
      "Validation - Epoch [30/200], Loss: 0.0098\n",
      "Training - Epoch [31/200], Loss: 0.0100\n",
      "Validation - Epoch [31/200], Loss: 0.0166\n",
      "Training - Epoch [32/200], Loss: 0.0118\n",
      "Validation - Epoch [32/200], Loss: 0.0131\n",
      "Training - Epoch [33/200], Loss: 0.0102\n",
      "Validation - Epoch [33/200], Loss: 0.0088\n",
      "Training - Epoch [34/200], Loss: 0.0100\n",
      "Validation - Epoch [34/200], Loss: 0.0087\n",
      "Training - Epoch [35/200], Loss: 0.0094\n",
      "Validation - Epoch [35/200], Loss: 0.0083\n",
      "Training - Epoch [36/200], Loss: 0.0098\n",
      "Validation - Epoch [36/200], Loss: 0.0134\n",
      "Training - Epoch [37/200], Loss: 0.0099\n",
      "Validation - Epoch [37/200], Loss: 0.0083\n",
      "Training - Epoch [38/200], Loss: 0.0095\n",
      "Validation - Epoch [38/200], Loss: 0.0088\n",
      "Training - Epoch [39/200], Loss: 0.0105\n",
      "Validation - Epoch [39/200], Loss: 0.0160\n",
      "Training - Epoch [40/200], Loss: 0.0111\n",
      "Validation - Epoch [40/200], Loss: 0.0084\n",
      "Training - Epoch [41/200], Loss: 0.0096\n",
      "Validation - Epoch [41/200], Loss: 0.0081\n",
      "Training - Epoch [42/200], Loss: 0.0095\n",
      "Validation - Epoch [42/200], Loss: 0.0090\n",
      "Training - Epoch [43/200], Loss: 0.0094\n",
      "Validation - Epoch [43/200], Loss: 0.0095\n",
      "Training - Epoch [44/200], Loss: 0.0095\n",
      "Validation - Epoch [44/200], Loss: 0.0093\n",
      "Training - Epoch [45/200], Loss: 0.0093\n",
      "Validation - Epoch [45/200], Loss: 0.0094\n",
      "Training - Epoch [46/200], Loss: 0.0094\n",
      "Validation - Epoch [46/200], Loss: 0.0084\n",
      "Training - Epoch [47/200], Loss: 0.0095\n",
      "Validation - Epoch [47/200], Loss: 0.0100\n",
      "Training - Epoch [48/200], Loss: 0.0094\n",
      "Validation - Epoch [48/200], Loss: 0.0108\n",
      "Training - Epoch [49/200], Loss: 0.0097\n",
      "Validation - Epoch [49/200], Loss: 0.0099\n",
      "Training - Epoch [50/200], Loss: 0.0096\n",
      "Validation - Epoch [50/200], Loss: 0.0104\n",
      "Training - Epoch [51/200], Loss: 0.0092\n",
      "Validation - Epoch [51/200], Loss: 0.0081\n",
      "Training - Epoch [52/200], Loss: 0.0093\n",
      "Validation - Epoch [52/200], Loss: 0.0089\n",
      "Training - Epoch [53/200], Loss: 0.0094\n",
      "Validation - Epoch [53/200], Loss: 0.0082\n",
      "Training - Epoch [54/200], Loss: 0.0091\n",
      "Validation - Epoch [54/200], Loss: 0.0082\n",
      "Training - Epoch [55/200], Loss: 0.0110\n",
      "Validation - Epoch [55/200], Loss: 0.0130\n",
      "Training - Epoch [56/200], Loss: 0.0096\n",
      "Validation - Epoch [56/200], Loss: 0.0086\n",
      "Training - Epoch [57/200], Loss: 0.0096\n",
      "Validation - Epoch [57/200], Loss: 0.0099\n",
      "Training - Epoch [58/200], Loss: 0.0090\n",
      "Validation - Epoch [58/200], Loss: 0.0114\n",
      "Training - Epoch [59/200], Loss: 0.0091\n",
      "Validation - Epoch [59/200], Loss: 0.0079\n",
      "Training - Epoch [60/200], Loss: 0.0089\n",
      "Validation - Epoch [60/200], Loss: 0.0088\n",
      "Training - Epoch [61/200], Loss: 0.0090\n",
      "Validation - Epoch [61/200], Loss: 0.0089\n",
      "Training - Epoch [62/200], Loss: 0.0181\n",
      "Validation - Epoch [62/200], Loss: 0.0254\n",
      "Training - Epoch [63/200], Loss: 0.0247\n",
      "Validation - Epoch [63/200], Loss: 0.0154\n",
      "Training - Epoch [64/200], Loss: 0.0157\n",
      "Validation - Epoch [64/200], Loss: 0.0145\n",
      "Training - Epoch [65/200], Loss: 0.0135\n",
      "Validation - Epoch [65/200], Loss: 0.0117\n",
      "Training - Epoch [66/200], Loss: 0.0126\n",
      "Validation - Epoch [66/200], Loss: 0.0144\n",
      "Training - Epoch [67/200], Loss: 0.0123\n",
      "Validation - Epoch [67/200], Loss: 0.0117\n",
      "Training - Epoch [68/200], Loss: 0.0119\n",
      "Validation - Epoch [68/200], Loss: 0.0113\n",
      "Training - Epoch [69/200], Loss: 0.0113\n",
      "Validation - Epoch [69/200], Loss: 0.0142\n",
      "Training - Epoch [70/200], Loss: 0.0128\n",
      "Validation - Epoch [70/200], Loss: 0.0115\n",
      "Training - Epoch [71/200], Loss: 0.0118\n",
      "Validation - Epoch [71/200], Loss: 0.0111\n",
      "Training - Epoch [72/200], Loss: 0.0115\n",
      "Validation - Epoch [72/200], Loss: 0.0119\n",
      "Training - Epoch [73/200], Loss: 0.0114\n",
      "Validation - Epoch [73/200], Loss: 0.0105\n",
      "Training - Epoch [74/200], Loss: 0.0117\n",
      "Validation - Epoch [74/200], Loss: 0.0117\n",
      "Training - Epoch [75/200], Loss: 0.0129\n",
      "Validation - Epoch [75/200], Loss: 0.0147\n",
      "Training - Epoch [76/200], Loss: 0.0303\n",
      "Validation - Epoch [76/200], Loss: 0.0126\n",
      "Training - Epoch [77/200], Loss: 0.0144\n",
      "Validation - Epoch [77/200], Loss: 0.0134\n",
      "Training - Epoch [78/200], Loss: 0.0137\n",
      "Validation - Epoch [78/200], Loss: 0.0158\n",
      "Training - Epoch [79/200], Loss: 0.0131\n",
      "Validation - Epoch [79/200], Loss: 0.0111\n",
      "Training - Epoch [80/200], Loss: 0.0125\n",
      "Validation - Epoch [80/200], Loss: 0.0108\n",
      "Training - Epoch [81/200], Loss: 0.0122\n",
      "Validation - Epoch [81/200], Loss: 0.0134\n",
      "Training - Epoch [82/200], Loss: 0.0121\n",
      "Validation - Epoch [82/200], Loss: 0.0116\n",
      "Training - Epoch [83/200], Loss: 0.0116\n",
      "Validation - Epoch [83/200], Loss: 0.0100\n",
      "Training - Epoch [84/200], Loss: 0.0114\n",
      "Validation - Epoch [84/200], Loss: 0.0116\n",
      "Training - Epoch [85/200], Loss: 0.0111\n",
      "Validation - Epoch [85/200], Loss: 0.0111\n",
      "Training - Epoch [86/200], Loss: 0.0114\n",
      "Validation - Epoch [86/200], Loss: 0.0113\n",
      "Training - Epoch [87/200], Loss: 0.0109\n",
      "Validation - Epoch [87/200], Loss: 0.0121\n",
      "Training - Epoch [88/200], Loss: 0.0110\n",
      "Validation - Epoch [88/200], Loss: 0.0098\n",
      "Training - Epoch [89/200], Loss: 0.0134\n",
      "Validation - Epoch [89/200], Loss: 0.0105\n",
      "Training - Epoch [90/200], Loss: 0.0115\n",
      "Validation - Epoch [90/200], Loss: 0.0101\n",
      "Training - Epoch [91/200], Loss: 0.0107\n",
      "Validation - Epoch [91/200], Loss: 0.0108\n",
      "Training - Epoch [92/200], Loss: 0.0109\n",
      "Validation - Epoch [92/200], Loss: 0.0112\n",
      "Training - Epoch [93/200], Loss: 0.0110\n",
      "Validation - Epoch [93/200], Loss: 0.0102\n",
      "Training - Epoch [94/200], Loss: 0.0107\n",
      "Validation - Epoch [94/200], Loss: 0.0106\n",
      "Training - Epoch [95/200], Loss: 0.0109\n",
      "Validation - Epoch [95/200], Loss: 0.0105\n",
      "Training - Epoch [96/200], Loss: 0.0127\n",
      "Validation - Epoch [96/200], Loss: 0.0102\n",
      "Training - Epoch [97/200], Loss: 0.0112\n",
      "Validation - Epoch [97/200], Loss: 0.0113\n",
      "Training - Epoch [98/200], Loss: 0.0112\n",
      "Validation - Epoch [98/200], Loss: 0.0102\n",
      "Training - Epoch [99/200], Loss: 0.0111\n",
      "Validation - Epoch [99/200], Loss: 0.0143\n",
      "Training - Epoch [100/200], Loss: 0.0135\n",
      "Validation - Epoch [100/200], Loss: 0.0108\n",
      "Training - Epoch [101/200], Loss: 0.0111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch [101/200], Loss: 0.0104\n",
      "Training - Epoch [102/200], Loss: 0.0107\n",
      "Validation - Epoch [102/200], Loss: 0.0109\n",
      "Training - Epoch [103/200], Loss: 0.0107\n",
      "Validation - Epoch [103/200], Loss: 0.0104\n",
      "Training - Epoch [104/200], Loss: 0.0109\n",
      "Validation - Epoch [104/200], Loss: 0.0096\n",
      "Training - Epoch [105/200], Loss: 0.0108\n",
      "Validation - Epoch [105/200], Loss: 0.0097\n",
      "Training - Epoch [106/200], Loss: 0.0107\n",
      "Validation - Epoch [106/200], Loss: 0.0126\n",
      "Training - Epoch [107/200], Loss: 0.0107\n",
      "Validation - Epoch [107/200], Loss: 0.0117\n",
      "Training - Epoch [108/200], Loss: 0.0108\n",
      "Validation - Epoch [108/200], Loss: 0.0134\n",
      "Training - Epoch [109/200], Loss: 0.0107\n",
      "Validation - Epoch [109/200], Loss: 0.0108\n",
      "Training - Epoch [110/200], Loss: 0.0107\n",
      "Validation - Epoch [110/200], Loss: 0.0108\n",
      "Training - Epoch [111/200], Loss: 0.0148\n",
      "Validation - Epoch [111/200], Loss: 0.0112\n",
      "Training - Epoch [112/200], Loss: 0.0125\n",
      "Validation - Epoch [112/200], Loss: 0.0102\n",
      "Training - Epoch [113/200], Loss: 0.0111\n",
      "Validation - Epoch [113/200], Loss: 0.0117\n",
      "Training - Epoch [114/200], Loss: 0.0108\n",
      "Validation - Epoch [114/200], Loss: 0.0158\n",
      "Training - Epoch [115/200], Loss: 0.0108\n",
      "Validation - Epoch [115/200], Loss: 0.0124\n",
      "Training - Epoch [116/200], Loss: 0.0106\n",
      "Validation - Epoch [116/200], Loss: 0.0103\n",
      "Training - Epoch [117/200], Loss: 0.0105\n",
      "Validation - Epoch [117/200], Loss: 0.0096\n",
      "Training - Epoch [118/200], Loss: 0.0108\n",
      "Validation - Epoch [118/200], Loss: 0.0108\n",
      "Training - Epoch [119/200], Loss: 0.0105\n",
      "Validation - Epoch [119/200], Loss: 0.0128\n",
      "Training - Epoch [120/200], Loss: 0.0108\n",
      "Validation - Epoch [120/200], Loss: 0.0100\n",
      "Training - Epoch [121/200], Loss: 0.0111\n",
      "Validation - Epoch [121/200], Loss: 0.0094\n",
      "Training - Epoch [122/200], Loss: 0.0117\n",
      "Validation - Epoch [122/200], Loss: 0.0116\n",
      "Training - Epoch [123/200], Loss: 0.0118\n",
      "Validation - Epoch [123/200], Loss: 0.0123\n",
      "Training - Epoch [124/200], Loss: 0.0109\n",
      "Validation - Epoch [124/200], Loss: 0.0098\n",
      "Training - Epoch [125/200], Loss: 0.0109\n",
      "Validation - Epoch [125/200], Loss: 0.0096\n",
      "Training - Epoch [126/200], Loss: 0.0105\n",
      "Validation - Epoch [126/200], Loss: 0.0101\n",
      "Training - Epoch [127/200], Loss: 0.0106\n",
      "Validation - Epoch [127/200], Loss: 0.0111\n",
      "Training - Epoch [128/200], Loss: 0.0105\n",
      "Validation - Epoch [128/200], Loss: 0.0095\n",
      "Training - Epoch [129/200], Loss: 0.0107\n",
      "Validation - Epoch [129/200], Loss: 0.0101\n",
      "Training - Epoch [130/200], Loss: 0.0106\n",
      "Validation - Epoch [130/200], Loss: 0.0103\n",
      "Training - Epoch [131/200], Loss: 0.0111\n",
      "Validation - Epoch [131/200], Loss: 0.0102\n",
      "Training - Epoch [132/200], Loss: 0.0108\n",
      "Validation - Epoch [132/200], Loss: 0.0100\n",
      "Training - Epoch [133/200], Loss: 0.0109\n",
      "Validation - Epoch [133/200], Loss: 0.0098\n",
      "Training - Epoch [134/200], Loss: 0.0130\n",
      "Validation - Epoch [134/200], Loss: 0.0109\n",
      "Training - Epoch [135/200], Loss: 0.0112\n",
      "Validation - Epoch [135/200], Loss: 0.0122\n",
      "Training - Epoch [136/200], Loss: 0.0113\n",
      "Validation - Epoch [136/200], Loss: 0.0098\n",
      "Training - Epoch [137/200], Loss: 0.0107\n",
      "Validation - Epoch [137/200], Loss: 0.0114\n",
      "Training - Epoch [138/200], Loss: 0.0106\n",
      "Validation - Epoch [138/200], Loss: 0.0104\n",
      "Training - Epoch [139/200], Loss: 0.0104\n",
      "Validation - Epoch [139/200], Loss: 0.0094\n",
      "Training - Epoch [140/200], Loss: 0.0106\n",
      "Validation - Epoch [140/200], Loss: 0.0105\n",
      "Training - Epoch [141/200], Loss: 0.0112\n",
      "Validation - Epoch [141/200], Loss: 0.0105\n",
      "Training - Epoch [142/200], Loss: 0.0107\n",
      "Validation - Epoch [142/200], Loss: 0.0099\n",
      "Training - Epoch [143/200], Loss: 0.0119\n",
      "Validation - Epoch [143/200], Loss: 0.0107\n",
      "Training - Epoch [144/200], Loss: 0.0126\n",
      "Validation - Epoch [144/200], Loss: 0.0114\n",
      "Training - Epoch [145/200], Loss: 0.0108\n",
      "Validation - Epoch [145/200], Loss: 0.0097\n",
      "Training - Epoch [146/200], Loss: 0.0105\n",
      "Validation - Epoch [146/200], Loss: 0.0096\n",
      "Training - Epoch [147/200], Loss: 0.0104\n",
      "Validation - Epoch [147/200], Loss: 0.0095\n",
      "Training - Epoch [148/200], Loss: 0.0104\n",
      "Validation - Epoch [148/200], Loss: 0.0111\n",
      "Training - Epoch [149/200], Loss: 0.0104\n",
      "Validation - Epoch [149/200], Loss: 0.0097\n",
      "Training - Epoch [150/200], Loss: 0.0104\n",
      "Validation - Epoch [150/200], Loss: 0.0095\n",
      "Training - Epoch [151/200], Loss: 0.0103\n",
      "Validation - Epoch [151/200], Loss: 0.0098\n",
      "Training - Epoch [152/200], Loss: 0.0103\n",
      "Validation - Epoch [152/200], Loss: 0.0097\n",
      "Training - Epoch [153/200], Loss: 0.0105\n",
      "Validation - Epoch [153/200], Loss: 0.0099\n",
      "Training - Epoch [154/200], Loss: 0.0105\n",
      "Validation - Epoch [154/200], Loss: 0.0094\n",
      "Training - Epoch [155/200], Loss: 0.0123\n",
      "Validation - Epoch [155/200], Loss: 0.0103\n",
      "Training - Epoch [156/200], Loss: 0.0107\n",
      "Validation - Epoch [156/200], Loss: 0.0094\n",
      "Training - Epoch [157/200], Loss: 0.0106\n",
      "Validation - Epoch [157/200], Loss: 0.0100\n",
      "Training - Epoch [158/200], Loss: 0.0115\n",
      "Validation - Epoch [158/200], Loss: 0.0104\n",
      "Training - Epoch [159/200], Loss: 0.0110\n",
      "Validation - Epoch [159/200], Loss: 0.0109\n",
      "Training - Epoch [160/200], Loss: 0.0109\n",
      "Validation - Epoch [160/200], Loss: 0.0108\n",
      "Training - Epoch [161/200], Loss: 0.0104\n",
      "Validation - Epoch [161/200], Loss: 0.0094\n",
      "Training - Epoch [162/200], Loss: 0.0104\n",
      "Validation - Epoch [162/200], Loss: 0.0099\n",
      "Training - Epoch [163/200], Loss: 0.0107\n",
      "Validation - Epoch [163/200], Loss: 0.0104\n",
      "Training - Epoch [164/200], Loss: 0.0118\n",
      "Validation - Epoch [164/200], Loss: 0.0101\n",
      "Training - Epoch [165/200], Loss: 0.0107\n",
      "Validation - Epoch [165/200], Loss: 0.0118\n",
      "Training - Epoch [166/200], Loss: 0.0111\n",
      "Validation - Epoch [166/200], Loss: 0.0105\n",
      "Training - Epoch [167/200], Loss: 0.0107\n",
      "Validation - Epoch [167/200], Loss: 0.0093\n",
      "Training - Epoch [168/200], Loss: 0.0103\n",
      "Validation - Epoch [168/200], Loss: 0.0107\n",
      "Training - Epoch [169/200], Loss: 0.0102\n",
      "Validation - Epoch [169/200], Loss: 0.0093\n",
      "Training - Epoch [170/200], Loss: 0.0102\n",
      "Validation - Epoch [170/200], Loss: 0.0094\n",
      "Training - Epoch [171/200], Loss: 0.0105\n",
      "Validation - Epoch [171/200], Loss: 0.0104\n",
      "Training - Epoch [172/200], Loss: 0.0104\n",
      "Validation - Epoch [172/200], Loss: 0.0093\n",
      "Training - Epoch [173/200], Loss: 0.0103\n",
      "Validation - Epoch [173/200], Loss: 0.0093\n",
      "Training - Epoch [174/200], Loss: 0.0102\n",
      "Validation - Epoch [174/200], Loss: 0.0094\n",
      "Training - Epoch [175/200], Loss: 0.0114\n",
      "Validation - Epoch [175/200], Loss: 0.0107\n",
      "Training - Epoch [176/200], Loss: 0.0108\n",
      "Validation - Epoch [176/200], Loss: 0.0110\n",
      "Training - Epoch [177/200], Loss: 0.0106\n",
      "Validation - Epoch [177/200], Loss: 0.0101\n",
      "Training - Epoch [178/200], Loss: 0.0115\n",
      "Validation - Epoch [178/200], Loss: 0.0097\n",
      "Training - Epoch [179/200], Loss: 0.0107\n",
      "Validation - Epoch [179/200], Loss: 0.0126\n",
      "Training - Epoch [180/200], Loss: 0.0105\n",
      "Validation - Epoch [180/200], Loss: 0.0100\n",
      "Training - Epoch [181/200], Loss: 0.0107\n",
      "Validation - Epoch [181/200], Loss: 0.0108\n",
      "Training - Epoch [182/200], Loss: 0.0120\n",
      "Validation - Epoch [182/200], Loss: 0.0102\n",
      "Training - Epoch [183/200], Loss: 0.0116\n",
      "Validation - Epoch [183/200], Loss: 0.0115\n",
      "Training - Epoch [184/200], Loss: 0.0106\n",
      "Validation - Epoch [184/200], Loss: 0.0100\n",
      "Training - Epoch [185/200], Loss: 0.0105\n",
      "Validation - Epoch [185/200], Loss: 0.0113\n",
      "Training - Epoch [186/200], Loss: 0.0105\n",
      "Validation - Epoch [186/200], Loss: 0.0112\n",
      "Training - Epoch [187/200], Loss: 0.0105\n",
      "Validation - Epoch [187/200], Loss: 0.0101\n",
      "Training - Epoch [188/200], Loss: 0.0101\n",
      "Validation - Epoch [188/200], Loss: 0.0095\n",
      "Training - Epoch [189/200], Loss: 0.0103\n",
      "Validation - Epoch [189/200], Loss: 0.0104\n",
      "Training - Epoch [190/200], Loss: 0.0103\n",
      "Validation - Epoch [190/200], Loss: 0.0101\n",
      "Training - Epoch [191/200], Loss: 0.0103\n",
      "Validation - Epoch [191/200], Loss: 0.0102\n",
      "Training - Epoch [192/200], Loss: 0.0161\n",
      "Validation - Epoch [192/200], Loss: 0.0122\n",
      "Training - Epoch [193/200], Loss: 0.0109\n",
      "Validation - Epoch [193/200], Loss: 0.0103\n",
      "Training - Epoch [194/200], Loss: 0.0108\n",
      "Validation - Epoch [194/200], Loss: 0.0099\n",
      "Training - Epoch [195/200], Loss: 0.0102\n",
      "Validation - Epoch [195/200], Loss: 0.0103\n",
      "Training - Epoch [196/200], Loss: 0.0105\n",
      "Validation - Epoch [196/200], Loss: 0.0102\n",
      "Training - Epoch [197/200], Loss: 0.0109\n",
      "Validation - Epoch [197/200], Loss: 0.0098\n",
      "Training - Epoch [198/200], Loss: 0.0102\n",
      "Validation - Epoch [198/200], Loss: 0.0097\n",
      "Training - Epoch [199/200], Loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch [199/200], Loss: 0.0114\n",
      "Training - Epoch [200/200], Loss: 0.0113\n",
      "Validation - Epoch [200/200], Loss: 0.0096\n"
     ]
    }
   ],
   "source": [
    "# Transformer Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, hidden_dim, num_layers, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.squeeze(1)\n",
    "        x = self.fc(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.tensor(features.values, dtype=torch.float32) \n",
    "        self.targets = torch.tensor(targets.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = X_train.shape[1]  # Dimension of input features\n",
    "num_heads = 2  # Number of attention heads = 2\n",
    "hidden_dim = 200  # Hidden layers of the model = 200\n",
    "num_layers = 2  # Number of transformer layers = 2\n",
    "dropout = 0.1  # Dropout probability = 0.1\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "model = TransformerModel(input_dim=input_dim, num_heads=num_heads, hidden_dim=hidden_dim,\n",
    "                          num_layers=num_layers, dropout=dropout)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression task\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Optimizer used is Adam and learning rate is 0.001\n",
    "\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(inputs)\n",
    "    average_loss = total_loss / len(train_dataset)\n",
    "    print(f'Training - Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for inputs, labels in test_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * len(inputs)\n",
    "        average_loss = total_loss / len(test_dataset)\n",
    "        print(f'Validation - Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        # Stored true labels and predictions\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(outputs.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1f80e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        # Stored true labels and predictions\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(outputs.numpy())\n",
    "\n",
    "# Converted y_true and y_pred to numpy arrays\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Computed confusion matrix\n",
    "cm = confusion_matrix(np.round(y_true), np.round(y_pred))\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2963b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.00958706\n",
      "Mean Absolute Error: 0.06519712\n",
      "Root Mean Squared Error: 0.09791353\n",
      "R-squared Score: 0.8804465711457975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Computed Mean Squared Error\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "# Computed Mean Absolute Error\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# Computed Root Mean Squared Error\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Computed R2-Score\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac9de0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alarm triggered for 8 consecutive faults on 2019-05-29.\n",
      "Alarm triggered for 7 consecutive faults on 2019-05-26.\n",
      "Alarm triggered for 7 consecutive faults on 2019-06-04.\n",
      "Alarm triggered for 7 consecutive faults on 2019-04-04.\n",
      "Alarm triggered for 7 consecutive faults on 2019-04-22.\n",
      "Alarm triggered for 7 consecutive faults on 2019-05-06.\n",
      "Alarm triggered for 7 consecutive faults on 2019-04-20.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-12.\n",
      "Alarm triggered for 6 consecutive faults on 2019-05-18.\n",
      "Alarm triggered for 6 consecutive faults on 2019-05-20.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-13.\n",
      "Alarm triggered for 6 consecutive faults on 2019-05-27.\n",
      "Alarm triggered for 6 consecutive faults on 2019-04-07.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-14.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-02.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-26.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-21.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-09.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-19.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-30.\n",
      "Alarm triggered for 5 consecutive faults on 2019-06-02.\n",
      "Alarm triggered for 5 consecutive faults on 2019-04-23.\n",
      "Alarm triggered for 5 consecutive faults on 2019-05-10.\n",
      "Alarm triggered for 4 consecutive faults on 2019-05-09.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-01.\n",
      "Alarm triggered for 4 consecutive faults on 2019-05-22.\n",
      "Alarm triggered for 4 consecutive faults on 2019-06-01.\n",
      "Alarm triggered for 4 consecutive faults on 2019-05-04.\n",
      "Alarm triggered for 4 consecutive faults on 2019-06-05.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-28.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-08.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-10.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-17.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-21.\n",
      "Alarm triggered for 4 consecutive faults on 2019-04-19.\n"
     ]
    }
   ],
   "source": [
    "# Function to check for four consecutive faults in a day and trigger alarms\n",
    "def check_consecutive_faults(fault_indices, df, window=3):\n",
    "    fault_timestamps = df.index[fault_indices]\n",
    "\n",
    "    grouped_by_day = fault_timestamps.to_series().dt.date\n",
    "\n",
    "    # Checked if there are three or more consecutive faults within the same day\n",
    "    daily_fault_count = grouped_by_day.value_counts()\n",
    "    for date, count in daily_fault_count.items():\n",
    "        if count >= window:\n",
    "            print(f\"Alarm triggered for {count} consecutive faults on {date}.\")\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_ac_power = model(X_test_tensor)  # Model predictions\n",
    "    actual_ac_power = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "    # Absolute residuals between predicted and actual AC power\n",
    "    residuals = torch.abs(predicted_ac_power - actual_ac_power)\n",
    "\n",
    "# Calculated the standard deviation for setting the fault threshold\n",
    "sigma = torch.std(residuals).item()\n",
    "threshold = 2 * sigma  # Set the threshold as 2 * sigma\n",
    "\n",
    "anomalies = (residuals > threshold).int()\n",
    "\n",
    "fault_indices = torch.nonzero(anomalies).squeeze().tolist()\n",
    "\n",
    "check_consecutive_faults(fault_indices, df, window=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22bc7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
